---
title: 《统计思维：程序员数学之概率统计》读书摘录
date: 2015-10-03 15:20:00
updated: 2015-10-03 15:20:00
category: statistics
tags:
- 统计
- 读书笔记
mathjax: true
---
## 第一章 探索性数据分析

### 重编码（recode）
不是调查收集的原始数据，而是使用原始数据计算得到的变量。
可用来检查数据的一致性和准确性

---
## 第二章 分布

### 直方图
直方图能判断分布的形状，容易发现最常出现的值，但不一定能看到很少出现的值（离群值）
<!--more-->
### 变量分布

- 集中趋势 —— 均值、中位数
    变量值是否聚集在某个值附近？

- 众数
    是否有多个聚集点？

- 展布 —— 方差
    变量的变化性如何？

- 尾部
    当值偏离众数时，其概率降低多快？

- 离群值
    是否有远离众数的极端值？

### 汇总统计量

- 均值
    描述分布的“集中趋势”

	$$x=\frac{1}{n} \sum\_i{x\_i}$$

- 方差
    - 描述分布的变化性，或“展布”

    $$S^2=\frac{1}{n} \sum\_i{(x\_i -\bar{x} )^2}$$

- 效应量
    - 均值的差值：$\bar{x\_1} -\bar{x\_2} $
    - 均值差/合并标准差：
    $$d=\bar{x\_1} -\bar{x\_2} \over s$$
    其中，$s= \frac{n\_1 \cdot s\_1 + n\_2 \cdot s\_2}{n\_1+n\_2}$，该量描述均值差相对标准差的**倍数**
    
## 第三章 概率质量函数
### 概率质量函数（Probability Mass Function，PMF）
概率质量函数将每个值映射到其概率，$概率=\frac{频数}{样本量} $

* PMF 适用于变量值数量较少的情况。随着值的数量增加，每个值对应的概率会变得越来越小，随机噪音的影响就会变大。

## 第四章 累积分布函数（cumulative distribution function，CDF）
### 百分位秩（percentile rank）
在标准化考试成绩中，百分位秩是**比你成绩低（或相同）的人的比例**

### CDF
CDF将一个值映射到百分位秩
CDF(x) = 小于或等于x的值在分布中所占的比例

* 不同于百分位秩，CDF范围为0到1
* 第 50 百分位就是**中位数**
* 基于百分位数的统计量
	* 中位数（median）
	* 四分位矩（interquartile range，IQR）
	* 等份点——分位数（quantile）

### 利用CDF生成随机样本
* 无论CDF的形状如何，其百分位秩的分布都是均匀的
利用这一点，可以使用给定的CDF生成随机数：

1. 从0到100中均匀地选择一个百分位秩
2. 使用cdf.Percentile，得到分布中对应所选百分位秩的值

## 第五章 分布建模
基于有限样本的经验观察，被称为*经验分布*
*分析分布*试图建立一个简化的分布模型，来描述真实世界的分布，可以用作经验分布的**建模**

* 现实世界的很多现象都可以用分析分布进行建模
* 分析分布是一种**抽象**，也是一种**数据压缩形式**：如果模型很好地拟合了一个数据集，那么只需几个参数便可对大量数据进行概括
* 有时候，我们会发现一种自然现象符合某个分析分布，进而这种认识可以帮助我们更好地了解物理系统：如 Pareto 分布经常是由带有正反馈的生成型过程导致的。
* 分析分布可以方便地进行数学分析
* 现实世界的数据**永远不会**完美地符合一个分析分布，现实世界和数学模型之间总是存在着差异。
* 什么是“相关”的，什么是“不必要”的，这取决于你将这个模型用于何种用途。

## 第六章 概率密度函数（Probability density function, PDF）
概率密度度量单位 x 的概率。

### 核密度估计（kernel density estimation, KDE）
核密度估计可以对一个样本寻找符合样本数据的适当平滑的 PDF

KDE 估计密度函数可用于：

1. 可视化
	在项目探索阶段，可通过 CDF 展现分布，继而判断估计 PDF 是否为该分布的适宜模型。
2. 插值
	如果相信总体分布是平滑的，那么就可以使用KDE为样本中不存在的值插入相应的密度。
3. 模拟
	我们可以使用 KDE，对样本分布做平滑处理，使得模拟可以探索可能性更高的结果。

### PMF、CDF、PDF 的关系

{% asset_img pmf-cdf-pdf.jpg 分布函数的关系框架 %}

PMF：一组**离散值**的概率。PDF 累加得到 CDF。
CDF：累积概率。
PDF：**连续性** CDF 的导数。

离散型分布 -> 连续型分布：平滑处理
1. 假设数据来自连续的分析分布，然后估计这个分布的参数
2. 核密度估计

### 矩（moment）
原始矩是一个统计量。对一组值为$x\_i$的样本，第 k 个原始矩为：
$$m'\_k=\frac{1}{n} \sum{\_i} x\_i^k$$ 当 k=1 时，原始矩即为样本均值 $\bar{x} $。

第 k 个中心矩（central moment）计算公式：
$$m\_k=\frac{1}{n} \sum{\_i} (x\_i -\bar{x} )^k$$
当 k=2 时，中心矩即为方差。

#### 为什么称为“矩”
> 如果我们在直尺的不同位置 $x\_i$ 附加一个重物，然后将直尺围绕这些值的均值旋转，旋转重物的[惯性力矩](http://en.wikipedia.org/wiki/Moment_of_inertia)就是这些值的方差。

#### 统计量的单位
如果值$x\_i$的单位是厘米，那么第一原始矩的单位是*厘米*，第二原始矩的单位是*平方厘米*，第三原始矩的单位是*立方厘米*

### 偏度（skewness）
如果分布是以集中趋势为中心对称的，那么这个分布就是*非偏斜的（unskewed）*。
如果分布中的值向右**延伸更多**，那么这个分布就是*右偏的（right skewed）*；
如果分布中的值向左**延伸更多**，那么这个分布就是*左偏的（left skewed）*；

* *偏斜（skewed）*与*有偏（biased）*并无关系。偏度只是描述了分布的形状。

#### 偏度的计算
对给定的值序列 $x\_i$，样本偏度 $$g\_1= \frac{ \tfrac{1}{n} \sum{\_i} (x\_i-\bar{x} )^3}{方差^3} $$

偏度为负值代表分布左偏，正值代表分布右偏。$g\_1$的大小代表偏斜的程度。

#### 衡量分布对称性的另一个方法
实际应用中，样本偏度容易受分布中离群值的影响，因此，计算样本偏度通常并非好主意。

衡量分布对称性的另一个方法是**检查均值和中位数的关系**：极端值对均值的影响比对中位数影响更大
* 在左偏分布中，均值 < 中位数
* 在右偏分布中，均值 > 中位数

##### Pearson 中位数偏度系数（Pearson's median skewness coefficient）
$$g\_p=3(\bar{x} -m)/S$$

Pearson 中位数偏度系数更加稳健（robust）。

## 第七章 变量之间的关系

> 如果能够从一个变量的信息得到另一个变量的信息，那么这两个变量就是**相关的**。

### 散点图

研究两个变量之间关系最简单方法就是散点图（scatter plot）。

#### 抖动技术（jittering）
当获取数据由于某种原因而丢失部分信息，例如数据经过四舍五入后丢失了更高精度的小数位信息，变得“更离散”而导致散点图不美观，这时可以通过加入随机噪音（例如服从均匀分布的随机值）来填补各离散值之间的空隙。

**抖动技术只是为了图像的美观，应只用于视觉呈现，而不能通过它来分析数据。**

#### 饱和（saturation）
由于数据在一定区域内过于密集，甚至出现重叠，而离群值显得特别突出。这种情况称为“饱和”。

解决办法：
将图中的点以半透明显示（例如 alpha=0.2），这样重叠的点只会导致那一片的数据点颜色更深。
（我的理解：**以半透明显示的办法，相当于把数据正则化（Normalized）了**，原先数据密度值的域为二值情况（0 or 1），**重叠区域密度大于 1 无法在图上体现，相当于上溢出。通过规范化，将密度值域打散在（0，1）连续域内了**，重叠区域密度只要密度不超过1，就能在散点图中较好地体现出来）

### 相关性（correlation）
相关性是一个**量化两个变量之间关系强弱**的统计量。

要衡量两个变量时，比较麻烦的是两个变量之间单位不同，无法直接比较。为此，我们需要将两个变量统一到一个量纲上。

常见的相关系数有两种：
- Pearson乘积矩相关系数：将变量统一为标准分数（standard score），即偏离均值的标准差数：$z\_i = (x\_i - \mu)/\sigma$。
- Spearman秩相关系数：将变量转换为秩（rank），就是该变量在其所有值中的排名。

标准分数有以下这些性质：
- $z\_i$是无量纲（单位）的，其分布均值为0，方差为1；
- 如果 $X$ 服从正态分布，则 $Z$ 也服从正态分布；
- 如果 $X$ 是偏斜的或包含离群值，则 $Z$ 也是偏斜的或包含离群值；

当观察的变量 $X$ 有偏斜，或是含有离群值时，$Z$ 也会受影响。这种情况下，使用百分位秩更加稳健，因为百分位秩总是服从(1, n)的均匀分布：$R~U(1, n)$，其中 $n$ 为样本数。

### 协方差（covariance）
协方差用于**度量两个变量共同变化的趋势**。

假设现在有两个序列 $X$ 和 $Y$，则两个序列中，值与均值的偏差为：
$$\begin{cases}
dx\_i = x\_i - \bar{x} \\\
dy\_i = y\_i - \bar{y}
\end{cases}$$

如果两个序列变化趋势一致的话，$dx\_i$ 和 $dy\_i$ 同号，即$dx\_i \cdot dy\_i > 0$；反之二者异号，即$dx\_i \cdot dy\_i < 0$。

**我们将这一序列所有样本的偏差加到一块，应该就能度量两个序列之间共同变化的趋势**，于是我们就有了“协方差”的定义：
$$\operatorname{Cov(X,Y)} = \frac{1}{n} \sum dx\_i dy\_i$$
注意到协方差定义中最后乘了一个 $\frac{1}{n}$ 来正则化（$n$为序列长度，此处要求$X$和$Y$必须长度相同）。

*当$X$和$Y$两个向量正交时，协方差为0*

### Pearson相关系数
协方差的单位是两个变量单位的乘积，这样会使人对它的意义感到迷惑，因而人们很少将协方差作为摘要统计量。接下来介绍的 Pearson相关系数解决了这个问题。

$$\rho = \operatorname{Cov(X,Y)} / S\_X S\_Y \tag{p}\label{pearson}$$
可见，Pearson相关系数加入了标准差来正则化协方差，而且是无量纲的。

我们可以把$\ref{pearson}$式中的$\operatorname{Cov(X,Y)}$展开，就能发现：
$$ \rho = \frac{1}{n} \sum{ \left( \left( x\_i-\bar{x} \right) / S\_X \right) \left( \left(y\_i-\bar{y}\right) / S\_Y \right) } $$
也就是说，Pearson相关系数在计算偏差时就将其与标准差相比较，得到一个归一化的结果：标准分数，从而实现无量纲的。

Pearson相关系数值的值域为$[-1, +1]$。如果$\rho >0$则两个变量正相关；反之$\rho <0$时，两个变量负相关。$\rho$的大小描述了相关性的强弱程度，当$\left\lvert \rho \right\rvert =1$时，两个变量完全相关，这时，只需要一个变量就能准确预测另一个变量。

**注意，Pearson相关系数接近0时，并不能代表变量之间没有相关关系，因为Peason相关系数只度量了线性关系。如果变量之间存在非线性关系，那么用$\rho$度量相关性就不那么准确了**。下图为一些具有非线性关系的变量的散点图，然而它们的相关系数都为0。

{% asset_img nonlinear-correlation-example.png 非线性关系变量散点图及其相关系数 %}

图片来源：[英文维基百科/Correlation and dependence](http://www.wikiwand.com/en/Correlation_and_dependence)

### Spearman秩相关
当变量之间呈线性相关，且变量大致符合正态分布时，Pearson相关系数能较好地说明相关性的强弱。然而离群值会影响Pearson相关系数的稳健性（回忆一下，Pearson相关系数定义中，每个样本的标准分数是相同权重加和的，因而离群值能较大程度地影响结果）

Spearman相关系数不仅能描述变量的相关性，还能够缓解离群值及偏斜分布的影响。缓解离群值影响是通过计算各个值的秩(rank)实现的。如在样本[1, 2, 5, 7]中，值5出现在有序列表的第3位，因此5的值为3。

*缓解离群值的常见方法就是用“排名”而非其值来计算。比如取中值（排名中位数）就比取均值面对离群点时更加稳健。*

### 相关性和因果关系

如果变量A和B相关，则有三种可能的解释：A导致B，或B导致A，或其他某种因素导致A和B。这些解释称为“因果关系”。

只有相关性，我们无法证明因果关系。要证明因果关系，有以下三种方法：
1. 时间
    如果 A 在 B 之前发生，则 A 可能导致 B，而 B 不可能导致 A。
2. 随机性
    类似随机对照试验。
3.回归分析

# 第八章 估计
使用样本来**估计**分布，用来估计的统计量叫做**估计量**（estimator）

## 均方误差（mean squared error，MSE）
均方误差可用来衡量估计量对分布的描述效果
$$ MSE = \frac{1}{m} \sum (\bar{x} - \mu)^2 $$
其中$m$为抽样次数。

### 均方根误差（root mean squared error，RMSE）
均方根误差就是均方误差的平方根：
$$ RMSE = \sqrt{MSE} $$

用均方根误差不一定越小越好，因为估计量在实际情况中不一定会出现。最可能与实际值相符的估计叫做**最大似然估计（maximum likelihood estimator，MLE）**

## 样本方差
用样本方差作为估计量估计分布的方差是最直观的方法：
$$S^2 = \frac{1}{n} \sum (x\_i - \bar{x})^2$$

然而，$$S^2$$是偏倚（biased）估计量，对于小样本，$S^2$通常比分布的方差低很多。

无偏估计量是$$S\_{n-1}^2$$
$$ S\_{n-1}^2 = \frac{1}{n-1} \sum (x\_i - \bar{x})^2 $$
其中，减去的“1”是自由度。

## 抽样
### 抽样误差
由随机选择导致的估计变化称为**抽样误差（sampling error）**，例如，从数量庞大的大猩猩总体中抽取9只测量体重，然而却运气不佳抽到了最重的9只。

### 抽样分布
抽样若干次，对每次抽样的估计量进行统计，得到的分布叫做**抽样分布**。抽样分布是对估计量分布的描述，而不是实际的值的分布。

### 抽样分布的描述
- 标准误差（standard error，SE）
标准误差度量估计值平均偏离实际值多少。注意标准误差描述的是**估计量**变化的情况，而标准差描述的是**度量值**变化的情况。
- 置信区间（confidential interval，CI）
抽样分布中指定比例的范围。例如，90%置信区间表示的是 第5个百分位数 到 第95个百分位数。

### 抽样偏倚
由于抽样过程导致的误差，叫做抽样偏倚（sampling bias）。比如，通过电话抽样统计女性体重，由于可能不能覆盖到没有电话或是不公布号码的人，实际统计的人群会有偏差。

### 测量误差
测量误差是得到的结果不准确。比如，统计女性体重时，只是询问而不测量；或是由于调查参与者“美化”自己的数字。

在汇报一个估计值时，可以用标准误差或置信区间。但要记住：抽样误差只是误差来源之一，而且通常不是最大的误差来源。
