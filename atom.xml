<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mengqi&#39;s blog</title>
  
  <subtitle>a paranoid android.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://mengqi92.github.io/"/>
  <updated>2019-11-30T16:28:17.775Z</updated>
  <id>http://mengqi92.github.io/</id>
  
  <author>
    <name>Mengqi</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Git 仓库大扫除</title>
    <link href="http://mengqi92.github.io/2018/09/18/git-housekeeping/"/>
    <id>http://mengqi92.github.io/2018/09/18/git-housekeeping/</id>
    <published>2018-09-18T23:09:02.000Z</published>
    <updated>2019-11-30T16:28:17.775Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2018/09/18/git-housekeeping/banner.jpg"><p>Git 可以说是目前最受欢迎的版本管理工具了，很多团队也都在用它来管理自己的项目代码。在一个多人协作的项目中，往往采用的是一个分支一个特性进行开发，随着每天的代码提交、合并，仓库中会有越来越多的冗余分支。这么多死分支不仅会掩盖真正在使用的分支，而且也为管理带来不便。如果你像我一样，也经常被淹没在 <code>git branch</code> 或 <code>git branch -r</code> 返回的分支大海中，那么，就是时候考虑给你的 git 仓库做一次大扫除了！</p><h2 id="本地分支与远程分支"><a href="#本地分支与远程分支" class="headerlink" title="本地分支与远程分支"></a>本地分支与远程分支</h2><p>大扫除之前，首先给自己做个深呼吸，回忆一下远程仓库和远程分支的概念。</p><p>我们本地的仓库既保留有本地的分支，也保留有跟踪远程仓库的 remote 分支（类似 <code>remotes/origin/**</code> 这种的）。后者相当于是远程仓库分支在本地仓库的代理，每次 <code>git fetch</code> 或 <code>git pull</code> 时，都会将远程仓库的分支同步到本地对应的 remote 分支上。</p><p>比如远程仓库新增了一个 <code>feature/add_a</code> 分支，那么我们在本地 <code>git fetch</code> 后，会得到一个 <code>remotes/origin/feature/add_a</code> 分支，这个名字表示 <code>origin</code> 这个远程仓库下的 <code>feature/add_a</code>，<code>origin</code> 是本地给远程仓库默认起的名字，你当然也可以改成别的名字。</p><p>理清楚了本地分支和远程分支，本地仓库和远程仓库，接下来我们就动起手来做清理吧！</p><a id="more"></a><h2 id="本地分支清理"><a href="#本地分支清理" class="headerlink" title="本地分支清理"></a>本地分支清理</h2><p>查看我们本地的分支只需要执行一下<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git branch</span></pre></td></tr></table></figure></p><p>我们还可以找出所有已经合入到 <code>master</code> 的本地分支</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git checkout master</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">git branch --merged</span></pre></td></tr></table></figure><p>针对这些已经合入的分支，如果确定已经不会使用的话，就可以将其删除了</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git branch -d feature/XXX</span></pre></td></tr></table></figure><p>如果十分确定所有合入的分支都不再需要了，那么可以考虑一次性解决（<code>(^\*)</code> 是匹配当前分支，其余 <code>(master|dev)</code> 部分可以根据自己项目的实际情况进行修改）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git branch --merged | grep -v <span class="string">"(^\*|master|dev)"</span> | xargs git branch -d</span></pre></td></tr></table></figure><p>这么一来，就可以安全地删除所有已经不再需要的分支了。除此之外，也可以浏览一下没有合入 master 的本地分支，检查看看哪些分支已经废弃，不需要继续开发了</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git branch --no-merged</span></pre></td></tr></table></figure><p>针对这些分支，只用 <code>git branch -d</code> 命令会收到系统的善意提醒。如果十分确定可以删除，那么可以使用强制删除命令（一定要确认好啊）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git branch -D feature/XXX</span></pre></td></tr></table></figure><p>经过这么一番清理，相信你的本地分支现在已经十分轻佻了，<code>git branch</code> 返回的结果看起来也十分清爽。接下来就来清理一下本地的远程分支。</p><h2 id="远程分支清理"><a href="#远程分支清理" class="headerlink" title="远程分支清理"></a>远程分支清理</h2><p>远程分支的查看只需要在 <code>git branch</code> 命令加一个 <code>-r</code>(<code>--remotes</code>) 参数即可</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git branch -r</span></pre></td></tr></table></figure><p>远程分支的清理，一方面是清理远程分支中，已经合入 <code>master</code> 的分支，另一方面是清理远程仓库已经删除了的分支，而本地还在跟踪的。</p><p>第二种情况的清理非常简单，只需要执行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git remote prune origin</span></pre></td></tr></table></figure><p>事实上，我们可以在每次 <code>git fetch</code> 时，添加一个参数 <code>-p</code> (<code>--prune</code>)，这样每次 fetch 远程仓库时都可以顺手删掉本地多余的分支（建议将 <code>git fetch -p</code> 直接 alias 到 <code>git fetch</code> 命令~）。</p><p>再来看第一种情况，虽然同样可以通过 <code>git branch -r --merged</code> 来查看已经合入 <code>master</code> 的分支，但由于远程分支不只是自己开发的，所以还需要别人的确认才能进行删除。<br>好在我们可以在命令行的帮助下快速筛选出每个人的分支，然后就可以把这份统计摘要发给 TA 来确认。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> branch <span class="keyword">in</span> `git branch -r --merged | grep -v HEAD`; <span class="keyword">do</span> <span class="built_in">echo</span> -e `git show --format=<span class="string">"%ci %cr %an"</span> <span class="variable">$branch</span> | head -n 1`; <span class="keyword">done</span> | sort -r | grep AUTHOR_NAME</span></pre></td></tr></table></figure><p>这行命令首先是过滤出所有已合入 <code>master</code> 的远程分支(<code>git branch -r --merged | grep -v HEAD</code>)，然后遍历每个分支，展示(<code>git show</code>)其最后一次提交的绝对时间(<code>%ci</code>)、相对时间(<code>%cr</code>)和作者(<code>%an</code>)信息，按时间倒序排列(<code>sort -r</code>)，最后过滤出作者是 <code>AUTHOR_NAME</code> 的分支。</p><p>如果想查看更多的信息，可以在 <code>git show</code> 的 <code>format</code> 加上 <code>%s</code>（提交信息）和 <code>%h</code>（commit SHA1 前缀）</p><p>这样一份报告，给到相关开发同学，确认之后，就可以执行批量清理了。注意，远程分支的删除应该到远程仓库去删除（否则下次 fetch 还会再拉下来），因此需要我们把这个删除动作 push 到远程仓库。</p><p>最后，如果你 push 了删除动作到远程仓库，不要忘了提醒下其他同学 <code>git fetch -p</code> 来同步删除自己本地的远程分支哈！</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git push origin --delete feature/YYY</span></pre></td></tr></table></figure><h3 id="找找我是谁"><a href="#找找我是谁" class="headerlink" title="找找我是谁"></a>找找我是谁</h3><p>如果自己经常换机器开发、push 代码，而且不同机器的 git config 不完全一样的话（比如我不同机器上 user.name 有的是英文名有的是中文名），提交的作者签名也不一样，这时还需要根据不同的 user.name 进行查找……</p><p>不过好在我们有命令行，用以下命令就能得到仓库里所有提交过的作者了~</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">git shortlog -s</span></pre></td></tr></table></figure><h2 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h2><p>本文中所有文字版权均属本人所有，未经允许请勿转载。</p><h2 id="鸣谢："><a href="#鸣谢：" class="headerlink" title="鸣谢："></a>鸣谢：</h2><p>题图 by The Creative Exchange on Unsplash</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2018/09/18/git-housekeeping/banner.jpg&quot; class=&quot;&quot;&gt;
&lt;p&gt;Git 可以说是目前最受欢迎的版本管理工具了，很多团队也都在用它来管理自己的项目代码。在一个多人协作的项目中，往往采用的是一个分支一个特性进行开发，随着每天的代码提交、合并，仓库中会有越来越多的冗余分支。这么多死分支不仅会掩盖真正在使用的分支，而且也为管理带来不便。如果你像我一样，也经常被淹没在 &lt;code&gt;git branch&lt;/code&gt; 或 &lt;code&gt;git branch -r&lt;/code&gt; 返回的分支大海中，那么，就是时候考虑给你的 git 仓库做一次大扫除了！&lt;/p&gt;
&lt;h2 id=&quot;本地分支与远程分支&quot;&gt;&lt;a href=&quot;#本地分支与远程分支&quot; class=&quot;headerlink&quot; title=&quot;本地分支与远程分支&quot;&gt;&lt;/a&gt;本地分支与远程分支&lt;/h2&gt;&lt;p&gt;大扫除之前，首先给自己做个深呼吸，回忆一下远程仓库和远程分支的概念。&lt;/p&gt;
&lt;p&gt;我们本地的仓库既保留有本地的分支，也保留有跟踪远程仓库的 remote 分支（类似 &lt;code&gt;remotes/origin/**&lt;/code&gt; 这种的）。后者相当于是远程仓库分支在本地仓库的代理，每次 &lt;code&gt;git fetch&lt;/code&gt; 或 &lt;code&gt;git pull&lt;/code&gt; 时，都会将远程仓库的分支同步到本地对应的 remote 分支上。&lt;/p&gt;
&lt;p&gt;比如远程仓库新增了一个 &lt;code&gt;feature/add_a&lt;/code&gt; 分支，那么我们在本地 &lt;code&gt;git fetch&lt;/code&gt; 后，会得到一个 &lt;code&gt;remotes/origin/feature/add_a&lt;/code&gt; 分支，这个名字表示 &lt;code&gt;origin&lt;/code&gt; 这个远程仓库下的 &lt;code&gt;feature/add_a&lt;/code&gt;，&lt;code&gt;origin&lt;/code&gt; 是本地给远程仓库默认起的名字，你当然也可以改成别的名字。&lt;/p&gt;
&lt;p&gt;理清楚了本地分支和远程分支，本地仓库和远程仓库，接下来我们就动起手来做清理吧！&lt;/p&gt;
    
    </summary>
    
    
      <category term="编程" scheme="http://mengqi92.github.io/categories/programming/"/>
    
    
      <category term="git" scheme="http://mengqi92.github.io/tags/git/"/>
    
      <category term="工具" scheme="http://mengqi92.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="小技巧" scheme="http://mengqi92.github.io/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>线性代数拾遗（六）：特征值与特征向量</title>
    <link href="http://mengqi92.github.io/2016/07/01/linear-algebra-6/"/>
    <id>http://mengqi92.github.io/2016/07/01/linear-algebra-6/</id>
    <published>2016-07-01T00:00:00.000Z</published>
    <updated>2019-11-30T16:28:17.783Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2016/07/01/linear-algebra-6/banner.jpeg"><a href="/2016/06/22/linear-algebra-5/" title="上一章">上一章</a>最后，我们引入了`马尔可夫链`。`马尔可夫链`简单来说就是一个个状态组成的链，其中每个状态只于前一个状态有关。然而，除了这个简单定义之外，`马尔可夫链`还有一个有趣的性质：`平稳分布`。要解释`平稳分布`是什么，我们先从一个例子讲起。<a id="more"></a><h1 id="一、马尔可夫链的平稳分布"><a href="#一、马尔可夫链的平稳分布" class="headerlink" title="一、马尔可夫链的平稳分布"></a>一、马尔可夫链的平稳分布</h1><p>比如一个地区有三个政党：「民主党」、「共和党」、「自由党」，我们用一个向量 $\mathbf{x} \in \mathbb{R}^3$ 来表示每年选举的投票结果:</p><script type="math/tex; mode=display">\begin{equation}\begin{bmatrix}\text{民主党得票率} \\\text{共和党得票率} \\\text{自由党得票率}\end{bmatrix}\nonumber\end{equation}</script><p>假设每年的选举结果只和上一年的结果有关，即选举向量构成的序列满足马尔可夫性质，是一个<code>马尔可夫链</code>。那么，像 <a href="/2016/06/22/linear-algebra-5/" title="上一章">上一章</a> 那个人口迁移的例子一样，我们可以用一个<code>状态迁移矩阵</code>来描述每年选举结果的变化情况。</p><p>比如我们要研究某一年开始，该地区选举变化情况，而且已经得到了该地区选举变化的迁移矩阵 $\mathbf{P}$：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{P}=\begin{bmatrix}0.5 & 0.2 & 0.3 \\0.3 & 0.8 & 0.3 \\0.2 & 0   & 0.4\end{bmatrix}\nonumber\end{equation}</script><p>假设在起始年，三个党的得票情况为：<script type="math/tex">\mathbf{x}_0 = \begin{bmatrix}1\\ 0\\ 0 \end{bmatrix}</script>。那么我们顺着迁移矩阵看一下接下来几年，这个地区的选举情况会发生怎么样的变化。通过递推公式 <script type="math/tex">\mathbf{x}_{i+1} = \mathbf{P} \mathbf{x}_i</script> 我们可以计算出</p><script type="math/tex; mode=display">\begin{equation}\mathbf{x}_1 =  \begin{bmatrix} 0.5 \\ 0.3 \\ 0.2 \end{bmatrix}, \mathbf{x}_2 = \begin{bmatrix} 0.37 \\ 0.45 \\ 0.18 \end{bmatrix}, \mathbf{x}_3 =  \begin{bmatrix} 0.329 \\ 0.525 \\ 0.146 \end{bmatrix}, \cdots, \mathbf{x}_7 = \begin{bmatrix} 0.3016 \\ 0.5953 \\ 0.1031 \end{bmatrix}, \mathbf{x}_8 = \begin{bmatrix} 0.3008 \\ 0.5977 \\ 0.1016 \end{bmatrix}, \mathbf{x}_9 = \begin{bmatrix} 0.3004 \\ 0.5988 \\ 0.1008 \end{bmatrix} \cdots \nonumber\end{equation}</script><p>我们可以发现，这个选举结果向量 $\mathbf{x}$ 越来越逼近于向量 <script type="math/tex">\mathbf{q} = \begin{bmatrix}0.3\\ 0.6\\ 0.1\end{bmatrix}</script>。事实上，当我们把迁移矩阵乘上这个向量：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{P}\mathbf{q}=\begin{bmatrix}0.5 & 0.2 & 0.3 \\0.3 & 0.8 & 0.3 \\0.2 & 0   & 0.4\end{bmatrix}\begin{bmatrix} 0.3\\ 0.6\\ 0.1 \end{bmatrix}=\begin{bmatrix} 0.3\\ 0.6\\ 0.1 \end{bmatrix}= \mathbf{q}\end{equation}</script><p>就会发现，不但选举结果越来越趋向某一个固定向量 $\mathbf{q}$，而且当结果达到和 $\mathbf{q}$ 一致时，这个系统便不再改变！这也就是我们所说的达到<code>平稳分布</code>。这个固定向量 $\mathbf{q}$ 就是 <code>稳态向量</code>。</p><p>可以证明，这个<code>稳态向量</code>由<code>迁移矩阵</code>所控制。一个<code>马尔可夫链</code>中，<code>迁移矩阵</code>一旦确定，那么不管它的起始状态（$\mathbf{x}_0$）是什么样，它的<code>稳态</code>将唯一确定（有种宿命论的感觉）。这是<code>马尔可夫链</code>的一个重要性质，对于一个系统的长期发展很有帮助。此外，这个性质也反应了矩阵的两个重要属性：<code>特征值</code>与<code>特征向量</code>。</p><h1 id="二、特征值与特征向量"><a href="#二、特征值与特征向量" class="headerlink" title="二、特征值与特征向量"></a>二、特征值与特征向量</h1><p>当我们把一个矩阵看作是一个线性变换：$\mathbf{x} \mapsto \mathbf{A}\mathbf{x}$ 时，我们将矩阵理解成为一种运动，一种能使向量 $\mathbf{x}$ 向着向量 $\mathbf{A}\mathbf{x}$ 移动的“力”。一般来说，向量 $\mathbf{x}$ 经 $\mathbf{A}$ 进行变换有可能是朝着各个方向移动。然而，总有某些特殊向量，线性变换在这些向量上的作用是十分简单的。</p><p>比如：已知向量 <script type="math/tex">\mathbf{u}=\begin{bmatrix}-1\\ 1\end{bmatrix}, \mathbf{v}=\begin{bmatrix}2\\ 1\end{bmatrix}</script>，矩阵 <script type="math/tex">\mathbf{A} = \begin{bmatrix} 3 & -2 \\ 1 & 0 \end{bmatrix}</script> 表示的线性变换分别应用于（即矩阵左乘）向量 $\mathbf{u}$ 和 $\mathbf{v}$ 后的结果如下图所示：</p><img class title="线性变换应用于不同的向量" data-src="/2016/07/01/linear-algebra-6/eigenvector.png"><p>事实上，$\mathbf{A}\mathbf{v} = 2\mathbf{v}$，从图像上看就是拉伸了向量 $\mathbf{v}$。</p><p>更一般的，</p><blockquote><p>$\mathbf{A}$ 为 $n\times n$矩阵，$\mathbf{x}$为非零向量，若存在数 $\lambda$ 使得 $\mathbf{A}\mathbf{x}=\lambda\mathbf{x}$，则称 $\lambda$ 为矩阵 $\mathbf{A}$ 的特征值，$\mathbf{x}$ 为 $\mathbf{A}$ 对应于特征值 $\lambda$ 的特征向量。</p></blockquote><p>这就是我们其实已经很熟悉的<code>特征值</code>与<code>特征向量</code>定义了。<code>特征值</code>与<code>特征向量</code>的一个作用就是来研究线性变换中那些“特殊情况”，这些特殊情况可以看作是这个线性变换的“特征”。当我们把矩阵看作线性变换时，<code>特征值</code>与<code>特征向量</code>可以相配合作为描述这个线性变换的一个“特征”（有的文献也把<code>特征值</code>与<code>特征向量</code>称为<code>本征值</code>与<code>本征向量</code>）。</p><p>至于<code>特征值</code>和<code>特征向量</code>的求解，相信大家比较熟练了（建立特征方程 $(\mathbf{A}-\lambda\mathbf{I})\mathbf{x}=\mathbf{0}$ 进行求解），这里不再赘述。注意，一个特征方程所有解的集合构成了一个空间，即对于某一个<code>特征值</code>，它所对应的<code>特征向量</code>将构成一个空间，被称为 $\mathbf{A}$ 对应于 $\lambda$ 的<code>特征空间</code>，<code>特征空间</code>由零向量和所有对应于 $\lambda$ 的<code>特征向量</code>组成。</p><p>不同<code>特征值</code>对应的<code>特征向量</code>线性无关，而同一个<code>特征值</code>对应的不同<code>特征向量</code>能张成整个<code>特征空间</code>。如果一个<code>特征值</code>只对应一个<code>特征向量</code>，那么这个<code>特征值</code>对应的<code>特征空间</code>就是一条一维直线；而如果一个<code>特征值</code>对应两个<code>特征向量</code>，那么这个<code>特征值</code>对应的<code>特征空间</code>将是一个二维平面。</p><img class title="两个一维特征向量张成两个一维特征空间" data-src="/2016/07/01/linear-algebra-6/eigenspace.png"><p>由于 $\mathbf{A}\mathbf{x}=\lambda\mathbf{x}$，因而线性变换 $\mathbf{A}$ 对于<code>特征空间</code>只起到“扩张”的作用（扩张后还是同样的<code>特征空间</code>）。</p><img class title="特征空间的扩张" data-src="/2016/07/01/linear-algebra-6/span.png"><h1 id="三、特征向量与马尔可夫链"><a href="#三、特征向量与马尔可夫链" class="headerlink" title="三、特征向量与马尔可夫链"></a>三、特征向量与马尔可夫链</h1><p>我们已经知道 $\mathbf{x}_{i+1}=\mathbf{A}\mathbf{x}_k$，而如果我们找一个 $\mathbf{A}$ 的<code>特征值</code> $\lambda$ 及其对应的<code>特征向量</code> $\mathbf{x}_0$，则有</p><script type="math/tex; mode=display">\begin{equation}\mathbf{x}_1 = \mathbf{A}\mathbf{x}_0 = \lambda\mathbf{x}_0 \\\mathbf{x}_{i+1} = \mathbf{A}\mathbf{x}_i = \lambda\mathbf{x}_i = \lambda^i\mathbf{x}_0\end{equation}</script><p>因此，如果我们已经知道一个马尔可夫链的转移矩阵 $\mathbf{A}$，我们不需要看它的初始状态是什么，只要找 $\mathbf{A}$ 的<code>特征值</code> $\lambda$ 及其对应的<code>特征向量</code> $\mathbf{x}_0$，那么我们就能通过计算得到这个马尔可夫链达到稳态时的状态。</p><p>$\mathbf{x}<em>0$ 除了用一个<code>特征向量</code>外，也可以用多个<code>特征向量</code>的线性组合。比如 $\mathbf{A}$ 的<code>特征值</code>为 $\lambda_1, \lambda_2$，对应的两个<code>特征向量</code>为 <script type="math/tex">\mathbf{v}_1, \mathbf{v}_2</script>，那么我们可以用 <script type="math/tex">c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2</script> 来表示 <script type="math/tex">\mathbf{x}_0</script>。这样得到的 $$\mathbf{x}</em>{i+1}$$ 为：</p><script type="math/tex; mode=display">\begin{align}\mathbf{x}_1 &= \mathbf{A}\mathbf{x}_0 \nonumber\\&= c_1 \mathbf{A} \mathbf{v}_1 + c_2 \mathbf{A} \mathbf{v}_2 \\\mathbf{x}_{i+1} &= c_1 \mathbf{A}^i \mathbf{v}_1 + c_2 \mathbf{A}^i \mathbf{v}_2 \nonumber\\&= c_1 \lambda_1^i \mathbf{v}_1 + c_2 \lambda_2^i \mathbf{v}_2\end{align}</script><h2 id="3-1-人口迁移例子"><a href="#3-1-人口迁移例子" class="headerlink" title="3.1 人口迁移例子"></a>3.1 人口迁移例子</h2><p>回顾 <a href="/2016/06/22/linear-algebra-5/" title="上一章">上一章</a> 那个关于城市人口迁移的研究，那个例子我们引入了<code>马尔可夫链</code>这个概念，而从这章我们知道<code>马尔可夫链</code>有个<code>平稳分布</code>的性质，那么<a href="/2016/06/22/linear-algebra-5/" title="上一章">上一章</a>那个人口迁移的例子最终也一定会达到某种稳定状态，即城乡人口比例保持不变。</p><p><a href="/2016/06/22/linear-algebra-5/" title="上一章">上一章</a>中，我们已经得出：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{x}_0 = \mathbf{x}_{i+1} = \begin{bmatrix} c_{i+1} \\ r_{i+1} \end{bmatrix}= \begin{bmatrix} 0.95 & 0.03 \\ 0.05 & 0.97 \end{bmatrix}\begin{bmatrix} c_i \\ r_i \end{bmatrix}\end{equation}</script><p>即<code>迁移矩阵</code> <script type="math/tex">\mathbf{A} = \begin{bmatrix} 0.95 & 0.03\\ 0.05 & 0.97 \end{bmatrix}</script>。这次的套路是求解特征方程 $(\mathbf{A}-\lambda\mathbf{I})\mathbf{x}=0$（事实上，这里的2阶方阵通过计算行列式解 $\det\mathbf{A}=0$ 会更方便些。当然，手边有电脑的话直接交给 matlab、python 之类的就行 :D），得到特征值为 1 和 0.92，对应的特征向量分别为 <script type="math/tex">\mathbf{v}_1 = \begin{bmatrix} 3\\ 5 \end{bmatrix}</script> 和 <script type="math/tex">\mathbf{v}_2 = \begin{bmatrix} 1\\ -1 \end{bmatrix}</script> 的倍数。</p><p>由于有两个互不相等的特征值，我们可以知道它们对应的两个特征向量也线性无关，我们将初始向量 $\mathbf{x}_0$ 用两个特征向量的线性组合表示：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{x}_0 = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2= [\mathbf{v}_1 \mathbf{v}_2] \begin{bmatrix} c_1\\ c_2 \end{bmatrix}\end{equation}</script><p>假设我们已知 <script type="math/tex">\mathbf{x}_0 = \begin{bmatrix} 0.6\\ 0.4 \end{bmatrix}</script> （单位：百万人），那么就可以解得 $c_1 = 0.125, c_2 = 0.225$.</p><p>所以，每年的人口分布为：</p><script type="math/tex; mode=display">\begin{array}\mathbf{x}_{i+1} = \mathbf{A}\mathbf{x}_i = \mathbf{A}^i\mathbf{x}_0 &= c_1 \mathbf{A}^i \mathbf{v}_1 + c_2 \mathbf{A}^i \mathbf{v}_2 \\\nonumber&= c_1 \, 1^i \, \mathbf{v}_1 + c_2 \, 0.92^i \, \mathbf{v}_2\end{array}</script><p>随着 $i \rightarrow \infty$，$1^i = 1, 0.92^i \rightarrow 0$，所以 $x_i \rightarrow c_1 \mathbf{v}_1 = 0.125 \mathbf{v}_1$</p><p>这就显示了这个马尔可夫链最终总会达到<code>平稳分布</code>，达到<code>平稳分布</code>时的<code>稳态向量</code>就是 $0.125 \mathbf{v}_1$。这也印证了我们之前的观察：马尔可夫链达到<code>平稳分布</code>时，<code>稳态向量</code>与初始状态无关，只与<code>迁移矩阵</code>（特别是<code>迁移矩阵</code>的<code>特征向量</code>）有关。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这一章，我们通过<code>马尔可夫链</code>了解到了矩阵<code>特征值</code>与<code>特征向量</code>的概念。在本章中，我们把一个矩阵看作是一个线性变换，这个矩阵不断应用于某一个向量，使这个向量在空间中发生“运动”。而直观的讲，<code>特征值</code>与<code>特征向量</code>就是来描述这个“运动”的一个“本征”的，即在某些方向上的线性变换不会改变向量的方向。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><hr><ul><li>线性代数及其应用：第3版/（美）莱（Lay, D.C.）著；沈复兴等译. ——北京：人民邮电出版社，2007.7</li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/07/01/linear-algebra-6/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;a href=&quot;/2016/06/22/linear-algebra-5/&quot; title=&quot;上一章&quot;&gt;上一章&lt;/a&gt;最后，我们引入了`马尔可夫链`。`马尔可夫链`简单来说就是一个个状态组成的链，其中每个状态只于前一个状态有关。然而，除了这个简单定义之外，`马尔可夫链`还有一个有趣的性质：`平稳分布`。要解释`平稳分布`是什么，我们先从一个例子讲起。
    
    </summary>
    
    
      <category term="线性代数" scheme="http://mengqi92.github.io/categories/linear-algebra/"/>
    
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数拾遗" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8B%BE%E9%81%97/"/>
    
      <category term="线性代数" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>愿望思维</title>
    <link href="http://mengqi92.github.io/2016/06/23/wishful-thinking/"/>
    <id>http://mengqi92.github.io/2016/06/23/wishful-thinking/</id>
    <published>2016-06-23T15:32:58.000Z</published>
    <updated>2019-11-30T16:28:17.783Z</updated>
    
    <content type="html"><![CDATA[<p>这篇我们放下数学公式，来聊聊编程。“编程”这个概念如今在中国已经不再陌生，几乎各个高校都有自己的计算机学院，各种各样的培训班也是层出不穷。然而大家也都知道入门容易，精通很难。如果一个学习编程的人没能培养出这个领域所需要的良好思维习惯，而只是蜻蜓点水一般记住了一些基础的语法，概念，那么就很难对编程有更深入的理解。所以有必要介绍一些基本的，却容易被忽略的编程习惯。</p><h1 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h1><p>程序员的天敌是复杂度。从小的方面看，我们需要面对算法的复杂度，即如何用尽量少的开销实现一个计算过程；从大的方面看，我们需要面对系统的复杂度，即如何将一个现实中的复杂问题用各种计算模块相互搭配，组成一个系统来解决。如何控制软件开发中的复杂度，是计算机专业一直以来的热点话题。</p><p>总的来说，解决系统复杂度，我们有几个武器：抽象、模块化、解耦合等等，我们今天介绍同样好用的武器：愿望思维。</p><a id="more"></a><h1 id="愿望思维"><a href="#愿望思维" class="headerlink" title="愿望思维"></a>愿望思维</h1><img class data-src="/2016/06/23/wishful-thinking/puzzle.jpg"><blockquote><p>要把大象装冰箱，总共分几步？</p></blockquote><p>某年春晚小品里，宋丹丹提出了这个问题，最一开始听得时候我像小品里的赵本山一样也是摸不着头脑，这就好像我们拿到一个任务需求，对方提出了一个非常宏大的愿景，然而作为具体实现者的我们，却发现不知道从哪里开始。生活中的这种情况十分常见，尤其是当你还处在学习阶段，还不能达到熟练应用技能的地步，面对一个看起来十分复杂的问题，往往无从下手。这个时候我们不妨放轻松，先不去考虑具体实现细节，而是站在一定高度，把任务分解。</p><p>我们首先定义一个把大象装冰箱的函数，名字就叫做 <code>packaging</code>，接受两个参数：大象<code>elephant</code>和<code>冰箱</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">packaging</span><span class="params">(elephant, refridgerator)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">pass</span></span></pre></td></tr></table></figure><p>然后完全不考虑细节地把任务分解为三大步：</p><ol><li>把冰箱门打开</li><li>把大象装进去</li><li>把冰箱门带上</li></ol><p>于是，我们的函数变成了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">packaging</span><span class="params">(elephant, refridgerator)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    refridgerator.open()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    refridgerator.load(elephant)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    refridgerator.close()</span></pre></td></tr></table></figure><p>注意，里面的三个函数这时不需要定义，我们这里假设（“希望”）它们已经被定义并实现。至于这三个函数到底怎么实现、由谁实现，我们目前不需要关心。比如，<code>fridgerator.open()</code> 可能是未来的我或者是隔壁的小王来实现，我只要希望他能实现我想要的功能就行了。这样，解决整体问题的时候，我们只需要关心骨架，不必费心考虑怎么实现。而在考虑具体实现时（比如我开始实现 <code>fridgerator.open()</code>这个函数），我们的问题域已经缩小，我在实现 <code>fridgerator.open()</code> 的过程中不必考虑大象的存在，因此也就更能够专注，并有机会写出更为普适的代码（比如实现一个装载任意陆地动物的函数，而非只是装载大象）。</p><p>这就是“愿望思维”的核心。借助“愿望思维”，不仅能让我们从实现细节中解脱出来，从大局角度思考，还可以帮助我们写出良好结构的代码。在编码的过程中，因为有了问题域的划分，我们能比较专注，保持清晰的思路；而且在最后完成的代码中，骨架一目了然，具体实现划分清晰，可以说是高内聚，低耦合。</p><p>编程中的愿望思维和结构化思维比较类似。带着愿望写骨架代码，再接着考虑具体实现，这样很容易得到良好结构的代码。我这次所介绍的“愿望思维”，和“结构化”，“模块化”，还有麦肯锡的“金字塔原理”，殊途同归，讲的意思都差不多，我觉得不必细究它们名字上的差异。</p><h1 id="把握结构"><a href="#把握结构" class="headerlink" title="把握结构"></a>把握结构</h1><p>不止在编程中，我们在工作生活中也可以利用愿望思维解决问题。比如，写论文没思路，“七天憋出来六个字”，不妨先把大纲列出，先列一级标题，把握整个论文的结构，将一大块的文章分解为一章、一节。对于每一章、节，还可以进一步分解，为每一段定义一个中心话题。经过这样一番分解，我们得到了一个框架，接下来一个个地补全框架中的内容就是了。还有比如做一个 PPT，也是先写好一个“脚本”，定义好各个模块，然后再考虑各个模块的具体实现。这样下来，不仅能保证总体的思路清晰，而且原来的复杂任务得到分解，也方便分布到不同时间、空间完成（方便任务管理），同时还能在一定程度上保持上下文的一贯。</p><p>反过来，我们在观察一个已经实现的复杂系统时，也可以提纲挈领，从抽象的结构层来分析理解。比如看一本厚厚的经典书，一上手可能觉得恐惧，觉得自己看不完这么多东西。然而，如果我们先把它的结构提取出来，在大的宏观角度看它是怎么实现出来的，我们就可以先对这本书有一个大的骨架形式的印象（这时不必考虑细节，就好像我们已经把每一章都读过了一样）。然后，就可以根据我们自己的需求，摘取需要的章节阅读（在阅读这些章节的时候同样可以递归地进行提纲挈领，提高阅读效率和质量）。再比如，很多电影可以比较明显地看出导演实现整个电影时的结构设计，观看这种电影的乐趣不仅在于具体某一个桥段、场景、台词，也在于整个结构的巧妙安排（这方面一个著名的例子就是怪才昆汀塔仑蒂诺的电影《低俗小说》）。</p><h1 id="更多阅读："><a href="#更多阅读：" class="headerlink" title="更多阅读："></a>更多阅读：</h1><hr><ul><li><span class="exturl" data-url="aHR0cDovL3Job2Rlc21pbGwub3JnL2JyYW5kb24vc2xpZGVzLzIwMTQtMDctcHlvaGlvL2NsZWFuLWFyY2hpdGVjdHVyZS8=" title="http://rhodesmill.org/brandon/slides/2014-07-pyohio/clean-architecture/">The Clean Architecture in Python by Brandon Rhodes<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ib29rLmRvdWJhbi5jb20vc3ViamVjdC80ODgyMTIwLw==" title="https://book.douban.com/subject/4882120/">《金字塔原理》<i class="fa fa-external-link"></i></span></li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇我们放下数学公式，来聊聊编程。“编程”这个概念如今在中国已经不再陌生，几乎各个高校都有自己的计算机学院，各种各样的培训班也是层出不穷。然而大家也都知道入门容易，精通很难。如果一个学习编程的人没能培养出这个领域所需要的良好思维习惯，而只是蜻蜓点水一般记住了一些基础的语法，概念，那么就很难对编程有更深入的理解。所以有必要介绍一些基本的，却容易被忽略的编程习惯。&lt;/p&gt;
&lt;h1 id=&quot;复杂度&quot;&gt;&lt;a href=&quot;#复杂度&quot; class=&quot;headerlink&quot; title=&quot;复杂度&quot;&gt;&lt;/a&gt;复杂度&lt;/h1&gt;&lt;p&gt;程序员的天敌是复杂度。从小的方面看，我们需要面对算法的复杂度，即如何用尽量少的开销实现一个计算过程；从大的方面看，我们需要面对系统的复杂度，即如何将一个现实中的复杂问题用各种计算模块相互搭配，组成一个系统来解决。如何控制软件开发中的复杂度，是计算机专业一直以来的热点话题。&lt;/p&gt;
&lt;p&gt;总的来说，解决系统复杂度，我们有几个武器：抽象、模块化、解耦合等等，我们今天介绍同样好用的武器：愿望思维。&lt;/p&gt;
    
    </summary>
    
    
      <category term="编程" scheme="http://mengqi92.github.io/categories/programming/"/>
    
    
      <category term="编程" scheme="http://mengqi92.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="重构" scheme="http://mengqi92.github.io/tags/%E9%87%8D%E6%9E%84/"/>
    
      <category term="代码结构" scheme="http://mengqi92.github.io/tags/%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>线性代数拾遗（五）：矩阵变换的应用</title>
    <link href="http://mengqi92.github.io/2016/06/22/linear-algebra-5/"/>
    <id>http://mengqi92.github.io/2016/06/22/linear-algebra-5/</id>
    <published>2016-06-22T00:00:00.000Z</published>
    <updated>2019-11-30T16:28:17.779Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2016/06/22/linear-algebra-5/banner.jpeg"><a href="/2016/05/14/linear-algebra-2/" title="上一章">上一章</a>用了一个经济学的例子，介绍了现实中的线性方程组，那个例子里，我们借助矩阵“封装”的作用，将解三个方程组的问题转换为解$$\mathbf{A}\mathbf{x}=\mathbf{0}$$。而我们知道，矩阵不仅可以封装数据，还可以表示线性变换，那这一章就来介绍一下矩阵变换在现实生活中的应用。<a id="more"></a><h1 id="一、社会学例子"><a href="#一、社会学例子" class="headerlink" title="一、社会学例子"></a>一、社会学例子</h1><p>这个例子同样来自于《线性代数及其应用》这本书。</p><p>假如我们要研究一个城市的人口迁入、迁出的问题。用 $c_i$ 和 $r_i$ 分别表示第 $i$ 年该城市市区和郊区的人口数，$c_0$和$r_0$就是初始年（最开始进行观测的那一年）市区和郊区的人口数。再用 $\mathbf{x}_i$ 表示第 $i$ 年的人口向量：<script type="math/tex">\mathbf{x}_i = \begin{bmatrix}c_i \\ r_i \end{bmatrix}</script>。</p><p>设人口统计学研究表明，每年有 5% 的城市人口迁移到郊区（其余 95% 继续留在城市），有 3% 的郊区人口移居城市（其余 97% 继续留在郊区），如下图所示：</p><div class="diagram">    <div class="diagram-container">        <svg width="113pt" height="131pt" viewbox="0.00 0.00 112.60 131.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 127)"><title>城市人口迁移示意图</title><polygon fill="white" stroke="none" points="-4,4 -4,-127 108.595,-127 108.595,4 -4,4"/><!-- city --><g id="node1" class="node"><title>city</title><ellipse fill="none" stroke="black" cx="27.2976" cy="-105" rx="27.0966" ry="18"/><text text-anchor="middle" x="27.2976" y="-101.3" font-family="Times,serif" font-size="14.00">城区</text></g><!-- city&#45;&gt;city --><g id="edge2" class="edge"><title>city&#45;&gt;city</title><path fill="none" stroke="black" d="M51.9923,-112.752C63.0402,-113.49 72.5952,-110.906 72.5952,-105 72.5952,-101.032 68.2819,-98.5632 62.1005,-97.5944"/><polygon fill="black" stroke="black" points="62.1063,-94.0926 51.9923,-97.248 61.8665,-101.089 62.1063,-94.0926"/><text text-anchor="middle" x="88.5952" y="-101.3" font-family="Times,serif" font-size="14.00">95%</text></g><!-- rural --><g id="node2" class="node"><title>rural</title><ellipse fill="none" stroke="black" cx="27.2976" cy="-18" rx="27.0966" ry="18"/><text text-anchor="middle" x="27.2976" y="-14.3" font-family="Times,serif" font-size="14.00">郊区</text></g><!-- city&#45;&gt;rural --><g id="edge1" class="edge"><title>city&#45;&gt;rural</title><path fill="none" stroke="black" d="M14.9598,-88.5321C11.0767,-82.7456 7.28502,-75.8964 5.29758,-69 2.806,-60.3542 5.18287,-51.2494 9.16186,-43.2132"/><polygon fill="black" stroke="black" points="12.3156,-44.755 14.3731,-34.3619 6.28344,-41.2035 12.3156,-44.755"/><text text-anchor="middle" x="16.7976" y="-57.8" font-family="Times,serif" font-size="14.00">5%</text></g><!-- rural&#45;&gt;city --><g id="edge3" class="edge"><title>rural&#45;&gt;city</title><path fill="none" stroke="black" d="M27.9302,-36.1236C28.214,-45.7781 28.4538,-58.0614 28.2976,-69 28.2611,-71.5529 28.2097,-74.2101 28.1492,-76.8689"/><polygon fill="black" stroke="black" points="24.6493,-76.8231 27.8835,-86.9122 31.6469,-77.0083 24.6493,-76.8231"/><text text-anchor="middle" x="39.7976" y="-57.8" font-family="Times,serif" font-size="14.00">3%</text></g><!-- rural&#45;&gt;rural --><g id="edge4" class="edge"><title>rural&#45;&gt;rural</title><path fill="none" stroke="black" d="M51.9923,-25.752C63.0402,-26.4902 72.5952,-23.9062 72.5952,-18 72.5952,-14.0317 68.2819,-11.5632 62.1005,-10.5944"/><polygon fill="black" stroke="black" points="62.1063,-7.09262 51.9923,-10.248 61.8665,-14.0885 62.1063,-7.09262"/><text text-anchor="middle" x="88.5952" y="-14.3" font-family="Times,serif" font-size="14.00">97%</text></g></g></svg>    </div>    <p class="diagram-caption">城市人口迁移示意图</p></div><p>这个研究结果，用数学表示就是，第 $i$ 年的城区人口经过一年后，在城区和郊区的分布为：</p><script type="math/tex; mode=display">\begin{equation}\begin{bmatrix} 0.95\, c_i \\ 0.05\, c_i \end{bmatrix}\end{equation}</script><p>第 $i$ 年的郊区人口经过一年后，在城区和郊区的分布为：</p><script type="math/tex; mode=display">\begin{equation}\begin{bmatrix} 0.03\, r_i \\ 0.97\, r_i \end{bmatrix}\end{equation}</script><p>这时（第 $i+1$ 年），城区人口有来自一年前城区人口的 95%，以及一年前郊区人口的 3%；同样，郊区人口有来自一年前城区人口的 5%，以及一年前郊区人口的 97%。用向量表示就是，第 $i+1$ 年的城市人口分布：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{x}_{i+1} = \begin{bmatrix} c_{i+1} \\ r_{i+1} \end{bmatrix}= c_i \begin{bmatrix} 0.95 \\ 0.05 \end{bmatrix} + r_i \begin{bmatrix} 0.03 \\ 0.97 \end{bmatrix}= \begin{bmatrix} 0.95 & 0.03 \\ 0.05 & 0.97 \end{bmatrix}\begin{bmatrix} c_i \\ r_i \end{bmatrix}\end{equation}</script><p>也就是每年人口分布是由上一年人口分布左乘一个矩阵（这个矩阵表示线性变换）得到的，我们用 $\mathbf{M}$ 表示这个矩阵，就是：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{x}_{i+1} = \mathbf{M} \mathbf{x}_i\end{equation}</script><p>从这个例子，我们可以发现，当我们假设人口迁移的规律比较简单时（每一年的人口只与上一年人口有关，且是线性关系），人口的迁移就可以通过线性变换来表示。又由于矩阵可以表示一个线性变换，所以每一年的人口都可看作是上一年人口左乘一个变换矩阵（又叫<code>转移矩阵</code>）。</p><h1 id="二、马尔可夫链"><a href="#二、马尔可夫链" class="headerlink" title="二、马尔可夫链"></a>二、马尔可夫链</h1><p>有同学可能已经意识到了，这个例子实际上就是<code>马尔可夫链</code>嘛！对，这个就是马尔可夫链。</p><blockquote><p>（马尔可夫链）为状态空间中经过从一个状态到另一个状态的转换的随机过程。该过程要求具备 “无记忆” 的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。</p><footer><strong>中文维基百科/马尔可夫链</strong><cite><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3poLWNuL+mprOWwlOWPr+Wkq+mTvg==" title="https://zh.wikipedia.org/zh-cn/马尔可夫链">zh.wikipedia.org/zh-cn/马尔可夫链<i class="fa fa-external-link"></i></span></cite></footer></blockquote><p>在我们的例子里，城市每一年人口只与上一年人口有关，满足马尔可夫性质，所以人口的迁移可以看作是一个马尔可夫链。这个链中表示状态的节点就是 $\mathbf{x}_i$，节点中的转换关系就是<code>转移矩阵</code> $\mathbf{M}$。</p><p>这个例子展示了我们借助线性变换解决几何之外的问题时的思路：</p><ul><li>首先，在我们将每年的人口建模为一个二维向量 $\mathbf{x}_i$ 的时候，这个实际问题就已经转换到二维的空间中了。从这个空间的角度来看，每年人口的变化情况，就是二维向量不断变换的过程。</li><li>由于我们假设人口变化是一个线性变换（比如每年城区人口是上一年城区人口和郊区人口的线性组合），所以这个变换可以用矩阵来描述。</li><li>又因为我们进一步简化问题，任务每年的变化是稳定的，所以这个线性变换只需要一个矩阵就可以了。</li></ul><p>未来关于这个例子还会进一步展开，对<code>马尔可夫链</code>的平稳分布进行更深入的分析。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><hr><ul><li>线性代数及其应用：第3版/（美）莱（Lay, D.C.）著；沈复兴等译. ——北京：人民邮电出版社，2007.7</li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/06/22/linear-algebra-5/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;a href=&quot;/2016/05/14/linear-algebra-2/&quot; title=&quot;上一章&quot;&gt;上一章&lt;/a&gt;用了一个经济学的例子，介绍了现实中的线性方程组，那个例子里，我们借助矩阵“封装”的作用，将解三个方程组的问题转换为解$$\mathbf{A}\mathbf{x}=\mathbf{0}$$。而我们知道，矩阵不仅可以封装数据，还可以表示线性变换，那这一章就来介绍一下矩阵变换在现实生活中的应用。
    
    </summary>
    
    
      <category term="线性代数" scheme="http://mengqi92.github.io/categories/linear-algebra/"/>
    
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数拾遗" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8B%BE%E9%81%97/"/>
    
      <category term="线性代数" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>线性代数拾遗（四）：线性方程组的应用</title>
    <link href="http://mengqi92.github.io/2016/06/20/linear-algebra-4/"/>
    <id>http://mengqi92.github.io/2016/06/20/linear-algebra-4/</id>
    <published>2016-06-20T00:00:00.000Z</published>
    <updated>2019-11-30T16:28:17.779Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2016/06/20/linear-algebra-4/banner.jpeg"><p>由于这段时间科研任务较重，加上 hexo 升级后总出现一些奇怪的问题，所以有一段时间没更新这个系列了，今天忙里偷闲补上一篇。</p><p>前面几章，我们回顾了一遍线性方程组和矩阵的一些概念。线性代数的最原始问题是解线性方程组，为了解决这个问题，我们引入了向量和矩阵，继而对矩阵的一些特性也进行了一番分析，然后又发现矩阵不但可以表示数据，也可以表示变换。然而，这些概念是如何应用于现实生活呢，实际生活中有哪些线性方程组的例子？这一章我们来介绍一些线性代数的实际应用。</p><p>总体上来说，牵涉到多个变量的相互约束，而且这些约束是“线性”的问题时，就有可能通过建立线性方程组从而得到解。</p><h1 id="一、经济学例子"><a href="#一、经济学例子" class="headerlink" title="一、经济学例子"></a>一、经济学例子</h1><p>这是来自《线性代数及其应用》中的一个例子，很好地展示了线性代数在经济学中的应用：</p><p>比如一个国家包括煤炭、电力、钢铁三个部门，各部门都产出一定的资源，同时也消耗一定的资源（为方便讨论，本例中只考虑煤炭、电力、钢铁这三种资源，并且假设所有产出的资源都会被消耗）。比如，煤炭部门生产的每 100 份煤炭中，60 份被电力部门消耗，40 份被钢铁部门消耗；电力部门每生产 100 份煤炭，40 份被煤炭部门消耗，10 份被自己消耗，还有 50 份被钢铁部门消耗；钢铁部门每生产 100 份钢铁，60 份被煤炭部门消耗，20 份被电力部门消耗，还有 20 份被自己消耗。那么，如何给这三种资源定价，使得各部门的收支达到平衡？</p><a id="more"></a><p>首先，上面所述的各部门产出与消耗情况可以用一个表格来表示：</p><div class="table-container"><table><thead><tr><th style="text-align:right"></th><th style="text-align:center">煤炭产出</th><th style="text-align:center">电力产出</th><th style="text-align:center">钢铁产出</th></tr></thead><tbody><tr><td style="text-align:right">煤炭部门的消耗</td><td style="text-align:center">0</td><td style="text-align:center">0.4</td><td style="text-align:center">0.6</td></tr><tr><td style="text-align:right">电力部门的消耗</td><td style="text-align:center">0.6</td><td style="text-align:center">0.1</td><td style="text-align:center">0.2</td></tr><tr><td style="text-align:right">钢铁部门的消耗</td><td style="text-align:center">0.4</td><td style="text-align:center">0.5</td><td style="text-align:center">0.2</td></tr></tbody></table></div><p>表中每一行表示某部们消耗各资源的情况，各列表示某资源被各部门消耗的情况。例如，煤炭部门每生产 1 单位的煤炭，就有 0.6 单位被电力部门消耗，0.4 单位被钢铁部门消耗；同时，煤炭部门也会消耗 0.4 单位的电力和 0.6 单位的钢铁来保证生产。</p><p>当然我们可以考虑用向量来表示这个表格。将表格中的各行<code>向量化</code>，得到：</p><p>\begin{align}<br>O_c &amp;= [0, 0.4, 0.6] \<br>O_e &amp;= [0.6, 0.1, 0.2] \<br>O_s &amp;= [0.4, 0.5, 0.2]<br>\end{align}</p><p>其中，$O_c$, $O_e$, $O_s$ 分别表示煤炭、电力、钢铁各个部门消耗三种资源的量。</p><p>各种资源的单位价格也可以用符号定义。例如用 $p_c$, $p_e$, $p_s$ 分别来表示煤炭、电力、钢铁三种资源的价格，那么煤炭部门的总支出就是 <script type="math/tex">0 \cdot p_c+0.4 p_e+0.6 p_s = O_c \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix}</script>. 同理，电力部门和钢铁部门的总支出是 <script type="math/tex">O_e \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix}, O_s \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix}</script>. </p><p>也就是说，煤炭部门每生产出 1 单位价值为 $p_c$ 的煤炭，它就需要消耗价值为 $O_c \cdot \begin{bmatrix}p_c\ p_e\ p_s\end{bmatrix}$ 的资源。要使煤炭部门收支平衡，就需要：</p><script type="math/tex; mode=display">\begin{equation}O_c \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} = p_c\end{equation}</script><p>同理，要使三个部门都达到收支平衡，需要：</p><script type="math/tex; mode=display">\begin{align}O_c \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= [0  , 0.4, 0.6] \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= p_c \\O_e \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= [0.6, 0.1, 0.2] \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= p_e \\O_s \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= [0.4, 0.5, 0.2] \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= p_s\end{align}</script><p>借助矩阵的封装，我们可以把这三个式子合并为一个式子：</p><script type="math/tex; mode=display">\begin{eqnarray}\mathbf{A} \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} \\\left( \mathbf{A} - \mathbf{I} \right) \cdot \begin{bmatrix}p_c\\ p_e\\ p_s\end{bmatrix} &= \begin{bmatrix}0\\ 0\\ 0\end{bmatrix} \label{homogeneous}\\\end{eqnarray}</script><p>其中，3 x 3 矩阵 $\mathbf{A}$ 就是上面的那个表格。</p><p>式子 $\eqref{homogeneous}$ 是我们熟悉的齐次线性方程组的形式。按照套路，我们化简增广矩阵：</p><script type="math/tex; mode=display">\begin{equation}\begin{bmatrix}-1 & 0.4 & 0.6 & 0 \\0.6 & -0.9 & 0.2 & 0 \\0.4 & 0.5 & -0.8 & 0\end{bmatrix}\sim\begin{bmatrix}1 & -0.4 & -0.6 & 0 \\0 & 1 & -0.85 & 0 \\0 & 0 & 0 & 0\end{bmatrix}\sim\begin{bmatrix}1 & 0 & -0.94 & 0 \\0 & 1 & -0.85 & 0 \\0 & 0 & 0 & 0\end{bmatrix}\end{equation}</script><p>由此得到通解：$p_c = 0.94 p_s$, $p_e = 0.85 p_s$，$p_s$ 为自由变量。</p><p>所以，各部门达到收支平衡时的平衡价格向量为：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{p} = p_s\begin{bmatrix}0.94 \\0.85 \\1\end{bmatrix}\end{equation}</script><p>也就是说，如果钢铁价格为100元，那么煤炭和电的价格分别为94元和和85元时，整个经济系统可以达到平衡。</p><h1 id="二、总结"><a href="#二、总结" class="headerlink" title="二、总结"></a>二、总结</h1><p>从上面的例子，我们可以发现：</p><ul><li>当一个系统中各个部分之间存在<strong>线性约束</strong>时（例如化学方程式的配平，各元素之间相互存在约束关系），就有可能借助线性方程组来建模。</li><li>当一个问题描述的是一张简单的表格时，我们可以将其<code>向量化</code>为一系列向量，或是一个矩阵，进而进行“批量”计算。</li></ul><p>这里，我们再次发现了矩阵“封装”计算的特点。借助<code>向量化</code>和<code>矩阵化</code>，我们可以将传统的数学问题转化为线性代数问题（如本文的例子就转化为了齐次线性方程组）。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><hr><ul><li>线性代数及其应用：第3版/（美）莱（Lay, D.C.）著；沈复兴等译. ——北京：人民邮电出版社，2007.7</li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/06/20/linear-algebra-4/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;p&gt;由于这段时间科研任务较重，加上 hexo 升级后总出现一些奇怪的问题，所以有一段时间没更新这个系列了，今天忙里偷闲补上一篇。&lt;/p&gt;
&lt;p&gt;前面几章，我们回顾了一遍线性方程组和矩阵的一些概念。线性代数的最原始问题是解线性方程组，为了解决这个问题，我们引入了向量和矩阵，继而对矩阵的一些特性也进行了一番分析，然后又发现矩阵不但可以表示数据，也可以表示变换。然而，这些概念是如何应用于现实生活呢，实际生活中有哪些线性方程组的例子？这一章我们来介绍一些线性代数的实际应用。&lt;/p&gt;
&lt;p&gt;总体上来说，牵涉到多个变量的相互约束，而且这些约束是“线性”的问题时，就有可能通过建立线性方程组从而得到解。&lt;/p&gt;
&lt;h1 id=&quot;一、经济学例子&quot;&gt;&lt;a href=&quot;#一、经济学例子&quot; class=&quot;headerlink&quot; title=&quot;一、经济学例子&quot;&gt;&lt;/a&gt;一、经济学例子&lt;/h1&gt;&lt;p&gt;这是来自《线性代数及其应用》中的一个例子，很好地展示了线性代数在经济学中的应用：&lt;/p&gt;
&lt;p&gt;比如一个国家包括煤炭、电力、钢铁三个部门，各部门都产出一定的资源，同时也消耗一定的资源（为方便讨论，本例中只考虑煤炭、电力、钢铁这三种资源，并且假设所有产出的资源都会被消耗）。比如，煤炭部门生产的每 100 份煤炭中，60 份被电力部门消耗，40 份被钢铁部门消耗；电力部门每生产 100 份煤炭，40 份被煤炭部门消耗，10 份被自己消耗，还有 50 份被钢铁部门消耗；钢铁部门每生产 100 份钢铁，60 份被煤炭部门消耗，20 份被电力部门消耗，还有 20 份被自己消耗。那么，如何给这三种资源定价，使得各部门的收支达到平衡？&lt;/p&gt;
    
    </summary>
    
    
      <category term="线性代数" scheme="http://mengqi92.github.io/categories/linear-algebra/"/>
    
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数拾遗" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8B%BE%E9%81%97/"/>
    
      <category term="线性代数" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>线性代数拾遗（三）：线性变换以及矩阵的意义</title>
    <link href="http://mengqi92.github.io/2016/05/20/linear-algebra-3/"/>
    <id>http://mengqi92.github.io/2016/05/20/linear-algebra-3/</id>
    <published>2016-05-20T21:11:00.000Z</published>
    <updated>2019-11-30T16:28:17.775Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2016/05/20/linear-algebra-3/banner.jpeg"><a href="/2016/05/14/linear-algebra-2/" title="上一章">上一章</a>我们讨论了齐次和非齐次两种线性方程组的解集，以及它们的几何意义。由齐次线性方程组，我们引入了零空间的概念；而由非齐次线性方程组，我们引入了列空间的概念。这两个空间目前是我们理解线性方程组的桥梁，未来还会对这些空间进行更进一步的讨论。在这之前，让我们先来研究一下矩阵的意义。 之前的两章中，矩阵是在矩阵方程中出现的，当时我们理解它的意义为“对向量的一种封装”，也就是一种“数据”的形式理解矩阵的。这一章，我们引入矩阵的另一层意义：`线性变换`。<a id="more"></a><h1 id="一、变换"><a href="#一、变换" class="headerlink" title="一、变换"></a>一、变换</h1><p>假如有如 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 形式的方程：</p><script type="math/tex; mode=display">\begin{bmatrix}4 & -3 & 1 & 3 \\2 & 0 & 5 & 1\end{bmatrix}\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}=\begin{bmatrix} 5 \\ 8 \end{bmatrix}</script><p>以往我们都是将其看成是几个列向量的线性组合，即<script type="math/tex">1\begin{bmatrix}4 \\ 2\end{bmatrix} + 1\begin{bmatrix}-3 \\ 0\end{bmatrix} + 1\begin{bmatrix}1 \\ 5\end{bmatrix} + 1\begin{bmatrix}3 \\ 1\end{bmatrix} = \begin{bmatrix} 5 \\ 8 \end{bmatrix}</script>，这次我们换个角度，把 $\mathbf{A}$ 看作一个整体，整个方程就是一个 4 维向量 $\mathbf{x}$ 乘以矩阵 $\mathbf{A}$ 后得到一个 2 维向量 $\mathbf{b}$。 以这个观点来看的话，<strong>矩阵 $\mathbf{A}$ 就相当于一个从一个向量集映射到另一个向量集的函数！</strong>。</p><p>假设 $\mathbf{x}$ 是 $n$ 维向量，$\mathbf{b}$ 是 $m$ 维向量，则 $\mathbf{A}$ 就是一个 $R^n$ 到 $R^m$ 的变换。这个变换的<code>定义域</code>是 $R^n$，<code>上域</code>是 $R^m$，记作 $T: R^n \rightarrow R^m$。$\mathbf{x}$ 是 $R^n$ 空间中的一个向量，$T(\mathbf{x})$ 就是其变换到 $R^m$ 空间中的<code>像</code>，而全体<code>像</code> $T(\mathbf{x})$ 的集合就称为变换 $T$ 的<code>值域</code>。图示如下：</p><img class title="变换$T$" data-src="/2016/05/20/linear-algebra-3/linear-transformation.png"><p>从这种观点来看，矩阵就是一个函数：$\mathbf{x}\mapsto\mathbf{A}{x}$！矩阵既可看作是数据的表示，又可看作是表示变换的函数，这不禁让我联想起了 lisp 里的“同像性”，也就是“代码即数据”。我不知道他们之间有没有更深一层的联系，不过从这一层面再来看矩阵，感觉又多了一层趣味……</p><p>除此之外，以动态的眼光来看待矩阵，也有助于我们理解为什么一些随时间变化的系统可以用线性代数来建模。比如马尔科夫链中的转移矩阵，就是用静态的矩阵来表示一个变换的过程。</p><p>不难发现，当变换 $T$ 为 $\mathbf{x}\mapsto\mathbf{A}\mathbf{x}$ ，向量 $\mathbf{x}$ 若有 n 维，则变换的定义域就是 $R^n$，$\mathbf{A}$ 就有 n 列；向量 $\mathbf{b}$  若有 m 维，则变换的上域就是 $R^m$，$\mathbf{A}$ 就有 m 行（$\mathbf{A}$ 每一列有 m 个元素）。而变换的值域就是 $\mathbf{A}$ 中列的所有线性组合组成的集合。</p><p>也就是说，像 <script type="math/tex">\begin{bmatrix}1 & -3 \\ 3 & 5 \\ -1 & 7\end{bmatrix}</script>这样的矩阵，所表达的变换就是一个二维到三维的映射 $T:R^2\rightarrow R^3$。</p><p>再例如，矩阵<script type="math/tex">\begin{bmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0\end{bmatrix}</script> 所表达的变换就是一个投影：把 $R^3$ 中的点投影到 $x_1 x_2$平面，因为：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 0\end{bmatrix}\begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}=\begin{bmatrix} x_1 \\ x_2 \\ 0 \end{bmatrix}</script><h1 id="二、线性变换"><a href="#二、线性变换" class="headerlink" title="二、线性变换"></a>二、线性变换</h1><p>线性变换是一类满足线性条件的变换。所谓的线性条件就是：</p><script type="math/tex; mode=display">T(\mathbf{u}+\mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v}) \\ \text{和}\\ T(c \mathbf{u}) = c T(\mathbf{u})</script><p>注意到，向量的加法和数乘运算在变换前和变换后的效果是一样的，也就是所谓的线性变换<em>保持了</em>向量的加法和数乘运算。</p><p>我们假设有一个二维向量 $\mathbf{x}=\begin{bmatrix}x_1\ x_2 \end{bmatrix}= x_1 \mathbf{e}_1 + x_2 \mathbf{e}_2$，其中 <script type="math/tex">\mathbf{e}_1=\begin{bmatrix}1\\ 0\end{bmatrix}, \mathbf{e}_2=\begin{bmatrix}0\\ 1\end{bmatrix}</script> 是 2$\times$ 2 单位矩阵 $\mathbf{I}_n$ 的列向量。由于线性变换保持加法和数乘运算，所以</p><script type="math/tex; mode=display">\begin{equation}T(\mathbf{x})=x_1 T(\mathbf{e}_1) + x_2 T(\mathbf{e}_2) = \begin{bmatrix}T(\mathbf{e}_1) & T(\mathbf{e}_2)\end{bmatrix} \begin{bmatrix} x_1\\ x_2 \end{bmatrix} = \mathbf{A}\mathbf{x} \nonumber\end{equation}</script><p>这也就是说，对于每一个线性变换$T: R^n \rightarrow R^m$，都有唯一一个矩阵 $\mathbf{A}$，使得 $T(\mathbf{x})=\mathbf{A}\mathbf{x}$，其中 $ \mathbf{A} = [ T(\mathbf{e}_1) \cdots T(\mathbf{e}_1) ] $。$ \mathbf{A} $ 被称为是线性变换 $T$ 的<code>标准矩阵</code>。</p><p>总结一下，线性变换是满足线性条件的变换，所谓线性条件就要求变换前后的加法和数乘运算不变（变换前 a+b 等于 c，则变换后 a’+b’ 也等于 c’）。 线性变换有两种描述形式：$T:R^n \rightarrow R^m$ 和 $ \mathbf{x} \mapsto \mathbf{A}\mathbf{x} $，后者也被称为<code>矩阵变换</code></p><blockquote><p>线性变换强调它作为映射的性质，而矩阵变换则描述了映射是怎样实现的。</p></blockquote><h1 id="三、几何中的线性变换"><a href="#三、几何中的线性变换" class="headerlink" title="三、几何中的线性变换"></a>三、几何中的线性变换</h1><p>借助上面线性变换的性质，我们就很容易理解图形学中一些专门用于变换的矩阵了，比如 2 维平面上的旋转矩阵：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{A}=\begin{bmatrix}\cos\varphi & -\sin\varphi \\\sin\varphi & \cos\varphi\end{bmatrix} \nonumber\end{equation}</script><p>把它的列向量拆开，就是 <script type="math/tex">T(\mathbf{e}_1) = \begin{bmatrix}\cos\varphi \\ \sin\varphi \end{bmatrix}</script>，<script type="math/tex">T(\mathbf{e}_2) = \begin{bmatrix}-\sin\varphi \\ \cos\varphi \end{bmatrix}</script>也就是 <script type="math/tex">\begin{bmatrix}1\\ 0\end{bmatrix}</script> 旋转到 <script type="math/tex">\begin{bmatrix}\cos\varphi \\ \sin\varphi\end{bmatrix}</script> ，<script type="math/tex">\begin{bmatrix}0\\ 1\end{bmatrix}</script> 旋转到 <script type="math/tex">\begin{bmatrix}-\sin\varphi \\ \cos\varphi\end{bmatrix}</script> 。</p><p>旋转变换如下图所示：</p><img class title="旋转变换" data-src="/2016/05/20/linear-algebra-3/rotation.png"><h1 id="四、存在性和唯一性问题"><a href="#四、存在性和唯一性问题" class="headerlink" title="四、存在性和唯一性问题"></a>四、存在性和唯一性问题</h1><p>有了线性变换的概念，我们再来回顾之前两章讨论的解的存在性和唯一性的问题。</p><h2 id="4-1-解的存在性"><a href="#4-1-解的存在性" class="headerlink" title="4.1 解的存在性"></a>4.1 解的存在性</h2><p>非线性方程组 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 可以看做是一个 $ \mathbf{x} $ 所在空间到 $ \mathbf{b} $ 所在空间的映射。<br>对映射 $T=R^n\rightarrow R^m$ ，如果 $R^n$ 中任意向量 $\mathbf{b}$ 都是 $R^n$ 中至少一个 $\mathbf{x}$ 的像，则称 $T$ 是 $R^n$ 到 $R^m$ 上的映射（或叫<code>满射</code>），这时，非线性方程组对于任意的 $ \mathbf{b} $ 都有解。反过来，如果存在 $ \mathbf{b} $ 使得非线性方程组无解，那么 $T$ 就不是 $R^n$ 到 $R^m$ 上的满射。它们的几何表示如下图所示：</p><img class title="满射" data-src="/2016/05/20/linear-algebra-3/existence.png"><h2 id="4-2-解的唯一性"><a href="#4-2-解的唯一性" class="headerlink" title="4.2 解的唯一性"></a>4.2 解的唯一性</h2><p>如果任意的 $ \mathbf{b}\in R^m $ 都是 $R^n$ 中最多一个向量 $ \mathbf{x} $ 的像，那么就称 $T$ 是<code>一对一映射</code>。</p><p>一对一映射也就是非线性方程组 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 对任意 $ \mathbf{b} $ 要么无解，要么有唯一解。也就是说，当 方程 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 有无穷多解时（即方程含有自由变量，即不满秩，即各列线性相关） ，$T$ 就不是一对一映射，这时齐次方程组 $\mathbf{A}\mathbf{x}=\mathbf{0}$ 只有平凡解。</p><img class title="一对一映射" data-src="/2016/05/20/linear-algebra-3/uniqueness.png"><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h1><hr><ul><li>线性代数及其应用：第3版/（美）莱（Lay, D.C.）著；沈复兴等译. ——北京：人民邮电出版社，2007.7</li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/05/20/linear-algebra-3/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;a href=&quot;/2016/05/14/linear-algebra-2/&quot; title=&quot;上一章&quot;&gt;上一章&lt;/a&gt;我们讨论了齐次和非齐次两种线性方程组的解集，以及它们的几何意义。由齐次线性方程组，我们引入了零空间的概念；而由非齐次线性方程组，我们引入了列空间的概念。这两个空间目前是我们理解线性方程组的桥梁，未来还会对这些空间进行更进一步的讨论。在这之前，让我们先来研究一下矩阵的意义。 

之前的两章中，矩阵是在矩阵方程中出现的，当时我们理解它的意义为“对向量的一种封装”，也就是一种“数据”的形式理解矩阵的。这一章，我们引入矩阵的另一层意义：`线性变换`。
    
    </summary>
    
    
      <category term="线性代数" scheme="http://mengqi92.github.io/categories/linear-algebra/"/>
    
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数拾遗" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8B%BE%E9%81%97/"/>
    
      <category term="线性代数" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>线性代数拾遗（二）：线性方程组的解集及其几何意义</title>
    <link href="http://mengqi92.github.io/2016/05/14/linear-algebra-2/"/>
    <id>http://mengqi92.github.io/2016/05/14/linear-algebra-2/</id>
    <published>2016-05-14T00:00:00.000Z</published>
    <updated>2019-11-30T16:28:17.775Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2016/05/14/linear-algebra-2/banner.jpeg"><a href="/2016/05/03/linear-algebra-1/" title="上一章">上一章</a>我们讲到三种等价形式：线性方程组、向量方程和矩阵方程。由于这三者之间的等价关系，我们解决现实问题时可以自由选取其中任意一个作为模型。我个人认为，线性方程组是最“质朴”的形式；向量方程则是与几何建立了关系，这将方便我们进行更直观的推理；矩阵方程则是向量方程的一种“封装”，是向量方程的一种抽象，它将具体的向量形式隐藏，提供给我们一个简洁的 API 形式——矩阵。未来将要介绍的很多概念就是基于对这一层封装的研究，如果到时候我们发现某个概念理解有困难，不妨转换思路到向量方程或线性方程组的形式进行分析。此外，我们之前还进行了关于线性方程组解集的讨论，在这章我们对其进一步探讨。<a id="more"></a><h1 id="一、齐次线性方程组"><a href="#一、齐次线性方程组" class="headerlink" title="一、齐次线性方程组"></a>一、齐次线性方程组</h1><p>形如 $\mathbf{A}\mathbf{x}=\mathbf{0}$ 的线性方程组称为<code>齐次方程组</code>。显然，$\mathbf{x}=\mathbf{0}$ 是方程的解，这个解太平凡了，以致于就叫<code>平凡解</code>。我们平常更关心的是它还有没有别的解，即<code>非平凡解</code>。下面以一个例子分析一下：</p><p>例：判断下列齐次方程组是否有非平凡解，表示其解集。</p><script type="math/tex; mode=display">\begin{array}3x_1 &+& 5x_2 &-& 4x_3 &= 0 \\-3x_1 &-& 2x_2 &+& 4x_3 &= 0 \\6x_1 &+& x_2 &-& 8x_3 &= 0\end{array}</script><p>对于这类求解集的问题，我们可以直接对增广矩阵化简，得到</p><script type="math/tex; mode=display">\begin{equation*}[\mathbf{A}\ \mathbf{0}] \sim\begin{bmatrix}3 & 5 & -4 & 0 \\-3 & -2 & 4 & 0 \\6 & 1 & -8 & 0\end{bmatrix}\sim\begin{bmatrix}3 & 5 & -4 & 0 \\0 & 3 & 0 & 0 \\0 & 0 & 0 & 0\end{bmatrix}\sim\begin{bmatrix}1 & 0 & -\frac{4}{3} & 0 \\0 & 1 & 0 & 0 \\0 & 0 & 0 & 0\end{bmatrix}\end{equation*}</script><p>从最后的行最简形式，我们可以得到解：<script type="math/tex">x_1 = \frac{4}{3} x_3, x_2 =0</script>，其中 $x_3$ 是自由变量。所以 $\mathbf{x}$ 的通解就是 <script type="math/tex">\mathbf{x} = \begin{bmatrix}x_1\\ x_2\\ x_3\end{bmatrix} = x_3\begin{bmatrix}\frac{4}{3}\\ 0\\ 1\end{bmatrix} = x_3\mathbf{v}</script>。也就是说，$\mathbf{A}\mathbf{x}=\mathbf{0}$ 的解是三维空间（因为向量 $\mathbf{v}$ 是三维的）中的一条直线（因为只有一个自由变量）。进一步推广，我们不难想象，如果解集中有 $p$ 个自由变量，则解集就是 $m$ 维空间（$m$ 为 $\mathbf{A}$ 的行数）中，$p$ 个向量张成的空间。<strong>如果没有自由变量（也就是 $\mathbf{A}$ 各列线性无关），那么就有 0 个向量张成的空间，即 $\operatorname{Span}{\mathbf{0}}$，$\mathbf{A}\mathbf{x}=\mathbf{0}$ 也就只有平凡解。</strong></p><h1 id="二、非齐次线性方程组"><a href="#二、非齐次线性方程组" class="headerlink" title="二、非齐次线性方程组"></a>二、非齐次线性方程组</h1><p><code>非齐次线性方程组</code>形如 $\mathbf{A}\mathbf{x}=\mathbf{b}$，<br>为了方便对比，我们把上面那个例子改为一个非齐次方程组进行分析：</p><script type="math/tex; mode=display">\begin{array}3x_1 &+& 5x_2 &-& 4x_3 &=& 7 \\-3x_1 &-& 2x_2 &+& 4x_3 &=& -1 \\ 6x_1 &+& x_2 &-& 8x_3 &=& -4 \end{array}</script><p>老套路，我们对这个方程组的增广矩阵行化简：</p><script type="math/tex; mode=display">\begin{bmatrix}3 & 5 & -4 & 7 \\-3 & -2 & 4 & -1 \\6 & 1 & -8 & -4\end{bmatrix}\sim\begin{bmatrix}3 & 5 & -4 & 7 \\0 & 1 & 0 & 2 \\0 & 0 & 0 & 0\end{bmatrix}\sim\begin{bmatrix}1 & 0 & -\frac{4}{3} & -1 \\0 & 1 & 0 & 2 \\0 & 0 & 0 & 0\end{bmatrix}</script><p>化简后可以得到方程组的解为：<script type="math/tex">x_1 = -1 + \frac{4}{3}x_3，x_2 = 2</script>，其中 $x_3$ 是自由变量。<br>我们把这个解集用向量的形式表示出来就是：</p><script type="math/tex; mode=display">\begin{equation*}\mathbf{x} = \begin{bmatrix}x_1\\ x_2\\ x_3\end{bmatrix}= \begin{bmatrix}-1+\frac{4}{3}x_3\\ 2\\ x_3\end{bmatrix}= \begin{bmatrix}-1\\ 2\\ 0\end{bmatrix} + x_3 \begin{bmatrix}\frac{4}{3}\\ 0\\ 1\end{bmatrix}\end{equation*}</script><p>注意到这个向量可分解为一个常数向量<script type="math/tex">\begin{bmatrix}-1\\ 2\\ 0\end{bmatrix}</script>和一个可任意伸缩的向量<script type="math/tex">x_3\begin{bmatrix}\frac{4}{3}\\ 0\\ 1\end{bmatrix}</script>，而且，常数向量就是行化简后矩阵的最后一列，而 <script type="math/tex">\begin{bmatrix}\frac{4}{3}\\ 0\\ 1\end{bmatrix}</script> 同样是齐次方程组的解。这是因为非齐次方程组只是最后一列由$\mathbf{0}$换成了$\mathbf{b}$，而且最后一列不会影响前面三列，所以齐次和非齐次方程组行化简后，变量的对应系数是相同的（系数矩阵就是前三列），<strong>非齐次方程组的解仅仅只比齐次方程组的解多了一个常数向量</strong>。例如齐次方程组的解集为$\mathbf{x}=t\mathbf{v}$，则非齐次方程组的解集就是 $\mathbf{x}=\mathbf{p}+t\mathbf{v}$，其中 $t$ 为任意实数。从几何的角度来看，就是<strong>齐次方程组的解集经向量 $\mathbf{p}$ 平移得到非齐次方程组的解集</strong>。这个 $\mathbf{p}$ 的学名就叫做<code>特解</code>。</p><p>注意，这里讲齐次方程组和非齐次方程组的解有一个前提，就是非齐次方程组首先要是有解的，如果$\mathbf{0}$变成$\mathbf{b}$ 导致方程组没有解，那么也就不能用齐次方程组的解集平移了。</p><p>结合之前总结的齐次线性方程组解的性质，当方程组含有 $p$ 个自由变量时，齐次方程组的解集是 $p$ 个向量的张成空间，而非齐次方程组解集只是这个空间进行了平移（前提是非齐次方程组有解），并没有改变这个空间的基本性质（比如空间的维度）。</p><h1 id="三、列空间"><a href="#三、列空间" class="headerlink" title="三、列空间"></a>三、列空间</h1><p>矩阵<script type="math/tex">\mathbf{A} = [\mathbf{a_1} \mathbf{a_2} \cdots \mathbf{a_n}]</script>的各个列向量线性组合组成的集合，就是$\mathbf{A}$的列空间。记作 $\operatorname{Col}\mathbf{A}$，即</p><script type="math/tex; mode=display">\begin{equation*}\operatorname{Col} \mathbf{A} = \operatorname{Span}\{\mathbf{a_1}, \mathbf{a_2}, \cdots, \mathbf{a_n}\}\end{equation*}</script><p>这个列空间，我们应该不陌生了，上一章中很多时候都是把矩阵看成列向量的排列，考虑 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 的解的情况时其实就是在列向量中进行分析的。列空间在分析矩阵中各列向量的线性相关性时很有帮助：只有各列线性无关时，这 $n$ 个列才能张成 $n$ 维空间，这时就说这个矩阵的秩为 $n$；而假如这里面有 1 列和其他某列线性相关，那么这 $n$ 个列就只能张成 $n-1$ 维空间，这个矩阵的秩就是 $n-1$；也就是说，<strong>矩阵的秩说明了这个矩阵的列向量最多能张成多少维</strong>。</p><p>如下图中，$\mathbf{A} = [\mathbf{a_1}\ \mathbf{a_2}\ \mathbf{a_3}]$，由于有两个向量线性相关，导致 3 个列向量只能张成 2 维，因此 $\mathbf{A}$ 的秩为 2。所以 $\mathbf{A}\mathbf{x}$ 得不到任意三维向量 $\mathbf{b}$，也就是 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 并不对所有 $\mathbf{b}$ 成立（只有$\mathbf{b}$ 是 $\mathbf{A}$ 列空间中的向量时才成立）。</p><img class title="秩小于n的情况" data-src="/2016/05/14/linear-algebra-2/r_less_than_n.png"><p>更进一步，非齐次线性方程组 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 中，如果 $\mathbf{A}$已知，$\mathbf{x}$和$\mathbf{b}$ 未知，此时我们关注的问题是 $\mathbf{A}$ 的列向量能张成多少维；如果 $\mathbf{A}$ 和 $\mathbf{b}$ 已知，我们关注的问题就是 $\mathbf{A}$ 中 $n$ 个列向量如何线性表示能表示成 $\mathbf{b}$，这时候我们如果提前知道 $\mathbf{A}$ 的列空间达不到 $\mathbf{b}$ 的维数，那么这些列向量就一定无法线性组合出 $\mathbf{b}$。</p><h1 id="四、零空间"><a href="#四、零空间" class="headerlink" title="四、零空间"></a>四、零空间</h1><p>齐次方程 $\mathbf{A}\mathbf{x}=\mathbf{0}$ 的全部解组成的集合，称为矩阵 $\mathbf{A}$ 的零空间，记作 $\operatorname{Nul} \mathbf{A}$。</p><p>当 $\mathbf{A}$ 中的列向量线性无关时，$\mathbf{A}\mathbf{x}=\mathbf{0}$ 只有零解，这时 $\mathbf{A}$ 的零空间就是 $\mathbf{0}$；而只要 $\mathbf{A}$ 中的列向量线性相关，$\mathbf{A}\mathbf{x}=\mathbf{0}$ 就存在非零解，这时 $\mathbf{A}$ 的零空间就是一个维度大于 0 的空间。</p><p>关于列空间和零空间的讨论先在这里打住，之后会进一步讨论它们之间的关系和各自的意义。目前只要知道列空间是由 $\mathbf{A}$ 的列向量张成的，而零空间的意义更隐晦一些，是 $\mathbf{A}\mathbf{x}=\mathbf{0}$ 的所有解组成的空间。从列空间能看出 $\mathbf{A}$ 各列的线性相关关系，列向量越相关，列空间维度越低。从零空间也能看出 $\mathbf{A}$ 各列的线性相关性，列向量越相关，零空间维度越高。而负责量化描述 $\mathbf{A}$ 列向量有多么线性相关的，是一个叫做<code>秩</code>的东西。</p><h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><hr><ul><li>线性代数及其应用：第3版/（美）莱（Lay, D.C.）著；沈复兴等译. ——北京：人民邮电出版社，2007.7</li><li>麻省理工学院的<span class="exturl" data-url="aHR0cDovL29wZW4uMTYzLmNvbS9zcGVjaWFsL29wZW5jb3Vyc2UvZGFpc2h1Lmh0bWw=" title="http://open.163.com/special/opencourse/daishu.html">线性代数公开课<i class="fa fa-external-link"></i></span></li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/05/14/linear-algebra-2/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;a href=&quot;/2016/05/03/linear-algebra-1/&quot; title=&quot;上一章&quot;&gt;上一章&lt;/a&gt;我们讲到三种等价形式：线性方程组、向量方程和矩阵方程。由于这三者之间的等价关系，我们解决现实问题时可以自由选取其中任意一个作为模型。我个人认为，线性方程组是最“质朴”的形式；向量方程则是与几何建立了关系，这将方便我们进行更直观的推理；矩阵方程则是向量方程的一种“封装”，是向量方程的一种抽象，它将具体的向量形式隐藏，提供给我们一个简洁的 API 形式——矩阵。未来将要介绍的很多概念就是基于对这一层封装的研究，如果到时候我们发现某个概念理解有困难，不妨转换思路到向量方程或线性方程组的形式进行分析。

此外，我们之前还进行了关于线性方程组解集的讨论，在这章我们对其进一步探讨。
    
    </summary>
    
    
      <category term="线性代数" scheme="http://mengqi92.github.io/categories/linear-algebra/"/>
    
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数拾遗" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8B%BE%E9%81%97/"/>
    
      <category term="线性代数" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>线性代数拾遗（一 ）：线性方程组、向量方程和矩阵方程</title>
    <link href="http://mengqi92.github.io/2016/05/03/linear-algebra-1/"/>
    <id>http://mengqi92.github.io/2016/05/03/linear-algebra-1/</id>
    <published>2016-05-03T22:55:27.000Z</published>
    <updated>2019-11-30T16:28:17.775Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2016/05/03/linear-algebra-1/banner.jpeg"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>线性代数在各大理工科，乃至经济金融领域的使用之广泛，毋庸置疑。 一直以来，我虽也知道线性代数的重要，但从内心上其实一直是犯怵的（尤其是学习论文、算法中，基本只要看到对方把算法向量化之后就蒙圈了），当年在学校学习过程中很多也是靠着死记硬背过来的，对它的直观意义一直都没能有很好的理解。</p><p>最近，这么一本书进入了我的视线：《线性代数及其应用》，听书名感觉平平，但只翻了几页就感觉十分过瘾，仿佛打通了任督二脉。以往很多死记硬背的知识点在这本书的解释下，变成了可以直观推导出来的结果。这本书不仅对线性代数的基本概念阐述地很直观形象，而且还有许多现实生活中的应用，特别是经济、物理、计算机领域，真正让人领略到线性代数作为现代数学的魅力。</p><p>我特将自己的读书总结和体会记录于此，也是希望借此加深自己的理解。</p><p>注意，这个系列假设你已经有了线性代数基础，像是行变换、将矩阵转换为行阶梯形式这种基本技巧已经掌握。本文不再赘述具体操作步骤，主要关注于概念的直观理解。</p><a id="more"></a><h1 id="线性方程组、向量方程和矩阵方程"><a href="#线性方程组、向量方程和矩阵方程" class="headerlink" title="线性方程组、向量方程和矩阵方程"></a>线性方程组、向量方程和矩阵方程</h1><h2 id="一、线性方程组"><a href="#一、线性方程组" class="headerlink" title="一、线性方程组"></a>一、线性方程组</h2><p>线性代数，最基本的问题，就是解线性方程组了。线性方程组就是一组形如 $a_1 x_1 + a_2 x_2 + \cdots + a_n x_n = b$ 的方程。一个线性方程组中的变量是相同的，如果第一个方程是关于 $x_1 \cdots x_n$ 的，那么其他的也都应该如此（这些变量不一定都出现，因为系数可以有 0）。</p><h3 id="1-1-线性方程组的矩阵形式"><a href="#1-1-线性方程组的矩阵形式" class="headerlink" title="1.1 线性方程组的矩阵形式"></a>1.1 线性方程组的矩阵形式</h3><p>方程组</p><script type="math/tex; mode=display">\left\{\begin{equation}\label{initial}\begin{array}{ccl}x_1 &-& 2x_2 &+& x_3 &= 0 \\    && 2x_2 &-& 8x_3 &= 8 \\{-4x_1} &+& 5x_2 &+& 9x_3 &= {-9}\end{array}\end{equation}\right.</script><p>可以通过増广矩阵形式描述：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & -2 & 1 & 0\\0 & 2 & -8 & 8\\-4 & 5 & 9 & -9\\\end{bmatrix}</script><p>增广矩阵去掉最后一列，就是该方程组的系数矩阵。</p><p>矩阵形式只是线性方程组的一种表示形式。今后的很多关于线性方程组的计算，都将在矩阵形式上进行操作，然而你也需要知道，在这些操作进行的同时，线性方程组也在进行类似的变换。比如，将增广矩阵的第一、二行对换，那么同时，它所代表的线性方程组中，第一、二个方程也进行了对调。</p><h3 id="1-2-线性方程组的解"><a href="#1-2-线性方程组的解" class="headerlink" title="1.2 线性方程组的解"></a>1.2 线性方程组的解</h3><p>解一个线性方程组，就是通过对其矩阵形式行变换（三种方式：交换方程的先后顺序，一个方程左右同乘以某数，和两个方程相加） 转换为行阶梯形式。比如</p><script type="math/tex; mode=display">\begin{bmatrix}1 & -2 & 1 & 0 & \\0 & 2 & -8 & 8 & \\-4 & 5 & 9 & -9 &\end{bmatrix}\text{转化为行阶梯形式：}\begin{bmatrix}1 & -2 & 1 & 0 & \\0 & 1 & -4 & 4 & \\0 & 0 & 1 & 3\end{bmatrix}\text{和最简形式：}\begin{bmatrix}1 & 0 & 0 & 29 & \\0 & 1 & 0 & 16 & \\0 & 0 & 1 & 3\end{bmatrix}</script><p>上面最简形式的矩阵对应的线性方程组是</p><script type="math/tex; mode=display">\left\{\begin{array}{ccl}x_1 && && &= 29 \\    && x_2 && &= 16 \\&& && x_3 &= 3\end{array}\right.</script><p>这个线性方程组和一开始的方程组是等价的，只是处于不同的状态，它们的解也是相同的，而显然行最简形式的方程组最容易解，所以我们一般都<strong>将线性方程组的増广矩阵转化为行最简形式继而求解</strong>。</p><h3 id="1-3-解的存在性和唯一性"><a href="#1-3-解的存在性和唯一性" class="headerlink" title="1.3 解的存在性和唯一性"></a>1.3 解的存在性和唯一性</h3><p>还记得线性代数时经常讨论的“无解““唯一解”“无穷多解”吧？</p><p>首先来看刚才的方程组，经过行变换后，方程组的解已经很显然了：$x_1 = 29, x_2 =16, x_3 = 3$。这个方程组的解就只有一个，是唯一解。</p><h4 id="1-3-1-无解"><a href="#1-3-1-无解" class="headerlink" title="1.3.1 无解"></a>1.3.1 无解</h4><p>我们再来看一个方程组：</p><script type="math/tex; mode=display">\left\{\begin{array}{cccl}&& x_2 &-& 4x_3 &= 8 \\2x_1 &-& 3x_2 &+& 2x_3 &= 1\\5x_1 &-& 8x_2 &+& 7x_3 &= 1\end{array}\right.</script><p>它的增广矩阵</p><script type="math/tex; mode=display">\begin{bmatrix}0 & 1 & -4 & 8 & \\2 & -3 & 2 & 1 & \\5 & -8 & 7 & 1\end{bmatrix}\text{ 行变换得到：}\begin{bmatrix}2 & -3 & 2 & 1 & \\0 & 1 & -4 & 8 & \\0 & 0 & 0 & 5/2\end{bmatrix}</script><p>变换后的矩阵所对应的方程组为</p><script type="math/tex; mode=display">\left\{\begin{array}{cccl}2x_1 &-& 3x_2 &+& 2x_3 &= 1 \\&& x_2 &-& 4x_3 &= 8\\&& && 0 &= 5/2\end{array}\right.</script><p>显然，第三个方程 $0=5/2$ 是无解的。对比这个方程组和它对应的增广矩阵，我们可以发现，<strong>当增广矩阵的行阶梯形式存在 $[0\ \cdots\ 0\ b]$ 形式的行时，方程组无解。</strong></p><h4 id="1-3-2-有解"><a href="#1-3-2-有解" class="headerlink" title="1.3.2 有解"></a>1.3.2 有解</h4><p>当增广矩阵变换为行阶梯形式后，不存在 $[0\ \cdots\ 0\ b]$ 形式的行，则说明方程有解。我们接下来讨论下它的解具体会是怎么样的。</p><p>假设现在有这样一个已经化为行最简形式的增广矩阵：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & 0 & -5 & 1 & \\0 & 1 & 1 & 4 & \\0 & 0 & 0 & 0\end{bmatrix}</script><p>这个矩阵有 4 列，故而有 3 个变量。相对应的方程组为：</p><script type="math/tex; mode=display">\left\{\begin{array}{cccl}x_1 && &-& 5x_3 &= 1 \\&& x_2 &+& x_3 &= 4\\&& && 0 &= 0\end{array}\right.</script><p>观察这个方程组，$x_1$ 和 $x_2$ 只存在于一个方程中（对应行最简形式中的主元位置），$x_3$ 存在于两个方程中。那么我们可以通过 $x_3$ 来表示 $x_1$ 和 $x_2$：</p><script type="math/tex; mode=display">\left\{\begin{aligned}x_1 &=\: 5x_3 \:+\: 1 \\x_2 &=\: x_3 \:+\: 4 \\x_3 &\: \text{是自由变量}\end{aligned}\right.</script><p>上面列出来的实际上就是这个方程组的解集了。<strong>$x_1$ 和 $x_2$ 被称为“基本变量”；$x_3$被称为“自由变量”，因为它在解集里不受任何约束，而基本变量需要自由变量来表示； 也就是说，自由变量确定了一个值，基本变量也就随之确定了一个值。上面这个解集形式也被称为方程组的“通解”，因为它给出了方程组所有解的显示表示。</strong></p><p>需要注意的是，我们需要先将增广矩阵变换为行最简形式，才能知道谁是自由变量，谁是基本变量。</p><p><strong>因为自由变量能取任意值，所以，存在自由变量的线性方程组有无穷多解，而没有自由变量的线性方程组则只有一个唯一解（就像本文第一个方程组那样）。</strong></p><p>总结一下：</p><ul><li>当增广矩阵的行阶梯形式（当然行最简形式也可以）<strong>存在$[0\ \cdots\ 0\ b]$ 形式</strong>时，方程组无解；</li><li>当增广矩阵的行最简形式<strong>不存在自由变量</strong>时，方程组有唯一解；</li><li>当增广矩阵的行最简形式<strong>存在自由变量</strong>时，方程组有无穷多解；</li></ul><h2 id="二、向量方程"><a href="#二、向量方程" class="headerlink" title="二、向量方程"></a>二、向量方程</h2><p>n 维空间中的点可用 n 维向量表示。</p><p>向量之间可以线性组合：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{y} = c_1 \mathbf{v_1} + \cdots + c_p \mathbf{v_p}\end{equation}</script><p>那么，假如有三个向量：$\mathbf{a_1} = [1, -2, -5]^T, \mathbf{a_2} = [2, 5, 6]^T, \mathbf{b} = [7, 4, -3]^T$，想要知道 $\mathbf{b}$ 是否能通过 $\mathbf{a_1}$ 和 $\mathbf{a_2}$ 线性表示，实际上就是求线性方程 $x_1 \mathbf{a_1} + x_2 \mathbf{a_2} = \mathbf{b}$ 是否有解的问题。</p><p>把这个方程展开来看，就是：</p><script type="math/tex; mode=display">\begin{equation}x_1 \begin{bmatrix}1\\-2\\-5\end{bmatrix} + x_2 \begin{bmatrix}2\\5\\6\end{bmatrix}= \begin{bmatrix}7\\4\\-3\end{bmatrix}\end{equation}</script><p>等同于</p><script type="math/tex; mode=display">\begin{equation}\begin{bmatrix}x_1\\-2x_1\\-5x_1\end{bmatrix} +  \begin{bmatrix}2x_2\\5x_2\\6x_2\end{bmatrix}= \begin{bmatrix}7\\4\\-3\end{bmatrix}\end{equation}</script><p>和</p><script type="math/tex; mode=display">\begin{equation}\begin{bmatrix}x_1 + 2x_2\\-2x_1+5x_2\\-5x_1+6x_2\end{bmatrix}= \begin{bmatrix}7\\4\\-3\end{bmatrix}\end{equation}</script><p>所以这个问题其实和一个线性方程组是等价的，这个线性方程组对应的増广矩阵就是（<script type="math/tex">[\mathbf{a_1}, \mathbf{a_2}, \mathbf{b}]</script>）：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & 2 & 7 \\-2 & 5 & 4 \\-5 & -6 & -3\end{bmatrix}</script><p>化简为行最简形式就是：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & 0 & 3 \\0 & 1 & 2 \\0 & 0 & 0\end{bmatrix}</script><p>可以看出，这个线性方程组的解为 $x_1 = 3$ 和 $x_2 = 2$。继而我们就知道了 $\bf{b}$ 和 $\bf{a_1}$, $\bf{a_2}$ 的关系：</p><script type="math/tex; mode=display">\begin{equation}3 \begin{bmatrix}1\\-2\\-5\end{bmatrix} + 2 \begin{bmatrix}2\\5\\6\end{bmatrix}= \begin{bmatrix}7\\4\\-3\end{bmatrix}\end{equation}</script><p>我们反过来回顾这一过程，可以发现，之前我们线性方程组的的增广矩阵表示形式，其实也可以看做是列向量组成的形式，在这个例子中，增广矩阵可以表示为 <script type="math/tex">[\mathbf{a_1}, \mathbf{a_2}, \mathbf{b}]</script>。<strong>把增广矩阵按列拆开看，我们就可以得到线性方程组的向量方程表示形式。</strong></p><p>向量方程是线性方程组另一种重要的表现形式，它能帮助我们将矩阵、线性方程组的抽象概念同几何的直观联系起来。</p><p>在几何中，n 个向量 $\mathbf{v_1}, \mathbf{v_2}, \cdots, \mathbf{v_p}$ 的所有线性组合 $c_1 \mathbf{v_1} + c_2 \mathbf{v_2} + \cdots + c_p \mathbf{v_p}$ 成为一个空间，称作由 $\mathbf{v_1}, \mathbf{v_2}, \cdots, \mathbf{v_p}$ 张成的 $R^n$ 的子空间，记作 <script type="math/tex">\operatorname{Span}\left\{\mathbf{v_1}, \cdots, \mathbf{v_p}\right\}</script>。</p><p>一个向量张成的空间是一根直线，两个向量张成的空间是一个平面。</p><h2 id="三、矩阵方程"><a href="#三、矩阵方程" class="headerlink" title="三、矩阵方程"></a>三、矩阵方程</h2><p>向量的线性组合可以看作向量与矩阵的乘积，比如一个 $m\times n$ 的矩阵 $\mathbf{A}$，各列为 $\mathbf{a_1}, \cdots, \mathbf{a_n}$，而 $x$ 为 $n$ 维向量，则有：</p><script type="math/tex; mode=display">\begin{equation}\mathbf{A}\mathbf{x} = [\mathbf{a_1}\ \mathbf{a_2}\ \cdots \mathbf{a_n}]\begin{bmatrix}x_1\\ \vdots\\ x_n\end{bmatrix}= x_1 \mathbf{a_1} + x_2 \mathbf{a_2} + \cdots + x_n \mathbf{a_n}\end{equation}</script><p>这种形如 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 的形式，就称为矩阵方程。</p><p>由矩阵方程的定义，我们可以得出：<strong>方程$\mathbf{A}\mathbf{x}=\mathbf{b}$有解当且仅当$\mathbf{b}$为$\mathbf{A}$中列的线性组合。</strong>又因为我们之前提到，这些列向量的所有线性组合构成了<script type="math/tex">\operatorname{Span}\left\{\mathbf{a_1}, \cdots, \mathbf{a_n}\right\}</script>，向量 $\mathbf{b}$  是否存在于这个空间，就等价于 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 有解。</p><p>下面我们来讨论下任意 $\mathbf{b} \in R^m$ 的情况。</p><p>设</p><script type="math/tex; mode=display">\begin{equation}\mathbf{A} = \begin{bmatrix}1&3&4\\ -4&2&-6\\ -3&-2&-7\end{bmatrix}, \mathbf{b} = \begin{bmatrix}b1\\b2\\b3\end{bmatrix}\end{equation}</script><p>求方程 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 是否对 $b_1, b_2, b_3$ 的所有取值都有解？</p><p>我们首先对增广矩阵化简：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & 3 & 4 & b_1 \\-4 & 2 & -6 & b_2 \\-3 & -2 & -7 & b_3\end{bmatrix}\sim\begin{bmatrix}1 & 3 & 4 & b_1 \\0 & 14 & 10 & b_2+4b_1 \\0 & 0 & 0 & b_1-\frac{1}{2}b_2+b_3\end{bmatrix}</script><p>可以看出，当$\mathbf{b}$ 取某些值时，$b_1-\frac{1}{2}b_2+b_3$ 不等于0，于是就会有无解的情况。只有当</p><script type="math/tex; mode=display">b_1-\frac{1}{2}b_2+b_3=0</script><p>时方程才有解。注意，这个式子在几何中表示三维中的一个平面， 结合$\mathbf{A}\mathbf{x}=\mathbf{b}$，这个平面就是$\mathbf{A}$ 中列向量线性组合构成的集合。</p><p>本来 $\mathbf{b}$ 是三维的向量，如果没有限制的话它可以表示整个三维空间，然而，在这个空间中，一大部分都不满足使 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 有解。这仅剩的一个平面就是 $\mathbf{A}$ 的列向量所能张成的全部空间。  这些三维列向量最终张成了一个二维平面。</p><p>观察行最简形式矩阵，可以知道，之所以 $\mathbf{b}$ 的一些取值造成矩阵方程无解，是因为系数矩阵 $\mathbf{A}$ 中最后一行没有主元，在行最简形式中变成了形如 [0 0 0 b] 的行。<strong>如果系数矩阵 $\mathbf{A}$ 中每一行都有主元的话，那么就不会出现无解的情况。</strong></p><p>反过来看，当 n 个 m 维列向量能张成 $R^m$ 时，就说明对任意 $\mathbf{b} \in R^m$，方程 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 都有解，也就是说，$R^m$ 空间中的任意向量，都可以由 $\mathbf{A}$ 的列线性表示。</p><p>总结一下，就是以下四点相互等价。</p><ol><li>对任意 $\mathbf{b}\in R^m$，方程 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 都有解。</li><li>任意 $\mathbf{b}\in R^m$ 都是$\mathbf{A}$ 中列的一个线性组合。</li><li>$\mathbf{A}$ 的列张成 $R^m$。</li><li>$\mathbf{A}$ 中每一行都有主元位置。</li></ol><h2 id="四、三种等价形式"><a href="#四、三种等价形式" class="headerlink" title="四、三种等价形式"></a>四、三种等价形式</h2><p>矩阵方程</p><script type="math/tex; mode=display">\begin{equation}\mathbf{A}\mathbf{x} = \mathbf{b}\end{equation}</script><p>和向量方程</p><script type="math/tex; mode=display">\begin{equation}x_1 \mathbf{a_1} + x_2 \mathbf{a_2} + \cdots + x_n \mathbf{a_n} = \mathbf{b}\end{equation}</script><p>以及下列增广矩阵对应的线性方程组具有相同的解集</p><script type="math/tex; mode=display">\begin{equation}[\mathbf{a_1}\ \mathbf{a_2}\ \cdots\ \mathbf{a_n}\ \mathbf{b}]\end{equation}</script><blockquote><p>矩阵方程、向量方程和线性方程组是三种不同但却相互等价的形式。在现实生活中构造一个数学模型时，我们可以在任何情况下自由选择其中任何一种最自然、最便利的陈述形式。</p></blockquote><p>以上三种形式就是我们在解线性方程组时的三个工具，结合具体问题，我们可以通过不同角度观察问题，进而求解。 另外，这三种形式的求解，都是对增广矩阵进行行化简，因此，増广矩阵的行变换是一切的基础。</p><h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><hr><ul><li>线性代数及其应用：第3版/（美）莱（Lay, D.C.）著；沈复兴等译. ——北京：人民邮电出版社，2007.7</li></ul><h1 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h1><hr><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/05/03/linear-algebra-1/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;线性代数在各大理工科，乃至经济金融领域的使用之广泛，毋庸置疑。 一直以来，我虽也知道线性代数的重要，但从内心上其实一直是犯怵的（尤其是学习论文、算法中，基本只要看到对方把算法向量化之后就蒙圈了），当年在学校学习过程中很多也是靠着死记硬背过来的，对它的直观意义一直都没能有很好的理解。&lt;/p&gt;
&lt;p&gt;最近，这么一本书进入了我的视线：《线性代数及其应用》，听书名感觉平平，但只翻了几页就感觉十分过瘾，仿佛打通了任督二脉。以往很多死记硬背的知识点在这本书的解释下，变成了可以直观推导出来的结果。这本书不仅对线性代数的基本概念阐述地很直观形象，而且还有许多现实生活中的应用，特别是经济、物理、计算机领域，真正让人领略到线性代数作为现代数学的魅力。&lt;/p&gt;
&lt;p&gt;我特将自己的读书总结和体会记录于此，也是希望借此加深自己的理解。&lt;/p&gt;
&lt;p&gt;注意，这个系列假设你已经有了线性代数基础，像是行变换、将矩阵转换为行阶梯形式这种基本技巧已经掌握。本文不再赘述具体操作步骤，主要关注于概念的直观理解。&lt;/p&gt;
    
    </summary>
    
    
      <category term="线性代数" scheme="http://mengqi92.github.io/categories/linear-algebra/"/>
    
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数拾遗" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8B%BE%E9%81%97/"/>
    
      <category term="线性代数" scheme="http://mengqi92.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Ein 和 Eout，假设模型以及开放思维</title>
    <link href="http://mengqi92.github.io/2015/10/13/Ein-Eout/"/>
    <id>http://mengqi92.github.io/2015/10/13/Ein-Eout/</id>
    <published>2015-10-13T01:32:18.000Z</published>
    <updated>2019-11-30T16:28:17.763Z</updated>
    
    <content type="html"><![CDATA[<p>加州理工的<span class="exturl" data-url="aHR0cDovL29wZW4uMTYzLmNvbS9zcGVjaWFsL29wZW5jb3Vyc2UvbGVhcm5pbmdmcm9tZGF0YS5odG1s" title="http://open.163.com/special/opencourse/learningfromdata.html">机器学习公开课<i class="fa fa-external-link"></i></span>上，<span class="exturl" data-url="aHR0cHM6Ly93b3JrLmNhbHRlY2guZWR1" title="https://work.caltech.edu">穆斯塔法教授<i class="fa fa-external-link"></i></span>对机器学习的讲解非常细致，每个公式、每个符号都会进行详细的剖析，并直观地解释出来，他对机器学习的热情和态度很值得我们学习。</p><p>而这门课程在讲解学习的可行性时，多次提到了$E_{in}$和$E_{out}$的概念。 $E_{in}$和$E_{out}$分别表示模型假设对样本（已知）的错误率和对真实情况（未知）的错误率。统计机器学习之所以可行，就是因为有这样一个理论支撑：</p><script type="math/tex; mode=display">P[E\_{in} - E\_{out} > \epsilon] = 2 e^{-2\epsilon^2 N} \tag{\*}\label{\*}</script><p>上面的式子叫 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvSG9lZmZkaW5nJTI3c19pbmVxdWFsaXR5" title="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoeffding 不等式<i class="fa fa-external-link"></i></span>。从公式中可以看出，当N足够大时，$E_{in}$和$E_{out}$相差太大的概率就比较小。换句话说，当N足够大时，$E_{in}$就会更接近于$E_{out}$。如此，我们机器学习提出的模型假设如果对大量已知样本能够较好地拟合的话，那它对真实的未知样本应该也能够较好地拟合。</p><p>上面的$\ref{*}$式只适用于一次随机试验，一次试验只建立一个模型假设，而我们实际训练时是要提出若干个假设，再从这些假设中选择最符合目标函数的那个假设。也就是：</p><script type="math/tex; mode=display">P[E\_{in} - E\_{out} > \epsilon] = 2 M e^{-2\epsilon^2 N} \tag{\*\*}\label{\*\*}</script><p>式子中的 M 就是我们提出的假设数目。</p><h2 id><a href="#" class="headerlink" title></a><a id="more"></a></h2><p>理论先讲到这里，下面谈谈我个人对$E_{in}$和$E_{out}$的一点理解。</p><p><strong>我们人在观察世界、观察他人的时候，其实就是在学习。从小到大，我们通过眼耳鼻等五官获知大量样本，再从这些样本中不断丰富和调整自己头脑中的假设模型，我们对事物、对社会、对世界的认识也就是指自己头脑中的这个模型，即所谓的“世界观”、“价值观”等等。每个人对社会、对他人的评判也都是来源于他头脑中对所认识事物建立的模型。</strong></p><p>比如“士别三日，当刮目相看”的例子，孙权、鲁肃与吕蒙长期共事，逐渐对吕蒙建立了假设模型，而当吕蒙“乃始就学”之后，鲁肃再与吕蒙论议，发现他头脑中的这个模型已不能很好地拟合现在的吕蒙，乃大惊曰“士别三日，当刮目想看”。我们平时看人时，也要经常提醒自己，自己对他人的看法也只是自己头脑中的“假设模型”而已，你自己觉得拟合的再好，觉得$E_{in}$已经很小了，但也不能说明这个“假设”就能很好地拟合真实情况。$E_{in}$小，不代表$E_{out}$就小，还有可能是过拟合，或是假设模型本身就错了啊。</p><p>所以有时面对他人无端指责或是误解时，我们可以这样想：他对你的看法，其实是他先对你观察，并在他头脑中建立一个模型，这个模型就是你在他头脑中的投影。而他表达出来对你的看法，也都是基于他对你在他头脑中的投影所做的观察。既然是投影，必然不全面，这个投影不一定能代表你的真实情况。这样看来，当你被人无缘由嘲讽的时候，反而暴露出了他认识的局限。你也不妨就当他在对一个“幽灵”说话。</p><p>再从这个角度来看，我们也就不难理解新闻上经常出现的一些类似“某‘好男人’被曝出轨”、“某温文尔雅的编剧吸毒”的新闻所引起的舆论哗然。从机器学习的角度看，这就是反映了大众脑中的模型和真实情况反差太大，而这个反差的揭露时间又过短使得大家一时接受不了（Justin Beiber的变化时间就够长，所以它的那些新闻，我也都见怪不怪了 -_-）。大众脑中所建立模型的$E_{out}$过大，或者说 “bias” 过大，这个模型不能很好地预测真实世界。</p><p>那么，我们如何能够改善我们的假设对于真实情况的预测呢？我们再来回顾一下$\ref{**}式$：</p><script type="math/tex; mode=display">P[E\_{in} - E\_{out} > \epsilon] = 2 M e^{-2\epsilon^2 N}</script><p>要想提高$P[E_{in} - E_{out} &gt; \epsilon] $：一个是提高$N$，即增加我们的阅历，而且所“阅”的人（样本）分布也要尽可能的广，这样建立的模型泛化能力才更强。另一个就是不断迭代，不断评价旧有假设，从中发现不足（“吾日三省吾身”），并在其基础上进行改良，提出新的假设。也就是说，我们要保持一个勤于思考、开放的头脑，时刻提醒自己认识具有局限，保持谦卑的心态，不断学习、吸收并更新我们对世界、对他人的看法！</p><h2 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h2><p>本文中所有文字版权均属本人所有，未经允许请勿转载。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;加州理工的&lt;a href=&quot;http://open.163.com/special/opencourse/learningfromdata.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;机器学习公开课&lt;/a&gt;上，&lt;a href=&quot;https://work.caltech.edu&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;穆斯塔法教授&lt;/a&gt;对机器学习的讲解非常细致，每个公式、每个符号都会进行详细的剖析，并直观地解释出来，他对机器学习的热情和态度很值得我们学习。&lt;/p&gt;
&lt;p&gt;而这门课程在讲解学习的可行性时，多次提到了$E_{in}$和$E_{out}$的概念。 $E_{in}$和$E_{out}$分别表示模型假设对样本（已知）的错误率和对真实情况（未知）的错误率。统计机器学习之所以可行，就是因为有这样一个理论支撑：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;P[E\_{in} - E\_{out} &gt; \epsilon] = 2 e^{-2\epsilon^2 N} \tag{\*}\label{\*}&lt;/script&gt;&lt;p&gt;上面的式子叫 &lt;a href=&quot;https://en.wikipedia.org/wiki/Hoeffding%27s_inequality&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hoeffding 不等式&lt;/a&gt;。从公式中可以看出，当N足够大时，$E_{in}$和$E_{out}$相差太大的概率就比较小。换句话说，当N足够大时，$E_{in}$就会更接近于$E_{out}$。如此，我们机器学习提出的模型假设如果对大量已知样本能够较好地拟合的话，那它对真实的未知样本应该也能够较好地拟合。&lt;/p&gt;
&lt;p&gt;上面的$\ref{*}$式只适用于一次随机试验，一次试验只建立一个模型假设，而我们实际训练时是要提出若干个假设，再从这些假设中选择最符合目标函数的那个假设。也就是：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;P[E\_{in} - E\_{out} &gt; \epsilon] = 2 M e^{-2\epsilon^2 N} \tag{\*\*}\label{\*\*}&lt;/script&gt;&lt;p&gt;式子中的 M 就是我们提出的假设数目。&lt;/p&gt;
&lt;h2 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot;&quot;&gt;&lt;/a&gt;
    
    </summary>
    
    
      <category term="随笔" scheme="http://mengqi92.github.io/categories/nonsense/"/>
    
    
      <category term="随笔" scheme="http://mengqi92.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
      <category term="机器学习感悟" scheme="http://mengqi92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>Gabor 特征总结</title>
    <link href="http://mengqi92.github.io/2015/10/11/gabor/"/>
    <id>http://mengqi92.github.io/2015/10/11/gabor/</id>
    <published>2015-10-11T17:02:00.000Z</published>
    <updated>2019-11-30T16:28:17.767Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2015/10/11/gabor/banner.jpeg"><p>Gabor 特征是一种可以用来描述图像纹理信息的特征，Gabor 滤波器的频率和方向与人类的视觉系统类似，特别适合于纹理表示与判别。</p><p>Gabor 特征主要依靠 Gabor 核在频率域上对信号进行加窗，从而能描述信号的局部频率信息。</p><p>说到 Gabor 核，不能不提到傅里叶变换。正是靠傅里叶变换，我们才能将信号转换到频率域，才能让Gabor核在频率域去加窗。而在原本的空间域中，一个 Gabor 核实际上就是一个高斯核与正弦波调制的结果，可以看做是高斯核应用在了正弦波的频域部分。</p><p>上面说的还是比较笼统，下面我们一步一步介绍Gabor核是怎么对信号“加窗”的。</p><a id="more"></a><h1 id="一、傅里叶变换"><a href="#一、傅里叶变换" class="headerlink" title="一、傅里叶变换"></a>一、傅里叶变换</h1><p>关于傅里叶变换，韩昊同学总结过一个<span class="exturl" data-url="aHR0cDovL3podWFubGFuLnpoaWh1LmNvbS93aWxsZS8xOTc2MzM1OA==" title="http://zhuanlan.zhihu.com/wille/19763358">很直观的解释<i class="fa fa-external-link"></i></span>。我这里就不赘述了。</p><p>总之，傅里叶变换是图像处理里面一个很重要的工具，本质是将任意一个函数转化为若干不同频率正弦波的组合，（组合方式在离散函数中就是相加，在连续函数中就是积分）。由此，将空域（或时域）信号转换到了频域（即频率域）。</p><p>空间域中多个波叠加，在频率域中就对应着若干个散落的点。韩昊同学将其比喻为不同音阶组成的音谱。</p><p>频率域中的基本元素就是正弦波：空间域中的一个正弦波波形，在频率域中只要一个点就能表示。</p><p><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5YKF6YeM5Y+25Y+Y5o2i" title="https://zh.wikipedia.org/wiki/傅里叶变换">维基百科<i class="fa fa-external-link"></i></span>上有一个动态图，展示了一个叠加波如何分解到频率域上的若干点：</p><p><img alt="叠加波的分解过程" data-src="https://upload.wikimedia.org/wikipedia/commons/7/72/Fourier_transform_time_and_frequency_domains_%28small%29.gif?1444117179010"></p><p>事实上，任何波都可以看做是若干（乃至无穷）个不同频率正弦波的叠加。</p><p>就像可见光可以看做不同频率的光的叠加一样，通过傅里叶变换，我们能将任何波分解为不同频率波的叠加。这样转换的好处是：有些情况下空域中很复杂的问题，在频率域会变得十分简单。</p><!--more--><h1 id="二、Gabor-核"><a href="#二、Gabor-核" class="headerlink" title="二、Gabor 核"></a>二、Gabor 核</h1><h2 id="2-1-一维-Gabor-核"><a href="#2-1-一维-Gabor-核" class="headerlink" title="2.1 一维 Gabor 核"></a>2.1 一维 Gabor 核</h2><h3 id="2-1-1-一维傅里叶变换"><a href="#2-1-1-一维傅里叶变换" class="headerlink" title="2.1.1 一维傅里叶变换"></a>2.1.1 一维傅里叶变换</h3><p>一维傅里叶变化定义如下：</p><script type="math/tex; mode=display">\hat{f}(\xi)=\int\_{-\infty}^\infty f(t) e^{-i2\pi t \xi}\, dt,\quad \xi \text{为任意实数} \tag{1}\label{1}</script><p>其中，f 为输入信号，$\xi$ 表示分解得到的各个波的频率，$\hat{f}(f, \xi)$ 为变换后的信号。公式中的 $e^{-i2\pi x \xi}$ 表示一个复数波，关于复数波的解释可以看我<a href="/2015/10/06/complex/" title="之前的一篇文章">之前的一篇文章</a></p><p>从上面的公式可以看出，原信号 $f(t)$ 以 t 为自变量，描述了信号值随时间的变化，说明原信号空间在时间域中。经过傅里叶变换后，函数自变量变为了 $\xi$ ，$\hat{f}(\xi)$ 描述了信号值随频率的变化，即信号转换到了频率域空间中。如果说原来信号的图示需要以时间（空间）为坐标轴的话，信号在傅里叶变换后的图示就需要以频率为坐标轴了。</p><h3 id="2-1-2-一维-Gabor-核"><a href="#2-1-2-一维-Gabor-核" class="headerlink" title="2.1.2 一维 Gabor 核"></a>2.1.2 一维 Gabor 核</h3><p>一维Gabor核由一个高斯核与一个复数波的乘积定义：</p><script type="math/tex; mode=display">Gabor(t) = ke^{i\theta} \omega(at) s(t) \tag{2}\label{2}</script><p>其中，</p><script type="math/tex; mode=display">\begin{cases}\omega(t)=e^{-\pi t^2} \\\s(t) = e^{i(2\pi f\_0 t)} \\\\end{cases}</script><p>这里，$f_0$ 是复数波$s(t)$的频率。</p><p>将复数波$s(t) = e^{i(2\pi f_0 t)}$代入$\ref{2}$式中，得到：</p><script type="math/tex; mode=display">\begin{align}Gabor(t) & = k \omega(at) e^{i(2\pi f\_0 t + \theta)} \\\     & = k \omega(at) \left[ \cos(2\pi f\_0 t+\theta) + i\sin(2\pi f\_0 t+\theta) \right]\end{align}</script><p>上面最后一步得到了 Gabor 核的复数表示，我们就可以按实部和虚部将其拆分为实核和虚核，在很多应用中，我们只需要应用 Gabor核的实数部分即可：</p><script type="math/tex; mode=display">\begin{cases}Gabor\_{real}(t) = \omega(at)\cos(2\pi f\_0 t + \theta) \\\Gabor\_{imag}(t) = \omega(at)\sin(2\pi f\_0 t + \theta)\end{cases}</script><h3 id="2-1-3-Gabor-核的傅里叶变换"><a href="#2-1-3-Gabor-核的傅里叶变换" class="headerlink" title="2.1.3 Gabor 核的傅里叶变换"></a>2.1.3 Gabor 核的傅里叶变换</h3><p>将 Gabor 核（式$\ref{2}$）套入一维傅里叶变换（式$\ref{1}$）中，得到 Gabor 核的傅里叶变换：</p><script type="math/tex; mode=display">\begin{align}\hat{Gabor}(f)& = ke^{i\theta} \int\_{-\infty}^{\infty} e^{-i 2\pi f t} \omega(at) s(t) \,dt \\\& = ke^{i\theta} \int\_{-\infty}^{\infty} e^{-i2\pi (f-f\_0)t} \omega(at) \,dt \\\& = (k/a) \cdot e^{i\theta} \cdot \hat{\omega}\left( (f-f\_0)/a \right) \\\\end{align} \tag{3}\label{3}</script><p>上式中出现了 $\hat{\omega}(\frac{f-f_0}{a})$ 的形式，这里需要补充高斯核一个很有趣的性质：$\hat{\omega}(f) = \omega(f) = e^{-\pi f^2}$，这个性质这里就不证明了，有兴趣的同学可以自己推导一下。根据这个性质，上式中的 $\hat{\omega}(\frac{f-f_0}{a})$ 也可以写作 $\omega(\frac{f-f_0}{a})$，二者可以自由转换。</p><p>此外，$\ref{3}$式中的末尾，我们知道了Gabor核傅里叶变换后是这样一个形式：$\frac{k}{a} e^{i\theta} \hat{\omega}(\frac{f-f_0}{a})$，这个形式可以看做是一个复数波，它的幅度</p><script type="math/tex; mode=display">A = \left\lVert \hat{Gabor}(f) \right\rVert = \frac{k}{a} \hat{\omega}(\frac{f-f\_0}{a}) = \frac{k}{a} \omega(\frac{f-f\_0}{a})</script><p>也就是说，Gabor核相当于在频率域应用了一个高斯核窗口。假设我们这时有了一个信号的频率域：$f_{in}(f)$，那么我们直接用频率域的Gabor核 $\hat{Gabor}$ 与其相乘，就实现了对 $f_0$ 频率邻域范围内的滤波效果：输入信号频率离这个 Gabor 核的 $f_0$ 越远，则乘上Gabor核之后的结果就越小，尤其是当 $f_{in}$ 在 $f_0$ 的 $3\sigma$ 区间外时，这个频率几乎可以忽略不计。于是，最终能保留下来的信号就都是 $f_0$ 频率附近的信号了。</p><p>这个想法，用公式表示出来就是：</p><script type="math/tex; mode=display">\hat{Gabor} \cdot \hat{f\_{in}}</script><p>从这个角度出发，给我们任意一个输入信号，我们先用傅里叶变换将其变换到频率域得到$\hat{f_{in}}$，再用 Gabor 核的傅里叶变换结果与之相乘，就是频域滤波的结果了。</p><p>不过我们大可不必这么麻烦，因为有卷积定理：</p><script type="math/tex; mode=display">Gabor \* f\_{in} = \hat{Gabor} \cdot \hat{f\_{in}}</script><p>这样看来，我们只需要用 Gabor 核和输入信号卷积就可以得到输入信号在某频率邻域附近的响应结果！！</p><p>我们既可以用这个响应结果来实现频域滤波，又可以用它来描述信号的频率信息。下面要提到的Gabor特征，就是用Gabor核来描述信号的频率信息，从而作为信号的特征的。</p><h2 id="2-2-二维-Gabor-变换"><a href="#2-2-二维-Gabor-变换" class="headerlink" title="2.2 二维 Gabor 变换"></a>2.2 二维 Gabor 变换</h2><p>将上面的一维情况推广至二维：</p><h3 id="2-2-1-二维傅里叶变换："><a href="#2-2-1-二维傅里叶变换：" class="headerlink" title="2.2.1 二维傅里叶变换："></a>2.2.1 二维傅里叶变换：</h3><p>二维傅里叶变换定义如下：</p><script type="math/tex; mode=display">\hat{f}(\xi\_x, \xi\_y) = \iint f(x,y) e^{-i2\pi (\xi\_x x + \xi\_y y)}\, dx dy</script><p>为了简洁，改用 $(u_0, v_0)$ 来代替 $(\xi_x, \xi_y)$，则上式可写为：</p><script type="math/tex; mode=display">\hat{f}(u\_0, v\_0) = \iint f(x, y) \exp {\left( -i2\pi {\left( u\_0 x + v\_0 y\right) }\right) } \, dxdy \tag{4}\label{4}</script><p>提醒一下，这里 $(x, y)$ 表示空域坐标，$(u_0, v_0)$ 表示频域坐标。</p><h3 id="2-2-2-二维复数波"><a href="#2-2-2-二维复数波" class="headerlink" title="2.2.2 二维复数波"></a>2.2.2 二维复数波</h3><p>二维复数波完整定义如下（用复指数形式表示）：</p><script type="math/tex; mode=display">s(x,y) = \exp\left( i \left(2\pi (u\_0 x + v\_0 y) + P \right) \right)</script><p>由于初始相位对Gabor核影响不大，因此可以将其省略，得到更简洁的形式（论文中关于 Gabor 函数的定义各不一样，主要是这些细节的考虑不同）：</p><script type="math/tex; mode=display">s(x,y) = \exp \left(i \left(2\pi (u\_0 x + v\_0 y) \right) \right)</script><h3 id="2-2-3-二维高斯函数"><a href="#2-2-3-二维高斯函数" class="headerlink" title="2.2.3 二维高斯函数"></a>2.2.3 二维高斯函数</h3><p>二维高斯函数定义如下：</p><script type="math/tex; mode=display">\omega(x, y, \sigma_x, \sigma_y) = K \exp\left(-\pi \left( (x-x\_0)^2 / \sigma\_x^2 + (y-y\_0)^2 / \sigma\_y^2 \right) \right) \tag{5}\label{5}</script><p>其中，$\sigma_x, \sigma_y$ 分别为两个方向上的尺度参数（scaling parameters），用来控制高斯函数在两个方向上的“展布”形状。$(x_0, y_0)$ 为高斯函数的中心点。$K$ 为常数。</p><p>考虑全面的话，高斯函数还要有（顺时针）旋转，即：</p><script type="math/tex; mode=display">\begin{cases}(x-x\_0)\_r = (x-x\_0)\cos \theta + (y-y\_0)\sin \theta \\\(y-y\_0)\_r = -(x-x\_0)\sin \theta + (y-y\_0)\cos \theta\end{cases}</script><p>加入旋转参数后的二维高斯函数为：</p><script type="math/tex; mode=display">\omega\_r(x, y, \theta, \sigma\_x, \sigma\_y) = K \exp\left(-\pi \left( (x-x\_0)\_r^2 / \sigma\_x^2 + (y-y\_0)\_r^2 / \sigma\_y^2\right) \right)</script><img class title="二维高斯" data-src="/2015/10/11/gabor/2d-gaussian.png"><p>上图即是一个二维高斯核的图像，该高斯核中，$(x_0, y_0) = (0, 0)$，$(\sigma_x^2, \sigma_y^2) = (50, 40)$，$\theta = -45°$</p><p>从图像可以看出，$\sigma_x 和 \sigma_y$分别控制了高斯两个方向的“展布”情况。</p><h3 id="2-2-4-Gabor-滤波器核"><a href="#2-2-4-Gabor-滤波器核" class="headerlink" title="2.2.4 Gabor 滤波器核"></a>2.2.4 Gabor 滤波器核</h3><p>类似一维 Gabor 核，我们将二维高斯函数与二维复数波相乘，就得到了二维的Gabor核：</p><script type="math/tex; mode=display">\begin{align}Gabor(x\_0, y\_0, \theta, \sigma\_x, \sigma\_y, u\_0, v\_0)  & = s(x,y) \omega\_r(x,y) \\\& = K \exp\left(-\pi \left( (x-x\_0)\_r^2/\sigma\_x^2 + (y-y\_0)\_r^2/\sigma\_y^2 \right) \right) \exp\left(i 2\pi (u\_0 x + v\_0 y) \right) \\\\end{align}</script><p>它的各个参数含义如下：</p><ul><li>$(x_0, y_0)$: 高斯核的中心点</li><li>$\theta$: 高斯核的旋转方向（顺时针）</li><li>$(\sigma_x, \sigma_y)$: 高斯核两个方向上的尺度</li><li>$(u_0, v_0)$: 频域坐标</li><li>$K$: 高斯核的幅度（magnitude）的比例</li></ul><img class title="Gabor 核频率域图示" data-src="/2015/10/11/gabor/gabor-filter-frequency.png"><p>上图为Gabor核在频率域中的图示，这个Gabor核就是从之前那个高斯核得到的，其参数分别为：$u_0 = v_0 = 1/80$，$x_0 = y_0 = 0$，$\sigma_x^2 = 50$，$\sigma_y^2 = 40$，$\theta = -45°$，$F_0 = \sqrt{2}/80$，$\omega_0=45°$。</p><img class title="Gabor 核空间域图示" data-src="/2015/10/11/gabor/gabor-filter-spatial.png"><p>上图为Gabor核在空间域中的图示，参数和上面那个Gabor核一样。图像左边是实部，右边是虚部。这样的Gabor核与图像进行卷积，我们便能得到图像在$(u_0, v_0)$频率附近的响应情况。在图像处理中，通常使用Gabor的实部进行卷积就可以。</p><h1 id="三、Gabor-核作为图像特征"><a href="#三、Gabor-核作为图像特征" class="headerlink" title="三、Gabor 核作为图像特征"></a>三、Gabor 核作为图像特征</h1><p>通过上面的分析，我们知道了，一个Gabor核能获取到图像某个频率邻域的响应情况，这个响应结果可以看做是图像的一个特征。那么，我们如果用多个不同频率的Gabor核去获取图像在不同频率邻域的响应情况，最后就能形成图像在各个频率段的特征，这个特征就可以描述图像的频率信息了</p> <img class title="一系列 Gabor 核" data-src="/2015/10/11/gabor/gabor-filter-banks.png"><p>上图展示了一系列具有不同频率的 Gabor 核，用这些核与图像卷积，我们就能得到图像上每个点和其附近区域的频率分布情况。</p><p>由于纹理特征通常和频率相关，因此Gabor核经常用来作为纹理特征。又因为字符识别问题通常都是识别纹理的过程，所以Gabor核在光学字符识别（OCR）系统中也有广泛应用。</p><h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>由于本人对信号处理不是太了解，因此对傅里叶变换、频率域的理解都是个人粗浅的理解。为了完成这篇文章，我学习了很多信号处理的知识，重新理解了一些基本概念，看别人的帖子建立过一些认识，随后这层理解不牢又被推翻，再重新建立……前前后后用了一周的时间才最终完成。如有不严谨或错误的地方，还请大家谅解。要严肃学习的话最好还是看权威教材、看论文，我这篇文章可以作为另一个角度的补充。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5YKF6YeM5Y+25Y+Y5o2i" title="https://zh.wikipedia.org/wiki/傅里叶变换">中文维基百科 / 傅里叶变换<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3podWFubGFuLnpoaWh1LmNvbS93aWxsZS8xOTc2MzM1OA==" title="http://zhuanlan.zhihu.com/wille/19763358">韩昊同学对傅里叶变换的直观解释<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Y2356ev5a6a55CG" title="https://zh.wikipedia.org/wiki/卷积定理">中文维基百科 / 卷积定理<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cDovL2VuLndpa2lwZWRpYS5vcmcvR2Fib3JfZmlsdGVy" title="http://en.wikipedia.org/Gabor_filter">英文维基百科 / Gabor_filter<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvR2Fib3JfdHJhbnNmb3Jt" title="https://en.wikipedia.org/wiki/Gabor_transform">英文维基百科 / Gabor_transform<i class="fa fa-external-link"></i></span></li><li>Movellan J R. Tutorial on Gabor filters[J]. Open Source Document, 2002.</li><li>Idrissa M, Acheroy M. Texture classification using Gabor filters[J]. Pattern Recognition Letters, 2002, 23(9): 1095-1102.</li></ol><h1 id="版权声明"><a href="#版权声明" class="headerlink" title="版权声明"></a>版权声明</h1><p>本文所有文字版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2015/10/11/gabor/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;p&gt;Gabor 特征是一种可以用来描述图像纹理信息的特征，Gabor 滤波器的频率和方向与人类的视觉系统类似，特别适合于纹理表示与判别。&lt;/p&gt;
&lt;p&gt;Gabor 特征主要依靠 Gabor 核在频率域上对信号进行加窗，从而能描述信号的局部频率信息。&lt;/p&gt;
&lt;p&gt;说到 Gabor 核，不能不提到傅里叶变换。正是靠傅里叶变换，我们才能将信号转换到频率域，才能让Gabor核在频率域去加窗。而在原本的空间域中，一个 Gabor 核实际上就是一个高斯核与正弦波调制的结果，可以看做是高斯核应用在了正弦波的频域部分。&lt;/p&gt;
&lt;p&gt;上面说的还是比较笼统，下面我们一步一步介绍Gabor核是怎么对信号“加窗”的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="图像处理" scheme="http://mengqi92.github.io/categories/cv/"/>
    
    
      <category term="机器学习" scheme="http://mengqi92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="傅里叶变换" scheme="http://mengqi92.github.io/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    
      <category term="图像处理" scheme="http://mengqi92.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="Gabor 特征" scheme="http://mengqi92.github.io/tags/Gabor-%E7%89%B9%E5%BE%81/"/>
    
      <category term="特征提取" scheme="http://mengqi92.github.io/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    
      <category term="Gabor" scheme="http://mengqi92.github.io/tags/Gabor/"/>
    
  </entry>
  
  <entry>
    <title>我对卷积的理解</title>
    <link href="http://mengqi92.github.io/2015/10/06/convolution/"/>
    <id>http://mengqi92.github.io/2015/10/06/convolution/</id>
    <published>2015-10-06T20:05:00.000Z</published>
    <updated>2019-11-30T16:28:17.763Z</updated>
    
    <content type="html"><![CDATA[<img class data-src="/2015/10/06/convolution/banner.jpeg"><p>在学习机器学习和图像处理的过程中，经常会遇到卷积这个概念。我每次遇到这个概念都有点似懂非懂的样子。有时候清楚它的直观解释，但又搞不清公式中是如何体现的。究其原因，还是我没有完全搞懂这个概念。 维基百科上有一个动态图来演示这个概念，但对于我来说还是有些复杂。于是自己在网上找了很多文章来研究，终于有了比较直观的印象，这里就趁热把我理解的解释一下，作为总结。</p><h2 id="一、一维卷积"><a href="#一、一维卷积" class="headerlink" title="一、一维卷积"></a>一、一维卷积</h2><h3 id="1-1-数学定义"><a href="#1-1-数学定义" class="headerlink" title="1.1 数学定义"></a>1.1 数学定义</h3><p>维基百科上，卷积的形式化定义如下：</p><script type="math/tex; mode=display">f(x)\*g(x) = \int\_{-\infty}^{\infty} f(\tau)g(x-\tau) d\tau \tag{1}\label{1}</script><h3 id="1-2-直观解释"><a href="#1-2-直观解释" class="headerlink" title="1.2 直观解释"></a>1.2 直观解释</h3><p>先来分析一下这个公式：</p><ol><li>$f(x)*g(x)$ 表示 $f(x)$ 和 $g(x)$ 的卷积，注意此处自变量为 $x$；</li><li>它是对 $(-\infty, \infty)$ 区间上对 $\tau$ 求积分；</li><li>积分对象为两个函数的乘积：$f(\tau)$ 和 $g(x-\tau)$。</li><li>等式右边只有 $g(x-\tau)$ 提到了 $x$，其他部分都在关注 $\tau$</li></ol><p>这样一个公式恐怕还是难以理解，接下来将通过一个例子来进行解释。</p><a id="more"></a><h3 id="1-3-例子"><a href="#1-3-例子" class="headerlink" title="1.3 例子"></a>1.3 例子</h3><p>试想小明有一段时间每天都要去输液，输的药会在身体里残留直至失效，药效随着时间是不断衰落的。 这里为简便起见，假设药效 4 天就失效，而且药效持续函数是离散的。如下图所示：</p><img class title="药效持续函数" data-src="/2015/10/06/convolution/conv-effect-function.png"><p>图中，横坐标为天数，纵坐标为药效。输液当天（day=0）药效为 100%，第二天减弱为 80%，第三天减弱为 40%，第四天减弱为 0。</p><p>现在先定义一些符号：<br>记天数为 $t$，每天输液的药量为 $\operatorname{m}(t)$, 药效函数为 $\operatorname{eff}(t)$，小明身上残留的药效为 $\operatorname{rest}(t)$<br>其中药效函数：</p><script type="math/tex; mode=display">\operatorname{eff}(t) = \begin{cases} 100 \% & \text{t=0}  \\\80 \% & \text{t=1}  \\\40 \% & \text{t=2}  \\\0  \% & \text{t>=3}  \\\\end{cases}</script><p>下面观察一下小明从第一天起，连续三天输液后身上所留下的药效（假设每天药量固定为10）。</p><ul><li>第一天，小明去医院输完液后，药效为 10（$ \operatorname{rest}(t) = \operatorname{m}(t)\cdot \operatorname{eff}(0) $）。</li></ul><img class title="第一天累积的药效示意" data-src="/2015/10/06/convolution/conv-effect-day1.png"><ul><li>第二天，小明去医院准备输液<ul><li>输液前，他身上带着前一天的药效，此时已经衰减为 10$\cdot$ 80%=8，即 $ \operatorname{m}(t-1)\cdot \operatorname{eff}(1) $。</li><li>输液后，他身上携带的药效为：8 + 10 = 18（$ \operatorname{rest}(t) = \operatorname{m}(t-1)\cdot \operatorname{eff}(1) + \operatorname{m}(t)\cdot \operatorname{eff}(0) $）</li></ul></li></ul><img class title="第二天累积的药效示意" data-src="/2015/10/06/convolution/conv-effect-day2.png"><ul><li>第三天，小明去医院准备输液<ul><li>输液前，他身上带着前两天的药效，第一天的此时已衰减为 10$\cdot$ 40%=4（$ \operatorname{m}(t-2)\cdot \operatorname{eff}(2) $），第二天的此时衰减为 10$\cdot$ 80%=8（$ \operatorname{m}(t-1)\cdot \operatorname{eff}(1) $）。</li><li>输液后，他身上携带的药效为：4 + 8 + 10 = 22（$ \operatorname{rest}(t) = \operatorname{m}(t-2)\cdot \operatorname{eff}(2) + \operatorname{m}(t-1)\cdot \operatorname{eff}(1) + \operatorname{m}(t)\cdot \operatorname{eff}(0) $）。</li></ul></li></ul><img class title="第三天累积的药效示意" data-src="/2015/10/06/convolution/conv-effect-day3.png"><h3 id="1-4-分析"><a href="#1-4-分析" class="headerlink" title="1.4 分析"></a>1.4 分析</h3><p>从上面的分析我们可以得到，小明第 t 天身上残留的药效 $\operatorname{rest}(t) = \sum_{i=1}^n \operatorname{m}(t-i) \operatorname{eff}(i)$，其中 $n$ 为药效有效的最大天数。 我们不难想象，但药效函数 $\operatorname{eff}(t)$ 为连续时，上式中的求和就应改为积分；而当药效能无限期有效时，上式中 $n$ 就为 $\infty$。 无限期有效的药效函数，所对应的 $\operatorname{rest}(t) = \int_{-\infty}^\infty \operatorname{m}(t-\tau) \operatorname{eff}(\tau) \,d\tau$（本例中严格来说应该是 $\int_0^\infty$ ，这里推广到了 $(-\infty, \infty)$）。推导到这里，基本就是维基百科上卷积的定义了。</p><h3 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h3><p>我之前对卷积概念的困惑主要是因为对公式 $\ref{1}$ 的那个 $\tau$ 的意义理解错了，总以为 $\tau$ 是随着坐标轴变化的量。 事实上，在上面举的例子中，<strong>$\tau$ 是作为沿着纵坐标遍历的量：它的作用是对“纵向”上，历次函数 $\operatorname{eff}(t)$ 在当前点($t$)残余量($\operatorname{rest}(t)$)的求和。积分也是对纵向上的积分，而非横向上沿自变量的积分</strong>。</p><p>横坐标变化的量始终为 $t$，而且在卷积中并没有明显体现出 $t$ 的变化。</p><p>最后重新回顾一下上面的整个过程：比较三天以来的示意图可以发现，如果我们以“当天”而不是第 $t$ 天为参考的话，就会看到 $\operatorname{eff}(t)$ 随着时间是在向左平移（深蓝的线表示当天，前几天的线都在其左边），然后各天衰落后的药量残余等于 $\operatorname{eff}(t)$ 值乘上初始的药量值，最后将各天的药量残余求个和。整个过程的核心就是<strong>“（反转），移动，乘积，求和”</strong>，这里面“反转”的概念也好理解，就是本来 $\operatorname{eff}(t)$ 是<strong>“朝着右边”</strong>走的函数，$t=0,t=1,\cdots$，$\operatorname{eff}(t)$ 是形容<strong>t 天后的药量的</strong>，然而实际例子中我们是以当天为参考系，我们是在<strong>“朝着左边”</strong>看的，因而要“反转”。我认为这个“反转”是一个很自然的过程，不算是整个卷积的核心。 此外，在计算机领域，至少我接触到的图像处理、机器学习方面用到的卷积，其卷积核（就是例子中不断平移的函数 $\operatorname{eff}(t)$）一般是对称的，所以这个反转的概念也不是那么必要。</p><h2 id="二、二维卷积"><a href="#二、二维卷积" class="headerlink" title="二、二维卷积"></a>二、二维卷积</h2><h3 id="2-1-数学定义"><a href="#2-1-数学定义" class="headerlink" title="2.1 数学定义"></a>2.1 数学定义</h3><script type="math/tex; mode=display">f(x, y)\* g(x, y) = \int\_{\tau\_1=-\infty}^\infty \int\_{\tau\_2=-\infty}^{\infty} f(\tau\_1, \tau\_2) \cdot g(x-\tau\_1, y-\tau\_2)\,d\tau\_1 d\tau\_2 \tag{2}</script><p>二维卷积在图像处理中会经常遇到，图像处理中用到的大多是二维卷积的离散形式：</p><script type="math/tex; mode=display">f[x,y] * g[x,y] = \sum\_{n\_1=-\infty}^\infty \sum\_{n\_2=-\infty}^\infty f[n\_1, n\_2] \cdot g[x-n\_1, y-n\_2] \tag{3}</script><h3 id="2-2-图像处理中的二维卷积"><a href="#2-2-图像处理中的二维卷积" class="headerlink" title="2.2 图像处理中的二维卷积"></a>2.2 图像处理中的二维卷积</h3><p>二维卷积就是一维卷积的扩展，原理差不多。核心还是<strong>（反转），移动，乘积，求和</strong>。这里二维的反转就是将卷积核沿反对角线翻转，比如：</p><script type="math/tex; mode=display">\begin{bmatrix}     a & b & c \\\    d & e & f \\\    g & h & i \\\    \end{bmatrix}\text{翻转为} \begin{bmatrix}    i & h & g \\\    f & e & d \\\    c & b & a \\\    \end{bmatrix}</script><p>之后，卷积核在二维平面上平移，并且卷积核的每个元素与被卷积图像对应位置相乘，再求和。通过卷积核的不断移动，我们就有了一个新的图像，这个图像完全由卷积核在各个位置时的乘积求和的结果组成。</p><p>举一个最简单的均值滤波的例子：</p><script type="math/tex; mode=display">\text{这是一个 3x3 的均值滤波核，也就是卷积核：}\begin{bmatrix}    1/9 & 1/9 & 1/9 \\\    1/9 & 1/9 & 1/9 \\\    1/9 & 1/9 & 1/9 \\\\end{bmatrix} \\\\text{这是被卷积图像，这里简化为一个二维 5x5 矩阵：}\begin{bmatrix}    3 & 3 & 3 & 3 & 3 \\\    4 & 4 & 4 & 4 & 4 \\\    5 & 5 & 5 & 5 & 5 \\\    6 & 6 & 6 & 6 & 6 \\\    7 & 7 & 7 & 7 & 7 \\\\end{bmatrix} \\\</script><p>当卷积核运动到图像右下角处（卷积中心和图像对应图像第 4 行第 4 列）时，它和图像卷积的结果如下图所示：</p><img class title="二维卷积示例" data-src="/2015/10/06/convolution/2d-convolution.png"><p>可以看出，二维卷积在图像中的效果就是：对图像的每个像素的邻域（邻域大小就是核的大小）加权求和得到该像素点的输出值。滤波器核在这里是作为一个“权重表”来使用的。</p><h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><ol><li><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU1JThEJUI3JUU3JUE3JUFG" title="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF">中文维基百科/卷积<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ncmFwaGljcy5zdGFuZm9yZC5lZHUvY291cnNlcy9jczE3OC9hcHBsZXRzL2NvbnZvbHV0aW9uLmh0bWw=" title="https://graphics.stanford.edu/courses/cs178/applets/convolution.html">斯坦福大学CS178课程资料（有一个卷积的在线Applet演示）<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cDovL2NvbGFoLmdpdGh1Yi5pby9wb3N0cy8yMDE0LTA3LVVuZGVyc3RhbmRpbmctQ29udm9sdXRpb25z" title="http://colah.github.io/posts/2014-07-Understanding-Convolutions">Understanding Convolution（用图和例子从一维卷积一直讲到了CNN）<i class="fa fa-external-link"></i></span></li></ol><h2 id="版权声明："><a href="#版权声明：" class="headerlink" title="版权声明："></a>版权声明：</h2><p>本文中所有文字、图片版权均属本人所有，如需转载请注明来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2015/10/06/convolution/banner.jpeg&quot; class=&quot;&quot;&gt;
&lt;p&gt;在学习机器学习和图像处理的过程中，经常会遇到卷积这个概念。我每次遇到这个概念都有点似懂非懂的样子。有时候清楚它的直观解释，但又搞不清公式中是如何体现的。究其原因，还是我没有完全搞懂这个概念。 维基百科上有一个动态图来演示这个概念，但对于我来说还是有些复杂。于是自己在网上找了很多文章来研究，终于有了比较直观的印象，这里就趁热把我理解的解释一下，作为总结。&lt;/p&gt;
&lt;h2 id=&quot;一、一维卷积&quot;&gt;&lt;a href=&quot;#一、一维卷积&quot; class=&quot;headerlink&quot; title=&quot;一、一维卷积&quot;&gt;&lt;/a&gt;一、一维卷积&lt;/h2&gt;&lt;h3 id=&quot;1-1-数学定义&quot;&gt;&lt;a href=&quot;#1-1-数学定义&quot; class=&quot;headerlink&quot; title=&quot;1.1 数学定义&quot;&gt;&lt;/a&gt;1.1 数学定义&lt;/h3&gt;&lt;p&gt;维基百科上，卷积的形式化定义如下：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x)\*g(x) = \int\_{-\infty}^{\infty} f(\tau)g(x-\tau) d\tau \tag{1}\label{1}&lt;/script&gt;&lt;h3 id=&quot;1-2-直观解释&quot;&gt;&lt;a href=&quot;#1-2-直观解释&quot; class=&quot;headerlink&quot; title=&quot;1.2 直观解释&quot;&gt;&lt;/a&gt;1.2 直观解释&lt;/h3&gt;&lt;p&gt;先来分析一下这个公式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$f(x)*g(x)$ 表示 $f(x)$ 和 $g(x)$ 的卷积，注意此处自变量为 $x$；&lt;/li&gt;
&lt;li&gt;它是对 $(-\infty, \infty)$ 区间上对 $\tau$ 求积分；&lt;/li&gt;
&lt;li&gt;积分对象为两个函数的乘积：$f(\tau)$ 和 $g(x-\tau)$。&lt;/li&gt;
&lt;li&gt;等式右边只有 $g(x-\tau)$ 提到了 $x$，其他部分都在关注 $\tau$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样一个公式恐怕还是难以理解，接下来将通过一个例子来进行解释。&lt;/p&gt;
    
    </summary>
    
    
      <category term="图像处理" scheme="http://mengqi92.github.io/categories/cv/"/>
    
    
      <category term="机器学习" scheme="http://mengqi92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="图像处理" scheme="http://mengqi92.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="Gabor 特征" scheme="http://mengqi92.github.io/tags/Gabor-%E7%89%B9%E5%BE%81/"/>
    
      <category term="数学" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="卷积" scheme="http://mengqi92.github.io/tags/%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>复数的几种表示形式</title>
    <link href="http://mengqi92.github.io/2015/10/06/complex/"/>
    <id>http://mengqi92.github.io/2015/10/06/complex/</id>
    <published>2015-10-06T14:47:16.000Z</published>
    <updated>2015-10-06T14:47:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>研究傅里叶变换的过程中经常要和复数打交道，经常会遇到 $e^{ix}$ 这种形式。</p><p>这里就总结一下复数的直角坐标、极坐标，以及复指数表示形式，也有对欧拉公式的直观解释，以便更好地理解傅里叶变换。</p><p>本文中图片均来自于 <span class="exturl" data-url="aHR0cDovL3d3dy5jc2llLm50bnUuZWR1LnR3L351OTEwMjkvV2F2ZS5odG1s" title="http://www.csie.ntnu.edu.tw/~u91029/Wave.html">国立台湾师范大学资讯工程学系的演算法笔记<i class="fa fa-external-link"></i></span>。</p><a id="more"></a><h2 id="一、复数的直角坐标表示"><a href="#一、复数的直角坐标表示" class="headerlink" title="一、复数的直角坐标表示"></a>一、复数的直角坐标表示</h2><p>首先，复数基本单位是 $i=\sqrt{-1}$，有了这个单位，复数空间中的每个数都可以表示为 $a+bi$ 的形式。其中，a 被称为“实部（real part）”，b 被称为“虚部（imaginary part）”。</p><p>复数可以在复平面（complex plane）上表示，复平面横纵坐标分别为实部和虚部，下图就是复数 $2+3i$ 在复平面上的表示。</p><img class title="复平面" data-src="/2015/10/06/complex/complex-plane.png"><p>我们可以发现，这个复平面和实数空间的直角坐标系类似。那可不可以用极坐标的方法表示复数呢？</p><h2 id="二、复数的极坐标表示"><a href="#二、复数的极坐标表示" class="headerlink" title="二、复数的极坐标表示"></a>二、复数的极坐标表示</h2><p>事实上，复数是可以用极坐标表示的，那一个复数用极坐标表示时的长度和角度分别是多少呢？我们可以在复平面中计算出来。</p><p>例如，复数 $4+3i$ 的复平面直角坐标表示是$(4, 3)$，原点指向该点的向量长度 $r=\sqrt{3^2+4^2}=5$，向量的角度 $\theta = arctan(\frac{3}{4})$。</p><img class title="复数的极坐标表示" data-src="/2015/10/06/complex/complex-polar-plane.png"><p>这里，复数极坐标表示的长度 $r$ 也被称为“强度（magnitude）”，角度 $\theta$ 也被称为“相位（phase）”。</p><h3 id="2-1-由复数极坐标得到直角坐标"><a href="#2-1-由复数极坐标得到直角坐标" class="headerlink" title="2.1 由复数极坐标得到直角坐标"></a>2.1 由复数极坐标得到直角坐标</h3><p>上面我们用复数的直角坐标计算出了极坐标，那么是不是也可以由极坐标推出直角坐标呢？我们还是从复平面中来看：</p><img class title="复数两种表示形式之间的转换" data-src="/2015/10/06/complex/complex-polar-transform.png"><p>从上图可以看出，当我们有复数极坐标 $(r, \theta)$ 时，我们可以得到其直角坐标 $(r \cos(\theta), r \sin(\theta))$，即该复数为 $r\cos\theta + r*i\sin\theta$。</p><h2 id="三、复数的复指数表示与欧拉公式"><a href="#三、复数的复指数表示与欧拉公式" class="headerlink" title="三、复数的复指数表示与欧拉公式"></a>三、复数的复指数表示与欧拉公式</h2><p>欧拉有一天发现，神奇数字 $e$ 的纯虚数次方竟然在复数平面上绕圈！</p><p>用极坐标形式表示，就是 $e^{i\theta}=\cos\theta+i\sin\theta$。</p><p>如此，一个复数就又多了一种指数的表示形式，即复指数形式：$r e^{i\theta} = r \cos\theta + r*i \sin\theta$。</p><p>而当 $r=1$，$\theta=\pi$ 时，对应的直角坐标刚好就是 $(-1, 0)$ ，也就是实数 -1。由此就有了那个著名的“欧拉公式”：<script type="math/tex">e^{i\pi}+1=0</script></p><h3 id="3-1-复数波和实数波"><a href="#3-1-复数波和实数波" class="headerlink" title="3.1 复数波和实数波"></a>3.1 复数波和实数波</h3><p>实数波我们比较熟悉，就是 $\sin\theta$ 或 $\cos\theta$ 形式。而复数波则是由 $e^{i\theta}$ 来定义，实数波和复数波的示意图如下：</p><img class title="实数波和复数波示意" data-src="/2015/10/06/complex/real-wave-complex-wave.png"><p>从示意图中，可以看出，当俯视复数波时，观察到的投影即是一个实数波，即是 $e^{i\theta}=\cos\theta + i* \sin\theta$ 的实部：$\cos\theta$；当从左侧侧视复数波时，得到的投影即是其虚部：$\sin\theta$。</p><p>事实上，复数波的完整定义为：</p><script type="math/tex; mode=display">Ae^{i(\omega t+\phi)} = Ae^{i(2\pi f t+\phi)} = A\cos(2\pi f t+\phi) + iA\sin(2\pi f t+\phi)</script><p>其中，$A$为振幅，$\omega$为角速度，$f$为频率，$\phi$为初试相位，这个波的强度（magnitude）为 $A = \sqrt{A^2 \cdot \cos^2(2\pi f t+\phi) + A^2 \cdot \sin^2(2\pi f t+\phi)}$，瞬时相位（phase）为 $2\pi f t + \phi$。</p><p>由于复指数形式的复数波$e^{i\theta}$相较于$\cos(\theta)+i\sin(\theta)$更简单且更易于控制，因而在信号处理中得到广泛的使用。除此之外，$e^{i\theta}$形式可以看作是实数波的基础，因为我们可以组合两个复数波来得到$\cos(\theta)$和$\sin(\theta)$：</p><script type="math/tex; mode=display">\cos(\theta)=\frac{e^{i\theta}+e^{-i\theta}}{2}</script><script type="math/tex; mode=display">\sin(\theta)=\frac{e^{i\theta}-e^{-i\theta}}{2i}</script><p>另外，在信号处理中，我们只需要考虑实部的线性运算，因此，在我们对一个复数波进行滤波后，得到的复数波可以分解为 $\cos$ 和 $\sin$ 的形式，进而只需要选取实部所对应的 $\cos$ 部分就行了。</p><p>在傅里叶变换中，便是将任意非周期函数分解为了各种复数波叠加的形式，因而傅里叶变换的公式中才会有类似 $e^{ix}$ 的形式。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ol><li><span class="exturl" data-url="aHR0cDovL3d3dy5jc2llLm50bnUuZWR1LnR3L351OTEwMjkvV2F2ZS5odG1s" title="http://www.csie.ntnu.edu.tw/~u91029/Wave.html">国立台湾师范大学资讯工程学系的演算法笔记<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9jY3JtYS5zdGFuZm9yZC5lZHUvfmpvcy9mcC9Db21wbGV4X1NpbnVzb2lkcy5odG1s" title="https://ccrma.stanford.edu/~jos/fp/Complex_Sinusoids.html">斯坦福大学 JULIUS O. SMITH III 所著 Introduction to Digital Filters with Audio Applications 在线版<i class="fa fa-external-link"></i></span></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;研究傅里叶变换的过程中经常要和复数打交道，经常会遇到 $e^{ix}$ 这种形式。&lt;/p&gt;
&lt;p&gt;这里就总结一下复数的直角坐标、极坐标，以及复指数表示形式，也有对欧拉公式的直观解释，以便更好地理解傅里叶变换。&lt;/p&gt;
&lt;p&gt;本文中图片均来自于 &lt;a href=&quot;http://www.csie.ntnu.edu.tw/~u91029/Wave.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;国立台湾师范大学资讯工程学系的演算法笔记&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="图像处理" scheme="http://mengqi92.github.io/categories/cv/"/>
    
    
      <category term="傅里叶变换" scheme="http://mengqi92.github.io/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    
      <category term="欧拉公式" scheme="http://mengqi92.github.io/tags/%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F/"/>
    
      <category term="复数" scheme="http://mengqi92.github.io/tags/%E5%A4%8D%E6%95%B0/"/>
    
      <category term="数字信号处理" scheme="http://mengqi92.github.io/tags/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"/>
    
      <category term="图像处理" scheme="http://mengqi92.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="基础概念" scheme="http://mengqi92.github.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
      <category term="Gabor 特征" scheme="http://mengqi92.github.io/tags/Gabor-%E7%89%B9%E5%BE%81/"/>
    
  </entry>
  
  <entry>
    <title>Logistic 回归</title>
    <link href="http://mengqi92.github.io/2015/10/05/logistic-regression/"/>
    <id>http://mengqi92.github.io/2015/10/05/logistic-regression/</id>
    <published>2015-10-05T14:50:00.000Z</published>
    <updated>2019-11-30T16:28:17.783Z</updated>
    
    <content type="html"><![CDATA[<p>最近项目需要，用到了 Logistic 回归（Logistic Regression），因此又跟着 Andrew Ng 的机器学习课程复习了一遍相关知识，整理如下：</p><h2 id="一、问题的引入"><a href="#一、问题的引入" class="headerlink" title="一、问题的引入"></a>一、问题的引入</h2><p>使用线性回归方法是可以引申来处理分类问题的，一般是用回归得到假设值 $h_\theta (x)$ 来决定类别归属。例如：$h_\theta (x) &lt; 0.5$ 时，y = 0；$h_\theta (x) &gt; 0.5$ 时，y = 1。</p><p>然而，线性回归得到的假设值 $h_\theta (x)$ 有可能 &gt;1 或是 &lt;0，而且有可能会超出很多，这种情况下使用线性回归似乎不是很好的选择。</p><p>为了解决这个问题，我们引入 Logistic 回归方法，将 $h_\theta (x)$ 限制在 (0,1) 范围内。</p><p>注意，Logistic 回归是一种<strong>分类</strong>方法，而不是回归方法，名字中的“回归”是历史原因造成的。</p><a id="more"></a><h2 id="二、Logistic-函数（Logistic-Function）"><a href="#二、Logistic-函数（Logistic-Function）" class="headerlink" title="二、Logistic 函数（Logistic Function）"></a>二、Logistic 函数（Logistic Function）</h2><p>线性回归中，假设函数 $h_\theta (x)=\theta ^\top x$，这里将截距”藏”在了向量中，即$\theta=[\theta_0, \theta_1, \cdots, \theta_n]^\top$，$x=[1, x_1, x_2, \cdots, x_n]^\top$。</p><p>而在 Logistic 回归中，我们使用一个函数来<strong>限制假设函数的值域</strong>，这个函数就叫做 Logistic 函数（Logistic Function，也叫 Sigmoid Function）。</p><p>Logistic Function：<script type="math/tex">g(z)=\frac{1}{1+e^{-z}}</script></p><p>它的函数图像：<br><img class title="逻辑回归函数图像" data-src="/2015/10/05/logistic-regression/Logistic-curve.png"></p><p>从图像中可以看出，逻辑回归函数将输入的$(-\infty, \infty)$空间映射到了$(0,1)$空间，即将值域限制在了$(0,1)$之内。 限制后的假设函数为：</p><script type="math/tex; mode=display">h\_\theta (x)=g(\theta ^\top x)=\frac{1}{1+e^{-\theta ^\top x}}</script><p>注意该假设函数中，只有一个参数：$\theta$，我们接下来就需要通过优化来求解这个参数，以确定分类模型。</p><h2 id="三、假设函数的直观解释"><a href="#三、假设函数的直观解释" class="headerlink" title="三、假设函数的直观解释"></a>三、假设函数的直观解释</h2><p>由于假设函数的值域为$(0,1)$，而$h_\theta (x)$值越接近1，就越有可能是 y=1 类；反之$h_\theta (x)$值越接近0，越有可能是 y=0 类。</p><p>这样看来，假设函数 $h_\theta (x)$ 可以看做是给定 x，其类别 y=1 的估计概率，即</p><script type="math/tex; mode=display">h\_\theta (x)=P(y=1 \mid x;\theta )</script><h2 id="四、寻求优化参数-theta"><a href="#四、寻求优化参数-theta" class="headerlink" title="四、寻求优化参数 $\theta$"></a>四、寻求优化参数 $\theta$</h2><p>一般来说，寻找参数的过程就是优化目标函数的过程。</p><h3 id="4-1-线性回归的目标函数"><a href="#4-1-线性回归的目标函数" class="headerlink" title="4.1 线性回归的目标函数"></a>4.1 线性回归的目标函数</h3><p>在线性回归中，我们的目标函数为：</p><script type="math/tex; mode=display">J(\theta )=\frac{1}{m} \sum\_{i=1}^m \frac{1}{2} (h\_\theta (x^{(i)})-y^{(i)})^2</script><p>其中，$\frac{1}{2} (h_\theta (x^{(i)})-y^{(i)})^2$ 部分就是损失函数，即$Cost(h_\theta (x^{(i)}), y^{(i)})$</p><p>线性回归的优化目标就是最小化这个目标函数，即让各个样本点的误差达到最小。</p><h3 id="4-2-Logistic-回归的目标函数"><a href="#4-2-Logistic-回归的目标函数" class="headerlink" title="4.2 Logistic 回归的目标函数"></a>4.2 Logistic 回归的目标函数</h3><h4 id="4-2-1-平方形式的损失函数"><a href="#4-2-1-平方形式的损失函数" class="headerlink" title="4.2.1 平方形式的损失函数"></a>4.2.1 平方形式的损失函数</h4><p>我们把 Logistic 回归的假设函数 $h_\theta (x)=\frac{1}{1+e^{-\theta ^\top x}}$ 代入到线性回归的损失函数中，得到：</p><script type="math/tex; mode=display">Cost(h\_\theta (x), y) = \frac{1}{2} (h\_\theta (x)-y)^2 = \frac{1}{1+e^{-\theta ^\top x}}</script><p>为简便起见，这里以后，将各个点的误差$h_\theta (x^{(i)})-y^{(i)}$简写为$h_\theta (x)-y$。</p><p>然而，这样的损失函数代入$J(\theta )=\frac{1}{m} \sum\limits_{i=1}^m Cost(h_\theta x, y)$ 中，得到的目标函数 $J(\theta )$ 并非凸函数，其函数图像类似下图的左子图。</p><img class title="非凸函数和凸函数" data-src="/2015/10/05/logistic-regression/convex-function.png"><p>只有目标函数是凸函数时，我们才能通过各种优化方法（如梯度下降、牛顿法等）找到极值点，进而得到最优值对应的参数。 因此，Logistic 回归需要调整其损失函数形式，以使得目标函数为凸函数。</p><h4 id="4-2-2-对数形式的损失函数"><a href="#4-2-2-对数形式的损失函数" class="headerlink" title="4.2.2 对数形式的损失函数"></a>4.2.2 对数形式的损失函数</h4><p>Logistic 回归采用的损失函数为：</p><script type="math/tex; mode=display">Cost(h\_\theta (x), y)=\begin{cases} -log(h\_\theta (x)) &\text{if y=1} \\\-log(1-h\_\theta (x)) &\text{if y=0} \end{cases}</script><p>这两个函数 $-log(h_\theta (x))$，$-log(1-h_\theta (x))$ 的函数图像如下图所示。可以看出，当 y=1 时，随着 $h_\theta (x)$ 逐渐趋近于 0（即趋向于“分错类别”），损失函数将剧烈上升，趋向于 $\infty$，而当 $h_\theta (x)$ 逐渐趋近于 1（即趋向于“分对类别”） 时，损失函数则会逐渐减小到 0。当 y=0 时，情况类似。</p><p>可见，当分错类别时，这个损失函数会得到一个比较大的损失，进而来惩罚分类算法。</p><img class title="损失函数" data-src="/2015/10/05/logistic-regression/cost-function.png"><h5 id="简化损失函数"><a href="#简化损失函数" class="headerlink" title="简化损失函数"></a>简化损失函数</h5><p>上面对数形式损失函数是分段形式的，我们可以将两个式子压缩成一个式子：</p><script type="math/tex; mode=display">Cost(h\_\theta (x), y) = -ylog(h\_\theta (x)) -(1-y)log(1-h\_\theta (x))</script><p>当 y=0 时，取后半段；当 y=1 时，取前半段。</p><p>由此，我们终于得到了 Logistic 回归的目标函数$J(\theta)$：</p><script type="math/tex; mode=display">\begin{align} J(\theta) & = \frac{1}{m} \sum\_{i=1}^m Cost(h\_\theta(x^{(i)}), y^{(i)}) \\\& = -\frac{1}{m} [\sum\_{i=1}^m y^{(i)}log h\_\theta(x^{(i)}) + (1-y^{(i)})log (1-h\_\theta (x^{(i)}))] \\\ \end{align}</script><h3 id="4-3-优化目标函数求参"><a href="#4-3-优化目标函数求参" class="headerlink" title="4.3 优化目标函数求参"></a>4.3 优化目标函数求参</h3><p>优化目标函数：$\min_{\theta} J(\theta)$，即可得到参数 $\theta$</p><p>那么，如何优化目标函数呢？优化方法有很多种，这里讲一下“梯度下降法”：</p><h4 id="4-3-1-梯度下降法（Gradient-Descent）"><a href="#4-3-1-梯度下降法（Gradient-Descent）" class="headerlink" title="4.3.1 梯度下降法（Gradient Descent）"></a>4.3.1 梯度下降法（Gradient Descent）</h4><p>梯度下降法的原理这里不详细解释了，方法比较直观，网上有很多教程可以参考。</p><p>梯度下降法的使用很简单：在目标函数上任找一点开始，让参数 $\theta$ 不断朝着梯度方向迭代，直到收敛，收敛时函数位于极小值处，此时的 $\theta$ 即为 $\min_{\theta} J(\theta)$。</p><p>每一步迭代的形式化定义如下：</p><script type="math/tex; mode=display">\theta\_j := \theta\_j - \alpha \frac{\partial}{\partial \theta\_j} J(\theta)</script><p>这里引入了一个新的参数：$\alpha$，表示迭代速度，在这里作为调控因子。另外式子中 $J(\theta)$ 关于 $\theta$ 的梯度可以计算得到：</p><script type="math/tex; mode=display">\frac{\partial}{\partial \theta\_j} J(\theta) = \frac{1}{m} \sum\_{i=1}^m(h\_\theta (x^{(i)}) - y^{(i)})x\_j^{(i)}</script><p>此外，还要注意的是，梯度下降法迭代时，是所有参数：$\theta_0, \theta_1, \cdots, \theta_n$ 同时迭代的，这个可以以向量形式进行批量计算。</p><p>在梯度下降中，需要计算$\sum_{i=1}^m (h_\theta (x^{(i)}) - y^{(i)})x_j^{(i)}$，也就是每一个样本 $x^{(i)}$ 都要参与计算。这样在样本量较大时，难免效率底下。有一些改进的方法来解决这个问题，例如随机梯度下降法等，这里就不展开了。</p><h2 id="五、用求得的参数进行分类"><a href="#五、用求得的参数进行分类" class="headerlink" title="五、用求得的参数进行分类"></a>五、用求得的参数进行分类</h2><p>使用求得的参数 $\theta$，进而预测新的未知变量 $x$：</p><script type="math/tex; mode=display">h\_\theta(x)=\frac{1}{1+e^{-\theta ^\top x}}</script><p>之前提过了，这个 $h_\theta(x)$ 直观意义为：给定 x，其类别 y=1 的估计概率，即$h_\theta (x)=P(y=1 \mid x;\theta )$ 因此，我们有了 $h_\theta(x)$，就能确定未知样本的分类了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近项目需要，用到了 Logistic 回归（Logistic Regression），因此又跟着 Andrew Ng 的机器学习课程复习了一遍相关知识，整理如下：&lt;/p&gt;
&lt;h2 id=&quot;一、问题的引入&quot;&gt;&lt;a href=&quot;#一、问题的引入&quot; class=&quot;headerlink&quot; title=&quot;一、问题的引入&quot;&gt;&lt;/a&gt;一、问题的引入&lt;/h2&gt;&lt;p&gt;使用线性回归方法是可以引申来处理分类问题的，一般是用回归得到假设值 $h_\theta (x)$ 来决定类别归属。例如：$h_\theta (x) &amp;lt; 0.5$ 时，y = 0；$h_\theta (x) &amp;gt; 0.5$ 时，y = 1。&lt;/p&gt;
&lt;p&gt;然而，线性回归得到的假设值 $h_\theta (x)$ 有可能 &amp;gt;1 或是 &amp;lt;0，而且有可能会超出很多，这种情况下使用线性回归似乎不是很好的选择。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们引入 Logistic 回归方法，将 $h_\theta (x)$ 限制在 (0,1) 范围内。&lt;/p&gt;
&lt;p&gt;注意，Logistic 回归是一种&lt;strong&gt;分类&lt;/strong&gt;方法，而不是回归方法，名字中的“回归”是历史原因造成的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://mengqi92.github.io/categories/ml/"/>
    
    
      <category term="机器学习" scheme="http://mengqi92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Logistic 回归" scheme="http://mengqi92.github.io/tags/Logistic-%E5%9B%9E%E5%BD%92/"/>
    
      <category term="Logistic Regression" scheme="http://mengqi92.github.io/tags/Logistic-Regression/"/>
    
  </entry>
  
  <entry>
    <title>《统计思维：程序员数学之概率统计》读书摘录</title>
    <link href="http://mengqi92.github.io/2015/10/03/think-statistics-note/"/>
    <id>http://mengqi92.github.io/2015/10/03/think-statistics-note/</id>
    <published>2015-10-03T15:20:00.000Z</published>
    <updated>2015-10-03T15:20:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一章-探索性数据分析"><a href="#第一章-探索性数据分析" class="headerlink" title="第一章 探索性数据分析"></a>第一章 探索性数据分析</h2><h3 id="重编码（recode）"><a href="#重编码（recode）" class="headerlink" title="重编码（recode）"></a>重编码（recode）</h3><p>不是调查收集的原始数据，而是使用原始数据计算得到的变量。<br>可用来检查数据的一致性和准确性</p><hr><h2 id="第二章-分布"><a href="#第二章-分布" class="headerlink" title="第二章 分布"></a>第二章 分布</h2><h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><p>直方图能判断分布的形状，容易发现最常出现的值，但不一定能看到很少出现的值（离群值）<br><a id="more"></a></p><h3 id="变量分布"><a href="#变量分布" class="headerlink" title="变量分布"></a>变量分布</h3><ul><li><p>集中趋势 —— 均值、中位数<br>  变量值是否聚集在某个值附近？</p></li><li><p>众数<br>  是否有多个聚集点？</p></li><li><p>展布 —— 方差<br>  变量的变化性如何？</p></li><li><p>尾部<br>  当值偏离众数时，其概率降低多快？</p></li><li><p>离群值<br>  是否有远离众数的极端值？</p></li></ul><h3 id="汇总统计量"><a href="#汇总统计量" class="headerlink" title="汇总统计量"></a>汇总统计量</h3><ul><li><p>均值<br>  描述分布的“集中趋势”</p><script type="math/tex; mode=display">x=\frac{1}{n} \sum\_i{x\_i}</script></li><li><p>方差</p><ul><li><p>描述分布的变化性，或“展布”</p><script type="math/tex; mode=display">S^2=\frac{1}{n} \sum\_i{(x\_i -\bar{x} )^2}</script></li></ul></li><li><p>效应量</p><ul><li>均值的差值：$\bar{x_1} -\bar{x_2} $</li><li>均值差/合并标准差：<script type="math/tex; mode=display">d=\bar{x\_1} -\bar{x\_2} \over s</script>其中，$s= \frac{n_1 \cdot s_1 + n_2 \cdot s_2}{n_1+n_2}$，该量描述均值差相对标准差的<strong>倍数</strong></li></ul></li></ul><h2 id="第三章-概率质量函数"><a href="#第三章-概率质量函数" class="headerlink" title="第三章 概率质量函数"></a>第三章 概率质量函数</h2><h3 id="概率质量函数（Probability-Mass-Function，PMF）"><a href="#概率质量函数（Probability-Mass-Function，PMF）" class="headerlink" title="概率质量函数（Probability Mass Function，PMF）"></a>概率质量函数（Probability Mass Function，PMF）</h3><p>概率质量函数将每个值映射到其概率，$概率=\frac{频数}{样本量} $</p><ul><li>PMF 适用于变量值数量较少的情况。随着值的数量增加，每个值对应的概率会变得越来越小，随机噪音的影响就会变大。</li></ul><h2 id="第四章-累积分布函数（cumulative-distribution-function，CDF）"><a href="#第四章-累积分布函数（cumulative-distribution-function，CDF）" class="headerlink" title="第四章 累积分布函数（cumulative distribution function，CDF）"></a>第四章 累积分布函数（cumulative distribution function，CDF）</h2><h3 id="百分位秩（percentile-rank）"><a href="#百分位秩（percentile-rank）" class="headerlink" title="百分位秩（percentile rank）"></a>百分位秩（percentile rank）</h3><p>在标准化考试成绩中，百分位秩是<strong>比你成绩低（或相同）的人的比例</strong></p><h3 id="CDF"><a href="#CDF" class="headerlink" title="CDF"></a>CDF</h3><p>CDF将一个值映射到百分位秩<br>CDF(x) = 小于或等于x的值在分布中所占的比例</p><ul><li>不同于百分位秩，CDF范围为0到1</li><li>第 50 百分位就是<strong>中位数</strong></li><li>基于百分位数的统计量<ul><li>中位数（median）</li><li>四分位矩（interquartile range，IQR）</li><li>等份点——分位数（quantile）</li></ul></li></ul><h3 id="利用CDF生成随机样本"><a href="#利用CDF生成随机样本" class="headerlink" title="利用CDF生成随机样本"></a>利用CDF生成随机样本</h3><ul><li>无论CDF的形状如何，其百分位秩的分布都是均匀的<br>利用这一点，可以使用给定的CDF生成随机数：</li></ul><ol><li>从0到100中均匀地选择一个百分位秩</li><li>使用cdf.Percentile，得到分布中对应所选百分位秩的值</li></ol><h2 id="第五章-分布建模"><a href="#第五章-分布建模" class="headerlink" title="第五章 分布建模"></a>第五章 分布建模</h2><p>基于有限样本的经验观察，被称为<em>经验分布</em><br><em>分析分布</em>试图建立一个简化的分布模型，来描述真实世界的分布，可以用作经验分布的<strong>建模</strong></p><ul><li>现实世界的很多现象都可以用分析分布进行建模</li><li>分析分布是一种<strong>抽象</strong>，也是一种<strong>数据压缩形式</strong>：如果模型很好地拟合了一个数据集，那么只需几个参数便可对大量数据进行概括</li><li>有时候，我们会发现一种自然现象符合某个分析分布，进而这种认识可以帮助我们更好地了解物理系统：如 Pareto 分布经常是由带有正反馈的生成型过程导致的。</li><li>分析分布可以方便地进行数学分析</li><li>现实世界的数据<strong>永远不会</strong>完美地符合一个分析分布，现实世界和数学模型之间总是存在着差异。</li><li>什么是“相关”的，什么是“不必要”的，这取决于你将这个模型用于何种用途。</li></ul><h2 id="第六章-概率密度函数（Probability-density-function-PDF）"><a href="#第六章-概率密度函数（Probability-density-function-PDF）" class="headerlink" title="第六章 概率密度函数（Probability density function, PDF）"></a>第六章 概率密度函数（Probability density function, PDF）</h2><p>概率密度度量单位 x 的概率。</p><h3 id="核密度估计（kernel-density-estimation-KDE）"><a href="#核密度估计（kernel-density-estimation-KDE）" class="headerlink" title="核密度估计（kernel density estimation, KDE）"></a>核密度估计（kernel density estimation, KDE）</h3><p>核密度估计可以对一个样本寻找符合样本数据的适当平滑的 PDF</p><p>KDE 估计密度函数可用于：</p><ol><li>可视化<br> 在项目探索阶段，可通过 CDF 展现分布，继而判断估计 PDF 是否为该分布的适宜模型。</li><li>插值<br> 如果相信总体分布是平滑的，那么就可以使用KDE为样本中不存在的值插入相应的密度。</li><li>模拟<br> 我们可以使用 KDE，对样本分布做平滑处理，使得模拟可以探索可能性更高的结果。</li></ol><h3 id="PMF、CDF、PDF-的关系"><a href="#PMF、CDF、PDF-的关系" class="headerlink" title="PMF、CDF、PDF 的关系"></a>PMF、CDF、PDF 的关系</h3><img class title="分布函数的关系框架" data-src="/2015/10/03/think-statistics-note/pmf-cdf-pdf.jpg"><p>PMF：一组<strong>离散值</strong>的概率。PDF 累加得到 CDF。<br>CDF：累积概率。<br>PDF：<strong>连续性</strong> CDF 的导数。</p><p>离散型分布 -&gt; 连续型分布：平滑处理</p><ol><li>假设数据来自连续的分析分布，然后估计这个分布的参数</li><li>核密度估计</li></ol><h3 id="矩（moment）"><a href="#矩（moment）" class="headerlink" title="矩（moment）"></a>矩（moment）</h3><p>原始矩是一个统计量。对一组值为$x_i$的样本，第 k 个原始矩为：</p><script type="math/tex; mode=display">m'\_k=\frac{1}{n} \sum{\_i} x\_i^k$$ 当 k=1 时，原始矩即为样本均值 $\bar{x} $。第 k 个中心矩（central moment）计算公式：$$m\_k=\frac{1}{n} \sum{\_i} (x\_i -\bar{x} )^k</script><p>当 k=2 时，中心矩即为方差。</p><h4 id="为什么称为“矩”"><a href="#为什么称为“矩”" class="headerlink" title="为什么称为“矩”"></a>为什么称为“矩”</h4><blockquote><p>如果我们在直尺的不同位置 $x_i$ 附加一个重物，然后将直尺围绕这些值的均值旋转，旋转重物的<span class="exturl" data-url="aHR0cDovL2VuLndpa2lwZWRpYS5vcmcvd2lraS9Nb21lbnRfb2ZfaW5lcnRpYQ==" title="http://en.wikipedia.org/wiki/Moment_of_inertia">惯性力矩<i class="fa fa-external-link"></i></span>就是这些值的方差。</p></blockquote><h4 id="统计量的单位"><a href="#统计量的单位" class="headerlink" title="统计量的单位"></a>统计量的单位</h4><p>如果值$x_i$的单位是厘米，那么第一原始矩的单位是<em>厘米</em>，第二原始矩的单位是<em>平方厘米</em>，第三原始矩的单位是<em>立方厘米</em></p><h3 id="偏度（skewness）"><a href="#偏度（skewness）" class="headerlink" title="偏度（skewness）"></a>偏度（skewness）</h3><p>如果分布是以集中趋势为中心对称的，那么这个分布就是<em>非偏斜的（unskewed）</em>。<br>如果分布中的值向右<strong>延伸更多</strong>，那么这个分布就是<em>右偏的（right skewed）</em>；<br>如果分布中的值向左<strong>延伸更多</strong>，那么这个分布就是<em>左偏的（left skewed）</em>；</p><ul><li><em>偏斜（skewed）</em>与<em>有偏（biased）</em>并无关系。偏度只是描述了分布的形状。</li></ul><h4 id="偏度的计算"><a href="#偏度的计算" class="headerlink" title="偏度的计算"></a>偏度的计算</h4><p>对给定的值序列 $x_i$，样本偏度 <script type="math/tex">g\_1= \frac{ \tfrac{1}{n} \sum{\_i} (x\_i-\bar{x} )^3}{方差^3}</script></p><p>偏度为负值代表分布左偏，正值代表分布右偏。$g_1$的大小代表偏斜的程度。</p><h4 id="衡量分布对称性的另一个方法"><a href="#衡量分布对称性的另一个方法" class="headerlink" title="衡量分布对称性的另一个方法"></a>衡量分布对称性的另一个方法</h4><p>实际应用中，样本偏度容易受分布中离群值的影响，因此，计算样本偏度通常并非好主意。</p><p>衡量分布对称性的另一个方法是<strong>检查均值和中位数的关系</strong>：极端值对均值的影响比对中位数影响更大</p><ul><li>在左偏分布中，均值 &lt; 中位数</li><li>在右偏分布中，均值 &gt; 中位数</li></ul><h5 id="Pearson-中位数偏度系数（Pearson’s-median-skewness-coefficient）"><a href="#Pearson-中位数偏度系数（Pearson’s-median-skewness-coefficient）" class="headerlink" title="Pearson 中位数偏度系数（Pearson’s median skewness coefficient）"></a>Pearson 中位数偏度系数（Pearson’s median skewness coefficient）</h5><script type="math/tex; mode=display">g\_p=3(\bar{x} -m)/S</script><p>Pearson 中位数偏度系数更加稳健（robust）。</p><h2 id="第七章-变量之间的关系"><a href="#第七章-变量之间的关系" class="headerlink" title="第七章 变量之间的关系"></a>第七章 变量之间的关系</h2><blockquote><p>如果能够从一个变量的信息得到另一个变量的信息，那么这两个变量就是<strong>相关的</strong>。</p></blockquote><h3 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h3><p>研究两个变量之间关系最简单方法就是散点图（scatter plot）。</p><h4 id="抖动技术（jittering）"><a href="#抖动技术（jittering）" class="headerlink" title="抖动技术（jittering）"></a>抖动技术（jittering）</h4><p>当获取数据由于某种原因而丢失部分信息，例如数据经过四舍五入后丢失了更高精度的小数位信息，变得“更离散”而导致散点图不美观，这时可以通过加入随机噪音（例如服从均匀分布的随机值）来填补各离散值之间的空隙。</p><p><strong>抖动技术只是为了图像的美观，应只用于视觉呈现，而不能通过它来分析数据。</strong></p><h4 id="饱和（saturation）"><a href="#饱和（saturation）" class="headerlink" title="饱和（saturation）"></a>饱和（saturation）</h4><p>由于数据在一定区域内过于密集，甚至出现重叠，而离群值显得特别突出。这种情况称为“饱和”。</p><p>解决办法：<br>将图中的点以半透明显示（例如 alpha=0.2），这样重叠的点只会导致那一片的数据点颜色更深。<br>（我的理解：<strong>以半透明显示的办法，相当于把数据正则化（Normalized）了</strong>，原先数据密度值的域为二值情况（0 or 1），<strong>重叠区域密度大于 1 无法在图上体现，相当于上溢出。通过规范化，将密度值域打散在（0，1）连续域内了</strong>，重叠区域密度只要密度不超过1，就能在散点图中较好地体现出来）</p><h3 id="相关性（correlation）"><a href="#相关性（correlation）" class="headerlink" title="相关性（correlation）"></a>相关性（correlation）</h3><p>相关性是一个<strong>量化两个变量之间关系强弱</strong>的统计量。</p><p>要衡量两个变量时，比较麻烦的是两个变量之间单位不同，无法直接比较。为此，我们需要将两个变量统一到一个量纲上。</p><p>常见的相关系数有两种：</p><ul><li>Pearson乘积矩相关系数：将变量统一为标准分数（standard score），即偏离均值的标准差数：$z_i = (x_i - \mu)/\sigma$。</li><li>Spearman秩相关系数：将变量转换为秩（rank），就是该变量在其所有值中的排名。</li></ul><p>标准分数有以下这些性质：</p><ul><li>$z_i$是无量纲（单位）的，其分布均值为0，方差为1；</li><li>如果 $X$ 服从正态分布，则 $Z$ 也服从正态分布；</li><li>如果 $X$ 是偏斜的或包含离群值，则 $Z$ 也是偏斜的或包含离群值；</li></ul><p>当观察的变量 $X$ 有偏斜，或是含有离群值时，$Z$ 也会受影响。这种情况下，使用百分位秩更加稳健，因为百分位秩总是服从(1, n)的均匀分布：$R~U(1, n)$，其中 $n$ 为样本数。</p><h3 id="协方差（covariance）"><a href="#协方差（covariance）" class="headerlink" title="协方差（covariance）"></a>协方差（covariance）</h3><p>协方差用于<strong>度量两个变量共同变化的趋势</strong>。</p><p>假设现在有两个序列 $X$ 和 $Y$，则两个序列中，值与均值的偏差为：</p><script type="math/tex; mode=display">\begin{cases}dx\_i = x\_i - \bar{x} \\\dy\_i = y\_i - \bar{y}\end{cases}</script><p>如果两个序列变化趋势一致的话，$dx_i$ 和 $dy_i$ 同号，即$dx_i \cdot dy_i &gt; 0$；反之二者异号，即$dx_i \cdot dy_i &lt; 0$。</p><p><strong>我们将这一序列所有样本的偏差加到一块，应该就能度量两个序列之间共同变化的趋势</strong>，于是我们就有了“协方差”的定义：</p><script type="math/tex; mode=display">\operatorname{Cov(X,Y)} = \frac{1}{n} \sum dx\_i dy\_i</script><p>注意到协方差定义中最后乘了一个 $\frac{1}{n}$ 来正则化（$n$为序列长度，此处要求$X$和$Y$必须长度相同）。</p><p><em>当$X$和$Y$两个向量正交时，协方差为0</em></p><h3 id="Pearson相关系数"><a href="#Pearson相关系数" class="headerlink" title="Pearson相关系数"></a>Pearson相关系数</h3><p>协方差的单位是两个变量单位的乘积，这样会使人对它的意义感到迷惑，因而人们很少将协方差作为摘要统计量。接下来介绍的 Pearson相关系数解决了这个问题。</p><script type="math/tex; mode=display">\rho = \operatorname{Cov(X,Y)} / S\_X S\_Y \tag{p}\label{pearson}</script><p>可见，Pearson相关系数加入了标准差来正则化协方差，而且是无量纲的。</p><p>我们可以把$\ref{pearson}$式中的$\operatorname{Cov(X,Y)}$展开，就能发现：</p><script type="math/tex; mode=display">\rho = \frac{1}{n} \sum{ \left( \left( x\_i-\bar{x} \right) / S\_X \right) \left( \left(y\_i-\bar{y}\right) / S\_Y \right) }</script><p>也就是说，Pearson相关系数在计算偏差时就将其与标准差相比较，得到一个归一化的结果：标准分数，从而实现无量纲的。</p><p>Pearson相关系数值的值域为$[-1, +1]$。如果$\rho &gt;0$则两个变量正相关；反之$\rho &lt;0$时，两个变量负相关。$\rho$的大小描述了相关性的强弱程度，当$\left\lvert \rho \right\rvert =1$时，两个变量完全相关，这时，只需要一个变量就能准确预测另一个变量。</p><p><strong>注意，Pearson相关系数接近0时，并不能代表变量之间没有相关关系，因为Peason相关系数只度量了线性关系。如果变量之间存在非线性关系，那么用$\rho$度量相关性就不那么准确了</strong>。下图为一些具有非线性关系的变量的散点图，然而它们的相关系数都为0。</p><img class title="非线性关系变量散点图及其相关系数" data-src="/2015/10/03/think-statistics-note/nonlinear-correlation-example.png"><p>图片来源：<span class="exturl" data-url="aHR0cDovL3d3dy53aWtpd2FuZC5jb20vZW4vQ29ycmVsYXRpb25fYW5kX2RlcGVuZGVuY2U=" title="http://www.wikiwand.com/en/Correlation_and_dependence">英文维基百科/Correlation and dependence<i class="fa fa-external-link"></i></span></p><h3 id="Spearman秩相关"><a href="#Spearman秩相关" class="headerlink" title="Spearman秩相关"></a>Spearman秩相关</h3><p>当变量之间呈线性相关，且变量大致符合正态分布时，Pearson相关系数能较好地说明相关性的强弱。然而离群值会影响Pearson相关系数的稳健性（回忆一下，Pearson相关系数定义中，每个样本的标准分数是相同权重加和的，因而离群值能较大程度地影响结果）</p><p>Spearman相关系数不仅能描述变量的相关性，还能够缓解离群值及偏斜分布的影响。缓解离群值影响是通过计算各个值的秩(rank)实现的。如在样本[1, 2, 5, 7]中，值5出现在有序列表的第3位，因此5的值为3。</p><p><em>缓解离群值的常见方法就是用“排名”而非其值来计算。比如取中值（排名中位数）就比取均值面对离群点时更加稳健。</em></p><h3 id="相关性和因果关系"><a href="#相关性和因果关系" class="headerlink" title="相关性和因果关系"></a>相关性和因果关系</h3><p>如果变量A和B相关，则有三种可能的解释：A导致B，或B导致A，或其他某种因素导致A和B。这些解释称为“因果关系”。</p><p>只有相关性，我们无法证明因果关系。要证明因果关系，有以下三种方法：</p><ol><li>时间<br> 如果 A 在 B 之前发生，则 A 可能导致 B，而 B 不可能导致 A。</li><li>随机性<br> 类似随机对照试验。<br>3.回归分析</li></ol><h1 id="第八章-估计"><a href="#第八章-估计" class="headerlink" title="第八章 估计"></a>第八章 估计</h1><p>使用样本来<strong>估计</strong>分布，用来估计的统计量叫做<strong>估计量</strong>（estimator）</p><h2 id="均方误差（mean-squared-error，MSE）"><a href="#均方误差（mean-squared-error，MSE）" class="headerlink" title="均方误差（mean squared error，MSE）"></a>均方误差（mean squared error，MSE）</h2><p>均方误差可用来衡量估计量对分布的描述效果</p><script type="math/tex; mode=display">MSE = \frac{1}{m} \sum (\bar{x} - \mu)^2</script><p>其中$m$为抽样次数。</p><h3 id="均方根误差（root-mean-squared-error，RMSE）"><a href="#均方根误差（root-mean-squared-error，RMSE）" class="headerlink" title="均方根误差（root mean squared error，RMSE）"></a>均方根误差（root mean squared error，RMSE）</h3><p>均方根误差就是均方误差的平方根：</p><script type="math/tex; mode=display">RMSE = \sqrt{MSE}</script><p>用均方根误差不一定越小越好，因为估计量在实际情况中不一定会出现。最可能与实际值相符的估计叫做<strong>最大似然估计（maximum likelihood estimator，MLE）</strong></p><h2 id="样本方差"><a href="#样本方差" class="headerlink" title="样本方差"></a>样本方差</h2><p>用样本方差作为估计量估计分布的方差是最直观的方法：</p><script type="math/tex; mode=display">S^2 = \frac{1}{n} \sum (x\_i - \bar{x})^2</script><p>然而，<script type="math/tex">S^2</script>是偏倚（biased）估计量，对于小样本，$S^2$通常比分布的方差低很多。</p><p>无偏估计量是<script type="math/tex">S\_{n-1}^2</script></p><script type="math/tex; mode=display">S\_{n-1}^2 = \frac{1}{n-1} \sum (x\_i - \bar{x})^2</script><p>其中，减去的“1”是自由度。</p><h2 id="抽样"><a href="#抽样" class="headerlink" title="抽样"></a>抽样</h2><h3 id="抽样误差"><a href="#抽样误差" class="headerlink" title="抽样误差"></a>抽样误差</h3><p>由随机选择导致的估计变化称为<strong>抽样误差（sampling error）</strong>，例如，从数量庞大的大猩猩总体中抽取9只测量体重，然而却运气不佳抽到了最重的9只。</p><h3 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h3><p>抽样若干次，对每次抽样的估计量进行统计，得到的分布叫做<strong>抽样分布</strong>。抽样分布是对估计量分布的描述，而不是实际的值的分布。</p><h3 id="抽样分布的描述"><a href="#抽样分布的描述" class="headerlink" title="抽样分布的描述"></a>抽样分布的描述</h3><ul><li>标准误差（standard error，SE）<br>标准误差度量估计值平均偏离实际值多少。注意标准误差描述的是<strong>估计量</strong>变化的情况，而标准差描述的是<strong>度量值</strong>变化的情况。</li><li>置信区间（confidential interval，CI）<br>抽样分布中指定比例的范围。例如，90%置信区间表示的是 第5个百分位数 到 第95个百分位数。</li></ul><h3 id="抽样偏倚"><a href="#抽样偏倚" class="headerlink" title="抽样偏倚"></a>抽样偏倚</h3><p>由于抽样过程导致的误差，叫做抽样偏倚（sampling bias）。比如，通过电话抽样统计女性体重，由于可能不能覆盖到没有电话或是不公布号码的人，实际统计的人群会有偏差。</p><h3 id="测量误差"><a href="#测量误差" class="headerlink" title="测量误差"></a>测量误差</h3><p>测量误差是得到的结果不准确。比如，统计女性体重时，只是询问而不测量；或是由于调查参与者“美化”自己的数字。</p><p>在汇报一个估计值时，可以用标准误差或置信区间。但要记住：抽样误差只是误差来源之一，而且通常不是最大的误差来源。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;第一章-探索性数据分析&quot;&gt;&lt;a href=&quot;#第一章-探索性数据分析&quot; class=&quot;headerlink&quot; title=&quot;第一章 探索性数据分析&quot;&gt;&lt;/a&gt;第一章 探索性数据分析&lt;/h2&gt;&lt;h3 id=&quot;重编码（recode）&quot;&gt;&lt;a href=&quot;#重编码（recode）&quot; class=&quot;headerlink&quot; title=&quot;重编码（recode）&quot;&gt;&lt;/a&gt;重编码（recode）&lt;/h3&gt;&lt;p&gt;不是调查收集的原始数据，而是使用原始数据计算得到的变量。&lt;br&gt;可用来检查数据的一致性和准确性&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;第二章-分布&quot;&gt;&lt;a href=&quot;#第二章-分布&quot; class=&quot;headerlink&quot; title=&quot;第二章 分布&quot;&gt;&lt;/a&gt;第二章 分布&lt;/h2&gt;&lt;h3 id=&quot;直方图&quot;&gt;&lt;a href=&quot;#直方图&quot; class=&quot;headerlink&quot; title=&quot;直方图&quot;&gt;&lt;/a&gt;直方图&lt;/h3&gt;&lt;p&gt;直方图能判断分布的形状，容易发现最常出现的值，但不一定能看到很少出现的值（离群值）&lt;br&gt;
    
    </summary>
    
    
      <category term="统计" scheme="http://mengqi92.github.io/categories/%E7%BB%9F%E8%AE%A1/"/>
    
    
      <category term="读书笔记" scheme="http://mengqi92.github.io/tags/notes/"/>
    
      <category term="统计" scheme="http://mengqi92.github.io/tags/%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
</feed>
